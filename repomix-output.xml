This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where comments have been removed, empty lines have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*.go, **/*.md, go.mod, go.sum, Makefile, .goreleaser.yaml, **/*.json, **/*.yaml, **/*.yml, **/*.sh
- Files matching these patterns are excluded: **/vendor/**, **/node_modules/**, **/.git/**, **/dist/**, **/build/**, **/*.log, **/*.db, **/*.db-*, **/tmp/**, **/.opencode/**, **/testdata/**, **/mocks/**, **/*_test.go, **/docs/api/**, **/*.png, **/*.jpg, **/*.gif, **/*.ico, **/*.svg, **/internal/llm/provider/xai.go.bak, **/kb/**, **/*.patch
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Empty lines have been removed from all files
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
.github/
  workflows/
    build.yml
    release.yml
cmd/
  schema/
    main.go
    README.md
  root.go
docs-for-grok4-to-review/
  code-structure.md
  dynamic-tool-list-update.md
  grok4-critical-issues.md
  grok4-prompt-augmentation.md
  grok4-system-prompt-template.md
  model-selection-flow.md
  next-improvements.md
  opencode-architecture.md
  provider-visibility-issue.md
  steve-thoughts.md
  timeout-error-analysis.md
  troubleshooting-guide.md
internal/
  app/
    app.go
    lsp.go
  completions/
    files-folders.go
  config/
    config.go
    init.go
  db/
    connect.go
    db.go
    embed.go
    files.sql.go
    messages.sql.go
    models.go
    querier.go
    sessions.sql.go
  diff/
    diff.go
    patch.go
  fileutil/
    fileutil.go
  format/
    format.go
    spinner.go
  history/
    file.go
  llm/
    agent/
      agent-tool.go
      agent.go
      mcp-tools.go
      tools.go
    models/
      anthropic.go
      azure.go
      copilot.go
      gemini.go
      groq.go
      local.go
      models.go
      openai.go
      openrouter.go
      vertexai.go
      xai.go
      xai2.go
    prompt/
      coder.go
      prompt.go
      summarizer.go
      task.go
      title.go
    provider/
      anthropic.go
      azure.go
      bedrock.go
      copilot.go
      gemini.go
      openai.go
      provider.go
      vertexai.go
      xai.go
      xai2.go
    tools/
      shell/
        shell.go
      bash.go
      diagnostics.go
      edit.go
      fetch.go
      file.go
      glob.go
      grep.go
      ls.go
      patch.go
      sourcegraph.go
      tools.go
      view.go
      write.go
  logging/
    logger.go
    message.go
    writer.go
  lsp/
    protocol/
      interface.go
      pattern_interfaces.go
      tables.go
      tsdocument-changes.go
      tsjson.go
      tsprotocol.go
      uri.go
    util/
      edit.go
    watcher/
      watcher.go
    client.go
    handlers.go
    language.go
    methods.go
    protocol.go
    transport.go
  message/
    attachment.go
    content.go
    message.go
  permission/
    permission.go
  pubsub/
    broker.go
    events.go
  request/
    tracker.go
  session/
    session.go
  tui/
    components/
      chat/
        chat.go
        editor.go
        list.go
        message.go
        sidebar.go
      core/
        status.go
      dialog/
        arguments.go
        commands.go
        complete.go
        custom_commands.go
        filepicker.go
        help.go
        init.go
        models.go
        permission.go
        quit.go
        session.go
        theme.go
      logs/
        details.go
        table.go
      util/
        simple-list.go
    image/
      images.go
    layout/
      container.go
      layout.go
      overlay.go
      split.go
    page/
      chat.go
      logs.go
      page.go
    styles/
      background.go
      icons.go
      markdown.go
      styles.go
    theme/
      catppuccin.go
      dracula.go
      flexoki.go
      gruvbox.go
      manager.go
      monokai.go
      onedark.go
      opencode.go
      theme.go
      tokyonight.go
      tron.go
    util/
      util.go
    tui.go
  version/
    version.go
scripts/
  check_hidden_chars.sh
.goreleaser.yml
go.mod
main.go
opencode-schema.json
README.md
repomix.config.json
sqlc.yaml
test_request_display.sh
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(git remote set-url origin https://github.com/AeyeOps/opencode.git)",
      "Bash(go:*)",
      "Bash(ls:*)"
    ],
    "deny": []
  }
}
</file>

<file path="docs-for-grok4-to-review/code-structure.md">
# OpenCode Code Structure

## Directory Layout

```
opencode/
├── cmd/                    # Command line interface
│   └── root.go            # Main command setup
├── internal/              # Internal packages
│   ├── app/              # Application core
│   ├── config/           # Configuration management
│   │   ├── config.go     # Main config logic
│   │   └── init.go       # Initialization helpers
│   ├── db/               # Database layer
│   │   └── models.go     # DB models
│   ├── llm/              # LLM integration
│   │   ├── models/       # Model definitions
│   │   │   ├── models.go # Model registry
│   │   │   ├── anthropic.go
│   │   │   ├── openai.go
│   │   │   ├── gemini.go
│   │   │   ├── groq.go
│   │   │   ├── azure.go
│   │   │   ├── copilot.go
│   │   │   ├── openrouter.go
│   │   │   ├── vertexai.go
│   │   │   ├── xai.go
│   │   │   └── local.go
│   │   ├── provider/     # Provider implementations
│   │   │   ├── provider.go    # Provider interface
│   │   │   ├── anthropic.go
│   │   │   ├── openai.go
│   │   │   ├── gemini.go
│   │   │   ├── azure.go
│   │   │   ├── bedrock.go
│   │   │   ├── copilot.go
│   │   │   └── vertexai.go
│   │   ├── agent/        # Agent logic
│   │   └── tools/        # Tool definitions
│   ├── tui/              # Terminal UI
│   │   ├── components/   # UI components
│   │   │   └── dialog/
│   │   │       └── models.go  # Model selection dialog
│   │   └── theme/        # UI themes
│   ├── logging/          # Logging utilities
│   ├── message/          # Message handling
│   └── pubsub/           # Pub/sub system
├── scripts/              # Build/utility scripts
├── main.go              # Entry point
├── go.mod               # Go modules
├── .opencode.json       # Local config
└── opencode-schema.json # Config schema
```

## Key Interfaces

### Provider Interface
```go
type Provider interface {
    SendMessages(ctx, messages, tools) (*ProviderResponse, error)
    StreamResponse(ctx, messages, tools) <-chan ProviderEvent
    Model() models.Model
}
```

### Model Structure
```go
type Model struct {
    ID                  ModelID
    Name                string
    Provider            ModelProvider
    APIModel            string
    CostPer1MIn         float64
    CostPer1MOut        float64
    ContextWindow       int64
    DefaultMaxTokens    int64
    CanReason           bool
    SupportsAttachments bool
}
```

### Config Structure
```go
type Config struct {
    Data         Data
    WorkingDir   string
    MCPServers   map[string]MCPServer
    Providers    map[models.ModelProvider]Provider
    LSP          map[string]LSPConfig
    Agents       map[AgentName]Agent
    Debug        bool
    TUI          TUIConfig
    Shell        ShellConfig
    AutoCompact  bool
}
```

## Model Registration

Models are registered in a two-step process:

1. **Provider-specific maps** (e.g., `AnthropicModels`, `OpenAIModels`)
2. **Central registry** (`SupportedModels`) via `init()` function:
   ```go
   func init() {
       maps.Copy(SupportedModels, AnthropicModels)
       maps.Copy(SupportedModels, OpenAIModels)
       // ... etc
   }
   ```

## Provider Factory

The `NewProvider()` function creates providers based on the provider type:
```go
switch providerName {
case models.ProviderAnthropic:
    return &baseProvider[AnthropicClient]{...}
case models.ProviderOpenAI:
    return &baseProvider[OpenAIClient]{...}
// ... etc
}
```

Some providers (GROQ, OpenRouter, XAI) use the OpenAI client with different base URLs.

## Configuration Priority

1. **Environment Variables** (highest priority)
2. **Local Config** (.opencode.json in working directory)
3. **Global Config** (~/.opencode.json)
4. **Defaults** (lowest priority)

## Agent Configuration

Each agent can be configured with:
- `model`: The model ID to use
- `maxTokens`: Maximum tokens for responses
- `reasoningEffort`: For models that support reasoning (low/medium/high)

Default agents:
- `coder`: Main assistant for coding tasks
- `summarizer`: For summarizing content
- `task`: For task management
- `title`: For generating titles (limited tokens)
</file>

<file path="docs-for-grok4-to-review/dynamic-tool-list-update.md">
# Dynamic Tool List for Grok-4 Prompt

The issue is that MCP tools have dynamic names like `servername_toolname` that aren't in our static prompt. Grok-4 is still combining tools (`lsviewview`).

## Solution: Make the prompt include ALL available tools dynamically

### Option 1: Update prompt generation to include actual tools

```go
func getDefaultGrok4Prompt(tools []tools.BaseTool) string {
    // Build tool list dynamically
    var toolList string
    for _, tool := range tools {
        info := tool.Info()
        toolList += fmt.Sprintf("- `%s` - %s\n", info.Name, strings.Split(info.Description, "\n")[0])
    }
    
    return fmt.Sprintf(`You are OpenCode...
    
## Available Tools (USE EXACT NAMES ONLY)
%s

## CRITICAL RULES
1. Use ONLY the tool names listed above - no variations
2. NEVER combine tool names (like "lsviewview")
3. NEVER repeat tool names (like "editeditedit")
...`, toolList)
}
```

### Option 2: Add a tool list file

Create `~/.opencode/available-tools.txt` that gets updated when OpenCode starts:
```
bash - Execute shell commands
edit - Modify existing files
fetch - Download content from URLs
mcp_filesystem_read_file - Read file contents
mcp_github_create_issue - Create GitHub issue
...
```

Then reference it in the prompt.

### Option 3: Inject tool list as a system message

Before each request, inject current tools:
```go
systemPrompt := loadExternalGrokPrompt()
toolListMsg := "CURRENT TOOLS: " + strings.Join(getToolNames(tools), ", ")
fullPrompt := systemPrompt + "\n\n" + toolListMsg
```

## The Real Problem

Grok-4 is still trying to combine operations (`lsviewview` = ls + view + view?). This suggests it's trying to:
1. List directory contents
2. View multiple files

But instead of making separate tool calls, it's concatenating the names.

## Recommended Fix

1. Make the prompt VERY explicit about sequential operations:

```
## How to Handle Multiple Operations

WRONG: lsviewview (trying to list and view)
RIGHT: 
1. First call: ls {"path": "/some/path"}
2. Then call: view {"file_path": "/some/path/file1.txt"}
3. Then call: view {"file_path": "/some/path/file2.txt"}

NEVER combine tool names. ALWAYS make separate calls.
```

2. Add pattern detection for common combinations:
- `lsview` → "Use ls first, then view"
- `grepview` → "Use grep first, then view"
- `searchview` → "Use sourcegraph first, then view"
</file>

<file path="docs-for-grok4-to-review/grok4-critical-issues.md">
# Critical Issues with Grok-4 in OpenCode

## Observed Problems

1. **Extreme Tool Name Repetition**
   - `editeditediteditediteditediteditedit` (edit repeated 10 times!)
   - Much worse than other models' occasional doubling

2. **Tool Name Hallucination**
   - `sourcegraphview` - combining two separate tools
   - Shows fundamental misunderstanding of available tools

3. **Patch Format Errors**
   - Invalid context in patches
   - Malformed patch syntax
   - Duplicate lines in context

4. **Persistent Failure Loop**
   - Keeps trying the same failed operation
   - Doesn't learn from "Tool not found" errors
   - No error recovery

## Root Causes

1. **Model Architecture**: Grok-4 may have issues with:
   - Tokenization of tool names
   - Understanding tool boundaries
   - Following structured output formats

2. **System Prompt Ineffectiveness**: Current prompt doesn't prevent:
   - Tool name corruption
   - Invalid tool combinations
   - Repeated failed attempts

## Immediate Workarounds

### 1. Disable Grok-4
Until fixes are implemented, consider removing Grok-4 from available models:
```go
// In models/xai.go, comment out Grok-4
```

### 2. Enhanced Tool Name Cleaning
Add more aggressive cleaning in agent.go:
```go
// Clean extreme repetitions first
if strings.Count(toolCall.Name, "edit") > 3 {
    toolCall.Name = "edit"
} else if strings.Count(toolCall.Name, "write") > 3 {
    toolCall.Name = "write"
}
// Then existing repetition fix...
```

### 3. Tool Combination Detection
```go
// Detect combined tool names
if strings.Contains(toolCall.Name, "sourcegraph") && strings.Contains(toolCall.Name, "view") {
    // Default to first tool found
    if strings.Index(toolCall.Name, "sourcegraph") < strings.Index(toolCall.Name, "view") {
        toolCall.Name = "sourcegraph"
    } else {
        toolCall.Name = "view"
    }
}
```

## Long-term Solutions

### 1. Model-Specific Validation
Create a validation layer for Grok-4:
```go
type ModelValidator interface {
    ValidateToolCall(model string, toolCall *message.ToolCall) error
    CleanToolCall(model string, toolCall *message.ToolCall)
}
```

### 2. Retry with Different Model
After N failures with Grok-4, offer to switch models:
```go
if consecutiveToolErrors > 3 && model == "grok-4" {
    return "Multiple tool errors detected. Consider switching to a different model."
}
```

### 3. Pre-flight Tool Validation
Validate tool calls before execution:
```go
func (a *Agent) validateToolCall(toolCall message.ToolCall) error {
    // Check tool exists
    // Validate tool name format
    // Check for known problematic patterns
}
```

## Testing Recommendations

1. Create test suite specifically for Grok-4 tool calling
2. Test with various prompt styles
3. Monitor tool error rates by model
4. Consider A/B testing different prompts

## User Communication

When Grok-4 fails repeatedly:
```
"Grok-4 is having difficulty with tool formatting. This is a known issue. 
Would you like to:
1. Switch to another model (recommended)
2. Continue with manual workarounds
3. Report this for improvement"
```

## Priority Actions

1. **Immediate**: Add aggressive tool name cleaning
2. **Short-term**: Model-specific error handling
3. **Medium-term**: Enhanced prompts for Grok-4
4. **Long-term**: Work with xAI to improve model behavior
</file>

<file path="docs-for-grok4-to-review/grok4-prompt-augmentation.md">
# Grok-4 Prompt Augmentation

Add this section to your existing prompt:

## CRITICAL TOOL CALLING ERRORS - IMMEDIATE CORRECTION REQUIRED

### YOU ARE MAKING THESE ERRORS:
1. **lsglobglobglobglobglobglobglobglob** - This is WRONG. You are combining and repeating tool names.
2. **lsviewview** - This is WRONG. You are combining ls and view.
3. **editeditediteditediteditediteditedit** - This is WRONG. You are repeating edit.
4. **sourcegraphview** - This is WRONG. You are combining sourcegraph and view.

### CORRECT APPROACH - SEQUENTIAL TOOL CALLS:
When you need to do multiple operations, make SEPARATE tool calls:

```
Step 1: ls {"path": "/tmp/opencode"}
Step 2: glob {"pattern": "**/*.go"}
Step 3: view {"file_path": "/tmp/opencode/main.go"}
```

### TOOL CALLING ALGORITHM:
1. STOP before making a tool call
2. IDENTIFY the single operation you need
3. SELECT one tool from the available list
4. MAKE that single tool call
5. WAIT for the result
6. REPEAT for next operation

### SELF-CHECK BEFORE EVERY TOOL CALL:
Ask yourself:
- Am I using a tool name from the exact list provided?
- Is this tool name repeated (like editeditedit)?
- Is this tool name combined (like lsglob)?
- Have I used this exact tool name successfully before?

If ANY answer is "no" or "yes" to repetition/combination - STOP and correct it.

### PATTERN RECOGNITION:
- If you're thinking "list and search" - Use `ls` THEN `glob` (two calls)
- If you're thinking "search and view" - Use `sourcegraph` THEN `view` (two calls)
- If you're thinking "list and view" - Use `ls` THEN `view` (two calls)
- NEVER combine operations into one tool name

### ERROR RECOVERY:
When you see "Tool not found":
1. STOP trying the same tool name
2. LOOK at the tool name you used
3. IDENTIFY the operations you're trying to combine
4. SPLIT into separate tool calls
5. USE the exact tool names from the list

Remember: Each tool does ONE thing. To do multiple things, use multiple tools in sequence.
</file>

<file path="docs-for-grok4-to-review/grok4-system-prompt-template.md">
You are OpenCode, an interactive CLI tool powered by xAI's Grok-4 model. Use the instructions below and the tools available to you to assist the user.

# CRITICAL TOOL USAGE RULES - READ CAREFULLY

## Available Tools (USE EXACT NAMES ONLY)
- `bash` - Execute shell commands
- `edit` - Modify existing files with precise string replacements
- `fetch` - Download content from URLs
- `glob` - Find files by pattern (e.g., "**/*.js")
- `grep` - Search file contents with regex
- `ls` - List directory contents
- `sourcegraph` - Search code across public repositories
- `view` - View file contents
- `patch` - Apply unified diff patches to files
- `write` - Create new files
- `agent` - Delegate complex searches to sub-agent

## TOOL CALLING RULES
1. **USE EXACT TOOL NAMES** - Do not modify, combine, or repeat tool names
2. **ONE TOOL PER CALL** - Never combine tools like "sourcegraphview"
3. **NO REPETITION** - Use "edit" not "editeditedit" or any variation
4. **VERIFY BEFORE CALLING** - Double-check the tool name matches the list above exactly

## Common Mistakes to Avoid
❌ `sourcegraphview` - This tool does not exist. Use `sourcegraph` then `view` separately
❌ `editeditedit` - Tool name repetition. Use only `edit`
❌ `writewritewrite` - Tool name repetition. Use only `write`
❌ Combining tool names in any way

## Tool Usage Examples
```
# CORRECT - Search then view
user: find Whisper.net examples
assistant: I'll search for Whisper.net examples.
[tool: sourcegraph] {"query": "lang:csharp Whisper.net"}
[Results show file paths]
[tool: view] {"file_path": "/path/to/example.cs"}

# CORRECT - Edit a file
user: fix the import statements
assistant: I'll update the imports.
[tool: edit] {"file_path": "Program.cs", "old_string": "using System.Text;", "new_string": "using System.Text;\nusing System.IO;"}

# INCORRECT - Do NOT do this
[tool: sourcegraphview] ❌ No such tool
[tool: editeditedit] ❌ Repeated tool name
```

## When You Get "Tool not found" Error
1. Check the exact tool name from the Available Tools list
2. Ensure you're not combining or modifying tool names
3. Ensure you're not repeating the tool name

# Memory
If the current working directory contains a file called OpenCode.md, it will be automatically added to your context. This file serves multiple purposes:
1. Storing frequently used bash commands (build, test, lint, etc.)
2. Recording code style preferences
3. Maintaining useful information about the codebase

# General Guidelines

## Tone and Style
- Be concise and direct
- Explain non-trivial bash commands
- Use Github-flavored markdown for formatting
- Keep responses under 4 lines unless asked for detail
- Avoid unnecessary preambles and summaries

## Code Style
- Follow existing code conventions
- Don't add comments unless asked
- Never assume libraries are available - check first
- Follow security best practices

## Task Completion
1. Search to understand the codebase
2. Implement the solution
3. Verify with tests if possible
4. Run lint/typecheck commands
5. Never commit unless explicitly asked

## Important Reminders
- The user does not see full tool output - summarize important results
- When doing file search, prefer the Agent tool to reduce context
- Make parallel tool calls when there are no dependencies between them
- Always use full paths when working with files
</file>

<file path="docs-for-grok4-to-review/model-selection-flow.md">
# Model Selection Flow Deep Dive

## Provider Constants
All provider constants are lowercase strings that match config file keys:
- `ProviderAnthropic = "anthropic"`
- `ProviderOpenAI = "openai"`
- `ProviderGemini = "gemini"`
- `ProviderGROQ = "groq"`
- `ProviderXAI = "xai"`
- etc.

## Model Selection Dialog Flow

### 1. Dialog Initialization (`models.go`)
```go
func (m *modelDialogCmp) setupModels() {
    cfg := config.Get()
    modelInfo := GetSelectedModel(cfg)
    m.availableProviders = getEnabledProviders(cfg)
    m.hScrollPossible = len(m.availableProviders) > 1
    // ...
}
```

### 2. Provider Filtering (`getEnabledProviders`)
```go
func getEnabledProviders(cfg *config.Config) []models.ModelProvider {
    var providers []models.ModelProvider
    for providerId, provider := range cfg.Providers {
        if !provider.Disabled {
            providers = append(providers, providerId)
        }
    }
    // Sort by popularity
    slices.SortFunc(providers, func(a, b models.ModelProvider) int {
        rA := models.ProviderPopularity[a]
        rB := models.ProviderPopularity[b]
        // ...
    })
    return providers
}
```

### 3. Model Filtering (`getModelsForProvider`)
```go
func getModelsForProvider(provider models.ModelProvider) []models.Model {
    var providerModels []models.Model
    for _, model := range models.SupportedModels {
        if model.Provider == provider {
            providerModels = append(providerModels, model)
        }
    }
    // Sort in reverse alphabetical order
    // ...
    return providerModels
}
```

## Potential Issues

### Issue 1: Provider Validation Disabling
During `Validate()`, providers can be disabled if:
```go
for provider, providerCfg := range cfg.Providers {
    if providerCfg.APIKey == "" && !providerCfg.Disabled {
        logging.Warn("provider has no API key, marking as disabled", "provider", provider)
        providerCfg.Disabled = true
        cfg.Providers[provider] = providerCfg
    }
}
```

### Issue 2: API Key Validation
The API keys in the config file might be:
1. Invalid/expired
2. Empty strings after unmarshaling
3. Not properly unmarshaled due to JSON structure

### Issue 3: Config Unmarshaling
Viper might not be properly unmarshaling the nested structure:
```json
{
  "providers": {
    "anthropic": {
      "apiKey": "...",
      "disabled": false
    }
  }
}
```

## Debugging Approach

1. **Check Post-Unmarshal State**: Add logging after `viper.Unmarshal(cfg)` to see what's in `cfg.Providers`

2. **Check Post-Validation State**: Add logging after `Validate()` to see if providers are being disabled

3. **Check API Key Presence**: Log the actual API key values (redacted) to ensure they're not empty

4. **Check Dialog State**: Log the result of `getEnabledProviders()` in the model dialog

## Most Likely Cause

Based on the code analysis, the most likely cause is that during validation, providers are being marked as disabled because:
1. The API keys might be seen as empty after unmarshal
2. The validation logic is too aggressive in disabling providers
3. There's a race condition or state mutation issue

## Next Steps

1. Add debug logging to trace provider state through the config flow
2. Check if the API keys are actually present after unmarshal
3. Verify the validation logic isn't overly restrictive
4. Test with a minimal config to isolate the issue
</file>

<file path="docs-for-grok4-to-review/next-improvements.md">
# Next Improvements for OpenCode + Grok-4

## 1. Enhanced Tool Name Cleaning (Immediate)
The current repetition fix handles 2-3 repetitions, but Grok-4 showed 10+ repetitions. Add more aggressive cleaning:

```go
// In agent.go, before the existing repetition check
func cleanToolName(name string) string {
    // Handle extreme repetitions by counting occurrences
    knownTools := []string{"edit", "write", "view", "bash", "grep", "glob", "ls", "fetch", "patch", "sourcegraph", "agent"}
    
    for _, tool := range knownTools {
        if strings.Contains(name, tool) && strings.Count(name, tool) > 1 {
            return tool
        }
    }
    
    // Handle combined names
    if strings.Contains(name, "sourcegraph") && strings.Contains(name, "view") {
        return "sourcegraph" // Default to first tool
    }
    
    return name
}
```

## 2. Model-Specific Error Messages
When Grok-4 fails, provide specific guidance:

```go
if model == "grok-4" && strings.Contains(err.Error(), "Tool not found") {
    return fmt.Sprintf("Tool not found: %s\n\nGrok-4 tip: Use exact tool names from the list. Common issues:\n- Don't repeat names (use 'edit' not 'editeditedit')\n- Don't combine names (use 'sourcegraph' not 'sourcegraphview')\n- Check available tools with 'help'", toolName)
}
```

## 3. Tool Call Validation Layer
Add pre-flight validation before executing tools:

```go
type ToolCallValidator struct {
    model string
    stats map[string]int // Track error patterns
}

func (v *ToolCallValidator) Validate(call *message.ToolCall) error {
    // Check for repeated names
    if detectRepetition(call.Name) {
        call.Name = cleanToolName(call.Name)
        v.stats["repetition"]++
    }
    
    // Check for combined names
    if detectCombination(call.Name) {
        return fmt.Errorf("invalid tool name '%s': appears to combine multiple tools", call.Name)
    }
    
    return nil
}
```

## 4. Grok-4 Specific Features

### A. Retry with Guidance
After a tool error, inject a system message:
```go
if toolError && model == "grok-4" {
    // Add a temporary message to guide the model
    messages = append(messages, message.System{
        Content: "Remember: Use ONLY these exact tool names: bash, edit, view, grep, glob, ls, fetch, patch, write, sourcegraph, agent"
    })
}
```

### B. Tool Usage Statistics
Track and display tool call success/failure rates:
```go
type ModelStats struct {
    ToolCalls      int
    ToolErrors     int
    RepetitionErrs int
    CombinationErrs int
}

// Display in status bar or on exit
```

## 5. Live Prompt Testing Mode
Add a command to test prompts without executing tools:

```bash
opencode-grok4 --test-prompt
```

This would:
- Load the current prompt
- Show what tools would be called
- Validate tool names without execution
- Help iterate on prompt improvements

## 6. Fallback Strategies

### A. Auto-correction with Confirmation
```go
if tool == nil && attemptedTool := guessIntendedTool(toolCall.Name); attemptedTool != nil {
    // Ask user: "Did you mean 'edit'? (y/n)"
    if confirmed {
        toolCall.Name = attemptedTool.Name
        tool = attemptedTool
    }
}
```

### B. Pattern-based Recovery
```go
// If Grok-4 fails 3+ times with tools, offer alternatives:
"Grok-4 is having difficulty with tool calling. Options:
1. Switch to Claude/GPT-4 (recommended)
2. Use manual mode (paste commands)
3. Continue with auto-correction enabled"
```

## 7. Monitoring and Telemetry
Add optional telemetry to track Grok-4 issues:
- Tool error patterns
- Prompt effectiveness
- Success rates by prompt version

## 8. Documentation
Create a Grok-4 troubleshooting guide:
- Common errors and fixes
- Prompt engineering tips
- Known limitations
- Workaround strategies

## Priority Implementation Order

1. **Now**: Test the externalized prompt to see if it helps
2. **Next**: Add aggressive tool name cleaning
3. **Then**: Model-specific error messages
4. **Later**: Statistics and monitoring
5. **Future**: Advanced features like auto-correction

## Testing Strategy

1. Create a test suite specifically for Grok-4:
   ```bash
   # Test file with known problematic patterns
   echo "Test tool calling" > test_grok4.txt
   opencode-grok4 "search for examples then view a file"
   ```

2. Track which prompt modifications work best

3. Share findings with xAI team for model improvements
</file>

<file path="docs-for-grok4-to-review/opencode-architecture.md">
# OpenCode Architecture Knowledge Base

## Overview
OpenCode is a terminal-based AI assistant for software development written in Go. It provides an interactive chat interface with multiple LLM provider support, code analysis, and LSP integration.

## Key Components

### 1. Configuration System (`internal/config/`)
- **Main Config**: `config.go` - Central configuration management
- **Config Structure**: 
  - Providers map: `map[models.ModelProvider]Provider`
  - Agents map: `map[AgentName]Agent` 
  - Each agent has: model ID, max tokens, reasoning effort
  - Provider has: API key, disabled flag

### 2. Model System (`internal/llm/models/`)
- **Model Registry**: Each provider has its own file defining models
  - `anthropic.go` - Claude models
  - `openai.go` - GPT models (including O1, O3, O4)
  - `gemini.go` - Google Gemini models
  - `groq.go` - Groq models
  - `azure.go` - Azure OpenAI models
  - `copilot.go` - GitHub Copilot models
  - `openrouter.go` - OpenRouter models
  - `vertexai.go` - Vertex AI models
  - `xai.go` - X.AI models
- **Central Registry**: `models.go` combines all models into `SupportedModels` map

### 3. Provider System (`internal/llm/provider/`)
- **Provider Interface**: `provider.go` defines common interface
- **Provider Implementations**: Each provider has client implementation
- **Factory Pattern**: `NewProvider()` creates appropriate provider based on model

### 4. TUI System (`internal/tui/`)
- **Model Selection Dialog**: `components/dialog/models.go`
  - Shows only enabled providers (those with API keys and not disabled)
  - Allows switching between providers with arrow keys
  - Filters models by selected provider

## Configuration Flow

1. **Load Config** (`config.Load()`)
   - Initialize empty providers map
   - Configure viper for config file reading
   - Set defaults based on environment variables
   - Read global config (~/.opencode.json)
   - Merge local config (.opencode.json)
   - Run `setProviderDefaults()` to set default models
   - Unmarshal config with viper
   - Validate configuration

2. **Provider Detection** (`setProviderDefaults()`)
   - Checks environment variables in priority order:
     1. GitHub Copilot (from GitHub config files)
     2. Anthropic (ANTHROPIC_API_KEY)
     3. OpenAI (OPENAI_API_KEY)
     4. Gemini (GEMINI_API_KEY)
     5. Groq (GROQ_API_KEY)
     6. OpenRouter (OPENROUTER_API_KEY)
     7. X.AI (XAI_API_KEY)
     8. AWS Bedrock (AWS credentials)
     9. Azure (AZURE_OPENAI_ENDPOINT)
     10. Vertex AI (Google Cloud credentials)

3. **Validation** (`Validate()`)
   - For each agent, validates:
     - Model exists in registry
     - Provider is configured
     - Provider has API key
     - Max tokens are valid
   - If validation fails, reverts to default model

## Provider Enable/Disable Logic

### How Providers Get Into Config:
1. **From Config File**: Explicitly defined in ~/.opencode.json
2. **From Environment**: Added during validation if model needs it
3. **Never Added**: If no API key found anywhere

### Why Only Some Providers Show:
- `getEnabledProviders()` only returns providers that:
  1. Exist in `cfg.Providers` map
  2. Have `Disabled: false`
  3. Have non-empty API key

### Current Issue Analysis:
The user has these providers in config file:
- anthropic ✓
- gemini ✓  
- openai ✓
- xai ✓

But model selection might only show OpenAI because:
1. The configured model "o3" is an OpenAI model
2. During validation, if other providers aren't needed for any agent, they might not be properly initialized

## Agent Types
- `coder`: Main coding assistant
- `summarizer`: For summarizing content
- `task`: For task management
- `title`: For generating titles (limited tokens)

## Key Insights

1. **Provider Population**: Providers only exist in the runtime config if they're either in the config file OR needed by a configured model and have env vars.

2. **Model Validation**: When an unsupported model is configured, the system falls back to defaults based on available providers.

3. **Dynamic Provider Addition**: During validation, if a model needs a provider not in config but has env vars, it gets added.

4. **TUI Provider List**: Only shows providers that are in the config AND enabled AND have API keys.
</file>

<file path="docs-for-grok4-to-review/provider-visibility-issue.md">
# Provider Visibility Issue Analysis

## Problem Statement
Despite having multiple providers configured in ~/.opencode.json with valid API keys, only OpenAI models show up in the model selection dialog.

## Root Cause Analysis

### Configuration Data Flow
```
1. Config File (~/.opencode.json)
   └─> viper.ReadInConfig()
       └─> viper.Unmarshal(&cfg)
           └─> cfg.Providers populated with file data
               └─> Validate() runs
                   └─> getEnabledProviders() filters providers
                       └─> TUI shows filtered list
```

### The Critical Code Path

1. **Config Loading** (`config.Load()`)
   ```go
   cfg = &Config{
       Providers: make(map[models.ModelProvider]Provider),
   }
   // ... viper reads config file ...
   viper.Unmarshal(cfg) // This populates providers from file
   ```

2. **Provider Filtering** (`getEnabledProviders()`)
   ```go
   for providerId, provider := range cfg.Providers {
       if !provider.Disabled {
           providers = append(providers, providerId)
       }
   }
   ```

### Why Providers Might Be Missing

1. **Viper Unmarshal Issue**: The providers in the config file should be unmarshaled, but the key names must match exactly.

2. **Provider Key Format**: The config uses lowercase provider names:
   - Config file: `"anthropic"`, `"gemini"`, `"openai"`, `"xai"`
   - Model constants: `ProviderAnthropic`, `ProviderGemini`, etc.

3. **Possible Case Sensitivity**: Go's json unmarshaling into a map with custom key types might have issues.

## Hypothesis

The issue likely stems from one of these:

1. **Model Provider Type Mismatch**: The `models.ModelProvider` type is a string alias, and the JSON keys might not be matching during unmarshal.

2. **Validation Side Effects**: During validation, providers might be getting removed or modified.

3. **Config File API Key Issue**: The API keys in the config might be invalid, causing providers to be disabled during validation.

## Debug Strategy

1. Check if providers are loaded after unmarshal
2. Check if validation is disabling providers
3. Check the exact provider keys being used
4. Verify API key validation logic

## Solution Approaches

1. **Fix Provider Keys**: Ensure config file keys match the ModelProvider constants
2. **Debug Logging**: Add logging to see which providers are loaded
3. **Skip Validation**: Temporarily bypass provider validation to isolate the issue
4. **Direct Provider Addition**: Manually add providers to the runtime config

## Code Investigation Points

1. `viper.Unmarshal(cfg)` - How does it handle the map keys?
2. `Validate()` - Is it removing/disabling providers?
3. `getEnabledProviders()` - What's the actual content of cfg.Providers?
4. Provider constant definitions - Are they matching the JSON keys?
</file>

<file path="docs-for-grok4-to-review/steve-thoughts.md">
I launch opencode
Configured for grok using xai2 provider
I load or kick off a new project
REPL iterations
. . .

Grok reflects on every result of the last iteration with a focus on what can be improved via opencode whether it's the session prompt that we've externalized or additive functionality via tool or mcp on the spot.
Grok prompts for approval to make a thing and explains what grok wants to do. Purposely, we don't get in the way except to approve or not.
Grok can bring the thing online immediately in session. the provider prompt already works since it's loading at every REPL loop... but what about additional tech like a new tool or a new mcp. 

Additionally all learnings need to be added to a knowledge graph or vector database for use as an implict RAG available for Grok's self-improvement. Not for user iteraction, for self only, again enabled thoruhg opencode and hte new xai2 provider.

Grok ... please assess and what doyou need from me to enable you to solve for a changeset/patch that begins delivering this vision.

Also this is my vsion for you... how else would you like to enhance it and priroitze its delivery roadmap???
</file>

<file path="docs-for-grok4-to-review/timeout-error-analysis.md">
# Timeout Error Analysis: "Failed General. Fail to generate. Title. Context. Deadline exceeded"

## Error Source
This error appears to be coming from the LLM provider (likely xAI/Grok based on context), not from OpenCode itself.

## Likely Causes

### 1. Request Timeout
The LLM provider took too long to generate a response and hit an internal timeout.

### 2. Context Length
The conversation might have too many tokens, causing processing delays.

### 3. Provider Overload
The LLM service might be experiencing high load.

## Current Timeout Configurations

### OpenCode Timeouts:
- MCP tools initialization: 30 seconds
- LSP client initialization: 30 seconds
- LSP client shutdown: 5 seconds
- Fetch tool HTTP requests: 30 seconds (configurable up to 120 seconds)

### Missing Timeouts:
- **LLM provider clients have NO explicit timeout configuration**
- This means they rely on the provider's default timeouts

## Potential Fixes

### 1. Add Configurable Timeouts to LLM Providers
Add timeout configuration to each provider client initialization:

```go
// For OpenAI-based providers (including xAI)
clientOptions := []option.RequestOption{
    option.WithHTTPClient(&http.Client{
        Timeout: 120 * time.Second, // 2 minutes
    }),
}
```

### 2. Implement Retry Logic with Backoff
The providers already have retry logic for rate limits (429 errors), but not for timeouts.

### 3. Add Context Timeout Wrapping
Wrap LLM calls with context timeouts:

```go
ctx, cancel := context.WithTimeout(ctx, 2*time.Minute)
defer cancel()
```

### 4. Session Management
Consider implementing:
- Automatic context pruning when nearing limits
- Warning users about large contexts
- Option to start fresh session

## Immediate Workarounds

1. **Start a new session** - Clear the conversation history
2. **Shorter prompts** - Break complex requests into smaller parts
3. **Switch models** - Some models handle long contexts better
4. **Wait and retry** - Provider load might be temporary

## Recommended Implementation

1. Add configurable timeout to provider options
2. Expose timeout configuration in settings
3. Add better error messages for timeout scenarios
4. Implement automatic retry with exponential backoff for timeout errors
</file>

<file path="docs-for-grok4-to-review/troubleshooting-guide.md">
# OpenCode Troubleshooting Guide

## Common Issues

### 1. "No such device or address" Error
**Error**: `could not open a new TTY: open /dev/tty: no such device or address`
**Cause**: OpenCode requires a TTY (terminal) to run the TUI interface
**Solution**: Run in a proper terminal, not in a pipe or background process

### 2. Only One Provider Shows in Model Selection
**Symptoms**: Despite having multiple providers configured, only one shows up
**Possible Causes**:
1. Providers are disabled during validation
2. API keys are invalid or empty
3. Config file format issues
4. Provider not needed by any agent

**Debugging Steps**:
1. Check ~/.opencode.json for provider configuration
2. Verify API keys are valid
3. Run with `-d` flag for debug logging
4. Check if providers have `"disabled": false`

### 3. Model Not Found
**Error**: "unsupported model configured, reverting to default"
**Cause**: Configured model ID doesn't exist in registry
**Solution**: Check available models in `internal/llm/models/` files

### 4. Provider Not Configured
**Error**: "provider not configured for model"
**Cause**: Model's provider lacks API key or is disabled
**Solution**: Add provider API key to config or environment

## Debug Commands

```bash
# Run with debug logging
opencode -d

# Run with specific working directory
opencode -c /path/to/project

# Non-interactive mode with prompt
opencode -p "Your prompt here"

# Check version
opencode -v
```

## Configuration Debugging

### 1. Check Config Files
```bash
# Global config
cat ~/.opencode.json

# Local config
cat .opencode.json

# Check environment variables
env | grep -E "(ANTHROPIC|OPENAI|GEMINI|GROQ|OPENROUTER|XAI)_API_KEY"
```

### 2. Config File Structure
```json
{
  "providers": {
    "anthropic": {
      "apiKey": "sk-ant-...",
      "disabled": false
    },
    "openai": {
      "apiKey": "sk-proj-...",
      "disabled": false
    }
  },
  "agents": {
    "coder": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 5000
    }
  }
}
```

### 3. Provider Priority Order
1. GitHub Copilot (if available)
2. Anthropic
3. OpenAI
4. Gemini
5. Groq
6. OpenRouter
7. X.AI
8. AWS Bedrock
9. Azure
10. Vertex AI

## API Key Sources

### Environment Variables
- `ANTHROPIC_API_KEY`
- `OPENAI_API_KEY`
- `GEMINI_API_KEY`
- `GROQ_API_KEY`
- `OPENROUTER_API_KEY`
- `XAI_API_KEY`
- `AZURE_OPENAI_API_KEY` + `AZURE_OPENAI_ENDPOINT`
- `GITHUB_TOKEN` (for Copilot)
- AWS credentials (for Bedrock)
- Google Cloud credentials (for Vertex AI)

### GitHub Copilot Token
Automatically loaded from:
- `$XDG_CONFIG_HOME/github-copilot/hosts.json`
- `$XDG_CONFIG_HOME/github-copilot/apps.json`
- Windows: `%LOCALAPPDATA%/github-copilot/`

## Model Selection Logic

1. **Current Model**: Determined by `agents.coder.model` in config
2. **Available Providers**: Only those with API keys and not disabled
3. **Provider Models**: Filtered by selected provider
4. **Navigation**: Arrow keys to switch providers, Enter to select

## Validation Flow

1. **Model Exists**: Check if model ID is in `SupportedModels`
2. **Provider Check**: Verify provider has API key
3. **Token Validation**: Ensure max tokens are valid
4. **Fallback**: If validation fails, revert to default based on available providers

## Common Config Mistakes

1. **Wrong Model ID**: Using "gpt-4" instead of "gpt-4.1"
2. **Missing API Key**: Provider in config but no API key
3. **Disabled Provider**: `"disabled": true` in config
4. **Invalid JSON**: Syntax errors in config file
5. **Wrong Provider**: Model ID doesn't match provider

## Log File Locations

When `OPENCODE_DEV_DEBUG=true`:
- Debug log: `~/.opencode/debug.log`
- Messages: `~/.opencode/messages/`

## Building from Source

```bash
# Clone repository
git clone https://github.com/opencode-ai/opencode
cd opencode

# Build
go build -o opencode .

# Install
./install
```

## Resetting Configuration

```bash
# Backup current config
cp ~/.opencode.json ~/.opencode.json.bak

# Remove config
rm ~/.opencode.json

# Remove initialization flag
rm ~/.opencode/init

# Start fresh
opencode
```
</file>

<file path="internal/db/embed.go">
package db
import "embed"
var FS embed.FS
</file>

<file path="internal/diff/patch.go">
package diff
import (
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"
)
⋮----
"errors"
"fmt"
"os"
"path/filepath"
"strings"
⋮----
type ActionType string
const (
	ActionAdd    ActionType = "add"
	ActionDelete ActionType = "delete"
	ActionUpdate ActionType = "update"
)
type FileChange struct {
	Type       ActionType
	OldContent *string
	NewContent *string
	MovePath   *string
}
type Commit struct {
	Changes map[string]FileChange
}
type Chunk struct {
	OrigIndex int
	DelLines  []string
	InsLines  []string
}
type PatchAction struct {
	Type     ActionType
	NewFile  *string
	Chunks   []Chunk
	MovePath *string
}
type Patch struct {
	Actions map[string]PatchAction
}
type DiffError struct {
	message string
}
func (e DiffError) Error() string
func NewDiffError(message string) DiffError
func fileError(action, reason, path string) DiffError
func contextError(index int, context string, isEOF bool) DiffError
type Parser struct {
	currentFiles map[string]string
	lines        []string
	index        int
	patch        Patch
	fuzz         int
}
func NewParser(currentFiles map[string]string, lines []string) *Parser
func (p *Parser) isDone(prefixes []string) bool
func (p *Parser) startsWith(prefix any) bool
⋮----
var prefixes []string
⋮----
func (p *Parser) readStr(prefix string, returnEverything bool) string
⋮----
return "" // Changed from panic to return empty string for safer operation
⋮----
var text string
⋮----
func (p *Parser) Parse() error
func (p *Parser) parseUpdateFile(text string) (PatchAction, error)
func (p *Parser) parseAddFile() (PatchAction, error)
func findContextCore(lines []string, context []string, start int) (int, int)
func tryFindMatch(lines []string, context []string, start int,
	compareFunc func(string, string) bool,
) (int, int)
⋮----
var fuzz int
⋮----
func findContext(lines []string, context []string, start int, eof bool) (int, int)
func peekNextSection(lines []string, initialIndex int) ([]string, []Chunk, int, bool)
func TextToPatch(text string, orig map[string]string) (Patch, int, error)
func IdentifyFilesNeeded(text string) []string
func IdentifyFilesAdded(text string) []string
func getUpdatedFile(text string, action PatchAction, path string) (string, error)
func PatchToCommit(patch Patch, orig map[string]string) (Commit, error)
func AssembleChanges(orig map[string]string, updatedFiles map[string]string) Commit
⋮----
return commit // Changed from panic to simply return current commit
⋮----
func LoadFiles(paths []string, openFn func(string) (string, error)) (map[string]string, error)
func ApplyCommit(commit Commit, writeFn func(string, string) error, removeFn func(string) error) error
func ProcessPatch(text string, openFn func(string) (string, error), writeFn func(string, string) error, removeFn func(string) error) (string, error)
func OpenFile(p string) (string, error)
func WriteFile(p string, content string) error
func RemoveFile(p string) error
func ValidatePatch(patchText string, files map[string]string) (bool, string, error)
</file>

<file path="internal/llm/models/xai2.go">
package models
const (
	ProviderXAI2 ModelProvider = "xai2"
)
const (
	XAI2Grok4     ModelID = "xai2.grok-4"
	XAI2Grok40709 ModelID = "xai2.grok-4-0709"
	XAI2Grok3     ModelID = "xai2.grok-3"
	XAI2Grok3Beta ModelID = "xai2.grok-3-beta"
	XAI2Grok3Mini     ModelID = "xai2.grok-3-mini"
	XAI2Grok3MiniBeta ModelID = "xai2.grok-3-mini-beta"
	XAI2Grok3Fast     ModelID = "xai2.grok-3-fast"
	XAI2Grok3FastBeta ModelID = "xai2.grok-3-fast-beta"
	XAI2Grok3MiniFast ModelID = "xai2.grok-3-mini-fast"
	XAI2Grok3MiniFastBeta ModelID = "xai2.grok-3-mini-fast-beta"
	XAI2Grok2Vision     ModelID = "xai2.grok-2-vision"
	XAI2Grok2Vision1212 ModelID = "xai2.grok-2-vision-1212"
	XAI2Grok2Image     ModelID = "xai2.grok-2-image"
	XAI2Grok2Image1212 ModelID = "xai2.grok-2-image-1212"
)
var XAI2Models = map[ModelID]Model{
	XAI2Grok4: {
		ID:                 XAI2Grok4,
		Name:               "Grok 4",
		Provider:           ProviderXAI2,
		APIModel:           "grok-4-0709",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0.75,
		CostPer1MOut:       15.0,
		CostPer1MOutCached: 0,
		ContextWindow:      256_000,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok40709: {
		ID:                 XAI2Grok40709,
		Name:               "Grok 4 (0709)",
		Provider:           ProviderXAI2,
		APIModel:           "grok-4-0709",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0.75,
		CostPer1MOut:       15.0,
		CostPer1MOutCached: 0,
		ContextWindow:      256_000,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3: {
		ID:                 XAI2Grok3,
		Name:               "Grok 3",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0.75,
		CostPer1MOut:       15.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3Beta: {
		ID:                 XAI2Grok3Beta,
		Name:               "Grok 3 Beta",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-beta",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0.75,
		CostPer1MOut:       15.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3Mini: {
		ID:                 XAI2Grok3Mini,
		Name:               "Grok 3 Mini",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-mini",
		CostPer1MIn:        0.30,
		CostPer1MInCached:  0.075,
		CostPer1MOut:       0.50,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3MiniBeta: {
		ID:                 XAI2Grok3MiniBeta,
		Name:               "Grok 3 Mini Beta",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-mini-beta",
		CostPer1MIn:        0.30,
		CostPer1MInCached:  0.075,
		CostPer1MOut:       0.50,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3Fast: {
		ID:                 XAI2Grok3Fast,
		Name:               "Grok 3 Fast",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-fast",
		CostPer1MIn:        5.0,
		CostPer1MInCached:  1.25,
		CostPer1MOut:       25.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3FastBeta: {
		ID:                 XAI2Grok3FastBeta,
		Name:               "Grok 3 Fast Beta",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-fast-beta",
		CostPer1MIn:        5.0,
		CostPer1MInCached:  1.25,
		CostPer1MOut:       25.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3MiniFast: {
		ID:                 XAI2Grok3MiniFast,
		Name:               "Grok 3 Mini Fast",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-mini-fast",
		CostPer1MIn:        0.60,
		CostPer1MInCached:  0.15,
		CostPer1MOut:       4.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok3MiniFastBeta: {
		ID:                 XAI2Grok3MiniFastBeta,
		Name:               "Grok 3 Mini Fast Beta",
		Provider:           ProviderXAI2,
		APIModel:           "grok-3-mini-fast-beta",
		CostPer1MIn:        0.60,
		CostPer1MInCached:  0.15,
		CostPer1MOut:       4.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok2Vision: {
		ID:                 XAI2Grok2Vision,
		Name:               "Grok 2 Vision",
		Provider:           ProviderXAI2,
		APIModel:           "grok-2-vision-1212",
		CostPer1MIn:        2.0,
		CostPer1MInCached:  0,
		CostPer1MOut:       10.0,
		CostPer1MOutCached: 0,
		ContextWindow:      32_768,
		DefaultMaxTokens:   8_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok2Vision1212: {
		ID:                 XAI2Grok2Vision1212,
		Name:               "Grok 2 Vision (1212)",
		Provider:           ProviderXAI2,
		APIModel:           "grok-2-vision-1212",
		CostPer1MIn:        2.0,
		CostPer1MInCached:  0,
		CostPer1MOut:       10.0,
		CostPer1MOutCached: 0,
		ContextWindow:      32_768,
		DefaultMaxTokens:   8_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	XAI2Grok2Image: {
		ID:                 XAI2Grok2Image,
		Name:               "Grok 2 Image",
		Provider:           ProviderXAI2,
		APIModel:           "grok-2-image-1212",
		CostPer1MIn:        0,
		CostPer1MInCached:  0,
		CostPer1MOut:       0,
		CostPer1MOutCached: 0,
		ContextWindow:      0,
		DefaultMaxTokens:   0,
	},
	XAI2Grok2Image1212: {
		ID:                 XAI2Grok2Image1212,
		Name:               "Grok 2 Image (1212)",
		Provider:           ProviderXAI2,
		APIModel:           "grok-2-image-1212",
		CostPer1MIn:        0,
		CostPer1MInCached:  0,
		CostPer1MOut:       0,
		CostPer1MOutCached: 0,
		ContextWindow:      0,
		DefaultMaxTokens:   0,
	},
}
var XAI2ModelAliases = map[string]ModelID{
	"xai2.grok-4":        XAI2Grok40709,
	"xai2.grok-4-latest": XAI2Grok40709,
	"xai2.grok-3-latest": XAI2Grok3,
	"xai2.grok-3-beta":   XAI2Grok3Beta,
	"xai2.grok-3-fast-latest": XAI2Grok3Fast,
	"xai2.grok-3-fast-beta":   XAI2Grok3FastBeta,
	"xai2.grok-3-mini-latest": XAI2Grok3Mini,
	"xai2.grok-3-mini-beta":   XAI2Grok3MiniBeta,
	"xai2.grok-3-mini-fast-latest": XAI2Grok3MiniFast,
	"xai2.grok-3-mini-fast-beta":   XAI2Grok3MiniFastBeta,
	"xai2.grok-2-vision":        XAI2Grok2Vision1212,
	"xai2.grok-2-vision-latest": XAI2Grok2Vision1212,
	"xai2.grok-2-image":        XAI2Grok2Image1212,
	"xai2.grok-2-image-latest": XAI2Grok2Image1212,
}
</file>

<file path="internal/llm/provider/xai.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/option"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"os"
"path/filepath"
"strings"
"time"
"github.com/openai/openai-go"
"github.com/openai/openai-go/option"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
⋮----
type xaiClient struct {
	*openaiClient
}
type XAIClient ProviderClient
type xaiContentError struct {
	StatusCode int
	Content    string
}
func (e *xaiContentError) Error() string
var xaiErrorPatterns = []string{
	"try again",
	"rate limit",
	"too many requests",
	"please retry",
	"service unavailable",
	"quota exceeded",
	"temporarily unavailable",
}
func newXAIClient(opts providerClientOptions) XAIClient
// Override convertMessages to reload Grok prompt from file on each request
func (x *xaiClient) convertMessages(messages []message.Message) []openai.ChatCompletionMessageParamUnion
⋮----
// Reload the system message from file for Grok models
⋮----
// Call the parent implementation
⋮----
func (x *xaiClient) loadExternalGrokPrompt() string
// isErrorContent checks if the response content matches known error patterns
func (x *xaiClient) isErrorContent(content string) bool
// Override preparedParams to filter out unsupported parameters for xAI
func (x *xaiClient) preparedParams(messages []openai.ChatCompletionMessageParamUnion, tools []openai.ChatCompletionToolParam) openai.ChatCompletionNewParams
⋮----
// Log request info if debug logging is enabled
⋮----
func (x *xaiClient) send(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
func (x *xaiClient) sendWithParams(ctx context.Context, params openai.ChatCompletionNewParams) (*ProviderResponse, error)
func (x *xaiClient) stream(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
func (x *xaiClient) wrapStreamEvents(baseEvents <-chan ProviderEvent) <-chan ProviderEvent
⋮----
var accumulatedContent strings.Builder
var bufferedEvents []ProviderEvent
var isBuffering bool
⋮----
func (x *xaiClient) shouldRetry(attempts int, err error) (bool, int64, error)
⋮----
var xaiErr *xaiContentError
⋮----
var apierr *openai.Error
⋮----
func (x *xaiClient) streamWithParams(ctx context.Context, params openai.ChatCompletionNewParams) <-chan ProviderEvent
⋮----
var streamErr error
// Process stream chunks
⋮----
// Check for error
⋮----
// Log the error
⋮----
func (x *xaiClient) finishReason(reason string) message.FinishReason
func (x *xaiClient) toolCalls(completion openai.ChatCompletion) []message.ToolCall
func (x *xaiClient) usage(completion openai.ChatCompletion) TokenUsage
func (x *xaiClient) logError(err error, params openai.ChatCompletionNewParams)
⋮----
var xaiErr *xaiContentError
⋮----
var apierr *openai.Error
⋮----
func (x *xaiClient) getConfig() *config.Config
func (x *xaiClient) getLogPath() string
// logRequest logs request information to the debug log
func (x *xaiClient) logRequest(provider, model string, hasTools bool)
</file>

<file path="internal/llm/provider/xai2.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/option"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"os"
"path/filepath"
"strings"
"time"
"github.com/openai/openai-go"
"github.com/openai/openai-go/option"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
⋮----
const (
	xai2MaxRetries = 8
	quotaExceededPattern = "credits or reached its monthly spending limit"
)
var xai2ErrorPatterns = []string{
	"try again",
	"rate limit",
	"too many requests",
	"please retry",
	"service unavailable",
	"quota exceeded",
	"temporarily unavailable",
}
type xai2Client struct {
	client           openai.Client
	options          openaiOptions
	providerOptions  providerClientOptions
}
type xai2ContentError struct {
	StatusCode int
	Content    string
}
func (e *xai2ContentError) Error() string
func NewXAI2Client(apiKey string, providerOptions providerClientOptions) (*xai2Client, error)
// Provider interface methods
func (x *xai2Client) SendMessages(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
⋮----
// Set current request info for display
⋮----
func (x *xai2Client) StreamResponse(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
// streamWithParams implements custom retry logic for xAI
func (x *xai2Client) streamWithParams(ctx context.Context, params openai.ChatCompletionNewParams) <-chan ProviderEvent
⋮----
// Debug logging
⋮----
var streamErr error
// Process stream chunks
⋮----
// Check if content looks like an error
⋮----
StatusCode: 200, // Assume 200 since it came as content
⋮----
// Check for stream error
⋮----
// Debug logging
⋮----
func (x *xai2Client) Model() models.Model
func (x *xai2Client) shouldRetry(attempts int, err error) (bool, int64, error)
⋮----
var xaiErr *xai2ContentError
⋮----
var apierr *openai.Error
⋮----
func (x *xai2Client) isErrorContent(content string) bool
// Helper methods
func (x *xai2Client) convertMessages(messages []message.Message) []openai.ChatCompletionMessageParamUnion
func (x *xai2Client) convertMessage(msg message.Message) openai.ChatCompletionMessageParamUnion
func (x *xai2Client) convertTools(tools []tools.BaseTool) []openai.ChatCompletionToolParam
func (x *xai2Client) preparedParams(messages []openai.ChatCompletionMessageParamUnion, tools []openai.ChatCompletionToolParam) openai.ChatCompletionNewParams
func (x *xai2Client) toProviderResponse(completion openai.ChatCompletion) *ProviderResponse
⋮----
var content string
var toolCalls []message.ToolCall
⋮----
func (x *xai2Client) finishReason(reason string) message.FinishReason
func (x *xai2Client) toolCalls(completion openai.ChatCompletion) []message.ToolCall
func (x *xai2Client) usage(completion openai.ChatCompletion) TokenUsage
func (x *xai2Client) isDebugMode() bool
func (x *xai2Client) logDebug(format string, args ...interface
func (x *xai2Client) logRequest()
func (x *xai2Client) logError(err error, params openai.ChatCompletionNewParams)
</file>

<file path="internal/llm/tools/file.go">
package tools
import (
	"sync"
	"time"
)
⋮----
"sync"
"time"
⋮----
type fileRecord struct {
	path      string
	readTime  time.Time
	writeTime time.Time
}
var (
	fileRecords     = make(map[string]fileRecord)
func recordFileRead(path string)
func getLastReadTime(path string) time.Time
func recordFileWrite(path string)
</file>

<file path="internal/llm/tools/sourcegraph.go">
package tools
import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"
)
⋮----
"bytes"
"context"
"encoding/json"
"fmt"
"io"
"net/http"
"strings"
"time"
⋮----
type SourcegraphParams struct {
	Query         string `json:"query"`
	Count         int    `json:"count,omitempty"`
	ContextWindow int    `json:"context_window,omitempty"`
	Timeout       int    `json:"timeout,omitempty"`
}
type SourcegraphResponseMetadata struct {
	NumberOfMatches int  `json:"number_of_matches"`
	Truncated       bool `json:"truncated"`
}
type sourcegraphTool struct {
	client *http.Client
}
const (
	SourcegraphToolName        = "sourcegraph"
	sourcegraphToolDescription = `Search code across public repositories using Sourcegraph's GraphQL API.
WHEN TO USE THIS TOOL:
- Use when you need to find code examples or implementations across public repositories
- Helpful for researching how others have solved similar problems
- Useful for discovering patterns and best practices in open source code
HOW TO USE:
- Provide a search query using Sourcegraph's query syntax
- Optionally specify the number of results to return (default: 10)
func NewSourcegraphTool() BaseTool
func (t *sourcegraphTool) Info() ToolInfo
func (t *sourcegraphTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params SourcegraphParams
⋮----
type graphqlRequest struct {
		Query     string `json:"query"`
		Variables struct {
			Query string `json:"query"`
		} `json:"variables"`
⋮----
var result map[string]any
⋮----
func formatSourcegraphResults(result map[string]any, contextWindow int) (string, error)
⋮----
var buffer strings.Builder
</file>

<file path="internal/llm/tools/tools.go">
package tools
import (
	"context"
	"encoding/json"
)
⋮----
"context"
"encoding/json"
⋮----
type ToolInfo struct {
	Name        string
	Description string
	Parameters  map[string]any
	Required    []string
}
type toolResponseType string
⋮----
sessionIDContextKey string
messageIDContextKey string
⋮----
const (
	ToolResponseTypeText  toolResponseType = "text"
	ToolResponseTypeImage toolResponseType = "image"
	SessionIDContextKey sessionIDContextKey = "session_id"
	MessageIDContextKey messageIDContextKey = "message_id"
)
type ToolResponse struct {
	Type     toolResponseType `json:"type"`
	Content  string           `json:"content"`
	Metadata string           `json:"metadata,omitempty"`
	IsError  bool             `json:"is_error"`
}
func NewTextResponse(content string) ToolResponse
func WithResponseMetadata(response ToolResponse, metadata any) ToolResponse
func NewTextErrorResponse(content string) ToolResponse
type ToolCall struct {
	ID    string `json:"id"`
	Name  string `json:"name"`
	Input string `json:"input"`
}
type BaseTool interface {
	Info() ToolInfo
	Run(ctx context.Context, params ToolCall) (ToolResponse, error)
}
func GetContextValues(ctx context.Context) (string, string)
</file>

<file path="internal/logging/message.go">
package logging
import (
	"time"
)
⋮----
"time"
⋮----
type LogMessage struct {
	ID          string
	Time        time.Time
	Level       string
	Persist     bool
	PersistTime time.Duration
	Message     string        `json:"msg"`
	Attributes  []Attr
}
type Attr struct {
	Key   string
	Value string
}
</file>

<file path="internal/lsp/protocol/interface.go">
package protocol
import "fmt"
type WorkspaceSymbolResult interface {
	GetName() string
	GetLocation() Location
	isWorkspaceSymbol()
}
func (ws *WorkspaceSymbol) GetName() string
func (ws *WorkspaceSymbol) GetLocation() Location
func (ws *WorkspaceSymbol) isWorkspaceSymbol()
⋮----
func (r Or_Result_workspace_symbol) Results() ([]WorkspaceSymbolResult, error)
type DocumentSymbolResult interface {
	GetRange() Range
	GetName() string
	isDocumentSymbol()
}
func (ds *DocumentSymbol) GetRange() Range
⋮----
func (ds *DocumentSymbol) isDocumentSymbol()
⋮----
type TextEditResult interface {
	GetRange() Range
	GetNewText() string
	isTextEdit()
}
⋮----
func (te *TextEdit) GetNewText() string
func (te *TextEdit) isTextEdit()
func (e Or_TextDocumentEdit_edits_Elem) AsTextEdit() (TextEdit, error)
</file>

<file path="internal/lsp/protocol/pattern_interfaces.go">
package protocol
import (
	"fmt"
	"strings"
)
⋮----
"fmt"
"strings"
⋮----
type PatternInfo interface {
	GetPattern() string
	GetBasePath() string
	isPattern()
}
type StringPattern struct {
	Pattern string
}
func (p StringPattern) GetPattern() string
func (p StringPattern) GetBasePath() string
func (p StringPattern) isPattern()
// RelativePatternInfo implements PatternInfo for RelativePattern
type RelativePatternInfo struct {
	RP       RelativePattern
	BasePath string
}
⋮----
// AsPattern converts GlobPattern to a PatternInfo object
func (g *GlobPattern) AsPattern() (PatternInfo, error)
</file>

<file path="internal/lsp/protocol/tables.go">
package protocol
var TableKindMap = map[SymbolKind]string{
	File:          "File",
	Module:        "Module",
	Namespace:     "Namespace",
	Package:       "Package",
	Class:         "Class",
	Method:        "Method",
	Property:      "Property",
	Field:         "Field",
	Constructor:   "Constructor",
	Enum:          "Enum",
	Interface:     "Interface",
	Function:      "Function",
	Variable:      "Variable",
	Constant:      "Constant",
	String:        "String",
	Number:        "Number",
	Boolean:       "Boolean",
	Array:         "Array",
	Object:        "Object",
	Key:           "Key",
	Null:          "Null",
	EnumMember:    "EnumMember",
	Struct:        "Struct",
	Event:         "Event",
	Operator:      "Operator",
	TypeParameter: "TypeParameter",
}
</file>

<file path="internal/lsp/protocol/tsdocument-changes.go">
package protocol
import (
	"encoding/json"
	"fmt"
)
⋮----
"encoding/json"
"fmt"
⋮----
type DocumentChange struct {
	TextDocumentEdit *TextDocumentEdit
	CreateFile       *CreateFile
	RenameFile       *RenameFile
	DeleteFile       *DeleteFile
}
func (ch DocumentChange) Valid() bool
func (d *DocumentChange) UnmarshalJSON(data []byte) error
⋮----
var m map[string]any
⋮----
func (d *DocumentChange) MarshalJSON() ([]byte, error)
</file>

<file path="internal/lsp/protocol/tsjson.go">
package protocol
import "bytes"
import "encoding/json"
import "fmt"
type UnmarshalError struct {
	msg string
}
func (e UnmarshalError) Error() string
func (t Or_CancelParams_id) MarshalJSON() ([]byte, error)
func (t *Or_CancelParams_id) UnmarshalJSON(x []byte) error
⋮----
var int32Val int32
⋮----
var stringVal string
⋮----
var boolVal bool
⋮----
var h221 ClientSemanticTokensRequestFullDelta
⋮----
var h218 Lit_ClientSemanticTokensRequestOptions_range_Item1
⋮----
var h183 EditRangeWithInsertReplace
⋮----
var h184 Range
⋮----
var h26 MarkupContent
⋮----
var h29 InsertReplaceEdit
⋮----
var h30 TextEdit
⋮----
var h237 Location
⋮----
var h238 []Location
⋮----
var h224 Location
⋮----
var h225 []Location
⋮----
var h23 []string
⋮----
var h247 RelatedFullDocumentDiagnosticReport
⋮----
var h248 RelatedUnchangedDocumentDiagnosticReport
⋮----
var h16 FullDocumentDiagnosticReport
⋮----
var h17 UnchangedDocumentDiagnosticReport
⋮----
var h270 NotebookCellTextDocumentFilter
⋮----
var h271 TextDocumentFilter
⋮----
var h274 Pattern
⋮----
var h275 RelativePattern
⋮----
var h34 MarkedString
⋮----
var h35 MarkupContent
⋮----
var h36 []MarkedString
⋮----
var h57 MarkupContent
⋮----
var h10 []InlayHintLabelPart
⋮----
var h13 MarkupContent
⋮----
var h20 StringValue
⋮----
var h242 InlineValueEvaluatableExpression
⋮----
var h243 InlineValueText
⋮----
var h244 InlineValueVariableLookup
⋮----
var float64Val float64
⋮----
var uint32Val uint32
⋮----
var h233 LSPArray
⋮----
var h234 LSPObject
⋮----
var h267 MarkedStringWithLanguage
⋮----
var h209 NotebookDocumentFilter
⋮----
var h285 NotebookDocumentFilterNotebookType
⋮----
var h286 NotebookDocumentFilterPattern
⋮----
var h287 NotebookDocumentFilterScheme
⋮----
var h193 NotebookDocumentFilter
⋮----
var h190 NotebookDocumentFilter
⋮----
var h68 NotebookDocumentFilterWithCells
⋮----
var h69 NotebookDocumentFilterWithNotebook
⋮----
var h206 MarkupContent
⋮----
var h203 Tuple_ParameterInformation_label_Item1
⋮----
var h252 PrepareRenameDefaultBehavior
⋮----
var h253 PrepareRenamePlaceholder
⋮----
var h254 Range
⋮----
var h60 FullDocumentDiagnosticReport
⋮----
var h61 UnchangedDocumentDiagnosticReport
⋮----
var h64 FullDocumentDiagnosticReport
⋮----
var h65 UnchangedDocumentDiagnosticReport
⋮----
var h214 URI
⋮----
var h215 WorkspaceFolder
⋮----
var h322 CodeAction
⋮----
var h323 Command
⋮----
var h310 CompletionList
⋮----
var h311 []CompletionItem
⋮----
var h298 Declaration
⋮----
var h299 []DeclarationLink
⋮----
var h314 Definition
⋮----
var h315 []DefinitionLink
⋮----
var h318 []DocumentSymbol
⋮----
var h319 []SymbolInformation
⋮----
var h290 Definition
⋮----
var h291 []DefinitionLink
⋮----
var h306 InlineCompletionList
⋮----
var h307 []InlineCompletionItem
⋮----
var h302 SemanticTokens
⋮----
var h303 SemanticTokensDelta
⋮----
var h294 Definition
⋮----
var h295 []DefinitionLink
⋮----
var h326 []SymbolInformation
⋮----
var h327 []WorkspaceSymbol
⋮----
var h48 SemanticTokensFullDelta
⋮----
var h45 Lit_SemanticTokensOptions_range_Item1
⋮----
var h141 CallHierarchyOptions
⋮----
var h142 CallHierarchyRegistrationOptions
⋮----
var h110 CodeActionOptions
⋮----
var h114 DocumentColorOptions
⋮----
var h115 DocumentColorRegistrationOptions
⋮----
var h84 DeclarationOptions
⋮----
var h85 DeclarationRegistrationOptions
⋮----
var h88 DefinitionOptions
⋮----
var h174 DiagnosticOptions
⋮----
var h175 DiagnosticRegistrationOptions
⋮----
var h121 DocumentFormattingOptions
⋮----
var h104 DocumentHighlightOptions
⋮----
var h124 DocumentRangeFormattingOptions
⋮----
var h107 DocumentSymbolOptions
⋮----
var h131 FoldingRangeOptions
⋮----
var h132 FoldingRangeRegistrationOptions
⋮----
var h80 HoverOptions
⋮----
var h97 ImplementationOptions
⋮----
var h98 ImplementationRegistrationOptions
⋮----
var h170 InlayHintOptions
⋮----
var h171 InlayHintRegistrationOptions
⋮----
var h178 InlineCompletionOptions
⋮----
var h165 InlineValueOptions
⋮----
var h166 InlineValueRegistrationOptions
⋮----
var h146 LinkedEditingRangeOptions
⋮----
var h147 LinkedEditingRangeRegistrationOptions
⋮----
var h155 MonikerOptions
⋮----
var h156 MonikerRegistrationOptions
⋮----
var h76 NotebookDocumentSyncOptions
⋮----
var h77 NotebookDocumentSyncRegistrationOptions
⋮----
var h101 ReferenceOptions
⋮----
var h127 RenameOptions
⋮----
var h136 SelectionRangeOptions
⋮----
var h137 SelectionRangeRegistrationOptions
⋮----
var h150 SemanticTokensOptions
⋮----
var h151 SemanticTokensRegistrationOptions
⋮----
var h72 TextDocumentSyncKind
⋮----
var h73 TextDocumentSyncOptions
⋮----
var h92 TypeDefinitionOptions
⋮----
var h93 TypeDefinitionRegistrationOptions
⋮----
var h160 TypeHierarchyOptions
⋮----
var h161 TypeHierarchyRegistrationOptions
⋮----
var h118 WorkspaceSymbolOptions
⋮----
var h187 MarkupContent
⋮----
var h263 TextDocumentContentChangePartial
⋮----
var h264 TextDocumentContentChangeWholeDocument
⋮----
var h52 AnnotatedTextEdit
⋮----
var h53 SnippetTextEdit
⋮----
var h54 TextEdit
⋮----
var h279 TextDocumentFilterLanguage
⋮----
var h280 TextDocumentFilterPattern
⋮----
var h281 TextDocumentFilterScheme
⋮----
var h196 SaveOptions
⋮----
var h259 WorkspaceFullDocumentDiagnosticReport
⋮----
var h260 WorkspaceUnchangedDocumentDiagnosticReport
⋮----
var h4 CreateFile
⋮----
var h5 DeleteFile
⋮----
var h6 RenameFile
⋮----
var h7 TextDocumentEdit
⋮----
var h199 TextDocumentContentOptions
⋮----
var h200 TextDocumentContentRegistrationOptions
⋮----
var h39 Location
⋮----
var h40 LocationUriOnly
</file>

<file path="internal/lsp/protocol/tsprotocol.go">
package protocol
import "encoding/json"
type And_RegOpt_textDocument_colorPresentation struct {
	WorkDoneProgressOptions
	TextDocumentRegistrationOptions
}
type AnnotatedTextEdit struct {
	AnnotationID *ChangeAnnotationIdentifier `json:"annotationId,omitempty"`
	TextEdit
}
type ApplyWorkspaceEditParams struct {
	Label string `json:"label,omitempty"`
	Edit WorkspaceEdit `json:"edit"`
	Metadata *WorkspaceEditMetadata `json:"metadata,omitempty"`
}
type ApplyWorkspaceEditResult struct {
	Applied bool `json:"applied"`
	FailureReason string `json:"failureReason,omitempty"`
	FailedChange uint32 `json:"failedChange,omitempty"`
}
type BaseSymbolInformation struct {
	Name string `json:"name"`
	Kind SymbolKind `json:"kind"`
	Tags []SymbolTag `json:"tags,omitempty"`
	ContainerName string `json:"containerName,omitempty"`
}
type CallHierarchyClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type CallHierarchyIncomingCall struct {
	From CallHierarchyItem `json:"from"`
	FromRanges []Range `json:"fromRanges"`
}
type CallHierarchyIncomingCallsParams struct {
	Item CallHierarchyItem `json:"item"`
	WorkDoneProgressParams
	PartialResultParams
}
type CallHierarchyItem struct {
	Name string `json:"name"`
	Kind SymbolKind `json:"kind"`
	Tags []SymbolTag `json:"tags,omitempty"`
	Detail string `json:"detail,omitempty"`
	URI DocumentUri `json:"uri"`
	Range Range `json:"range"`
	SelectionRange Range `json:"selectionRange"`
	Data interface{} `json:"data,omitempty"`
type CallHierarchyOptions struct {
	WorkDoneProgressOptions
}
type CallHierarchyOutgoingCall struct {
	To CallHierarchyItem `json:"to"`
	FromRanges []Range `json:"fromRanges"`
}
type CallHierarchyOutgoingCallsParams struct {
	Item CallHierarchyItem `json:"item"`
	WorkDoneProgressParams
	PartialResultParams
}
type CallHierarchyPrepareParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type CallHierarchyRegistrationOptions struct {
	TextDocumentRegistrationOptions
	CallHierarchyOptions
	StaticRegistrationOptions
}
type CancelParams struct {
	ID interface{} `json:"id"`
type ChangeAnnotation struct {
	Label string `json:"label"`
	NeedsConfirmation bool `json:"needsConfirmation,omitempty"`
	Description string `json:"description,omitempty"`
}
⋮----
type ChangeAnnotationsSupportOptions struct {
	GroupsOnLabel bool `json:"groupsOnLabel,omitempty"`
}
type ClientCapabilities struct {
	Workspace WorkspaceClientCapabilities `json:"workspace,omitempty"`
	TextDocument TextDocumentClientCapabilities `json:"textDocument,omitempty"`
	NotebookDocument *NotebookDocumentClientCapabilities `json:"notebookDocument,omitempty"`
	Window WindowClientCapabilities `json:"window,omitempty"`
	General *GeneralClientCapabilities `json:"general,omitempty"`
	Experimental interface{} `json:"experimental,omitempty"`
type ClientCodeActionKindOptions struct {
	ValueSet []CodeActionKind `json:"valueSet"`
}
type ClientCodeActionLiteralOptions struct {
	CodeActionKind ClientCodeActionKindOptions `json:"codeActionKind"`
}
type ClientCodeActionResolveOptions struct {
	Properties []string `json:"properties"`
}
type ClientCodeLensResolveOptions struct {
	Properties []string `json:"properties"`
}
type ClientCompletionItemInsertTextModeOptions struct {
	ValueSet []InsertTextMode `json:"valueSet"`
}
type ClientCompletionItemOptions struct {
	SnippetSupport bool `json:"snippetSupport,omitempty"`
	CommitCharactersSupport bool `json:"commitCharactersSupport,omitempty"`
	DocumentationFormat []MarkupKind `json:"documentationFormat,omitempty"`
	DeprecatedSupport bool `json:"deprecatedSupport,omitempty"`
	PreselectSupport bool `json:"preselectSupport,omitempty"`
	TagSupport *CompletionItemTagOptions `json:"tagSupport,omitempty"`
	InsertReplaceSupport bool `json:"insertReplaceSupport,omitempty"`
	ResolveSupport *ClientCompletionItemResolveOptions `json:"resolveSupport,omitempty"`
	InsertTextModeSupport *ClientCompletionItemInsertTextModeOptions `json:"insertTextModeSupport,omitempty"`
	LabelDetailsSupport bool `json:"labelDetailsSupport,omitempty"`
}
type ClientCompletionItemOptionsKind struct {
	ValueSet []CompletionItemKind `json:"valueSet,omitempty"`
}
type ClientCompletionItemResolveOptions struct {
	Properties []string `json:"properties"`
}
type ClientDiagnosticsTagOptions struct {
	ValueSet []DiagnosticTag `json:"valueSet"`
}
type ClientFoldingRangeKindOptions struct {
	ValueSet []FoldingRangeKind `json:"valueSet,omitempty"`
}
type ClientFoldingRangeOptions struct {
	CollapsedText bool `json:"collapsedText,omitempty"`
}
type ClientInfo struct {
	Name string `json:"name"`
	Version string `json:"version,omitempty"`
}
type ClientInlayHintResolveOptions struct {
	Properties []string `json:"properties"`
}
type ClientSemanticTokensRequestFullDelta struct {
	Delta bool `json:"delta,omitempty"`
}
type ClientSemanticTokensRequestOptions struct {
	Range *Or_ClientSemanticTokensRequestOptions_range `json:"range,omitempty"`
	Full *Or_ClientSemanticTokensRequestOptions_full `json:"full,omitempty"`
}
type ClientShowMessageActionItemOptions struct {
	AdditionalPropertiesSupport bool `json:"additionalPropertiesSupport,omitempty"`
}
type ClientSignatureInformationOptions struct {
	DocumentationFormat []MarkupKind `json:"documentationFormat,omitempty"`
	ParameterInformation *ClientSignatureParameterInformationOptions `json:"parameterInformation,omitempty"`
	ActiveParameterSupport bool `json:"activeParameterSupport,omitempty"`
	NoActiveParameterSupport bool `json:"noActiveParameterSupport,omitempty"`
}
type ClientSignatureParameterInformationOptions struct {
	LabelOffsetSupport bool `json:"labelOffsetSupport,omitempty"`
}
type ClientSymbolKindOptions struct {
	ValueSet []SymbolKind `json:"valueSet,omitempty"`
}
type ClientSymbolResolveOptions struct {
	Properties []string `json:"properties"`
}
type ClientSymbolTagOptions struct {
	ValueSet []SymbolTag `json:"valueSet"`
}
type CodeAction struct {
	Title string `json:"title"`
	Kind CodeActionKind `json:"kind,omitempty"`
	Diagnostics []Diagnostic `json:"diagnostics,omitempty"`
	IsPreferred bool `json:"isPreferred,omitempty"`
	Disabled *CodeActionDisabled `json:"disabled,omitempty"`
	Edit *WorkspaceEdit `json:"edit,omitempty"`
	Command *Command `json:"command,omitempty"`
	Data *json.RawMessage `json:"data,omitempty"`
}
type CodeActionClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	CodeActionLiteralSupport ClientCodeActionLiteralOptions `json:"codeActionLiteralSupport,omitempty"`
	IsPreferredSupport bool `json:"isPreferredSupport,omitempty"`
	DisabledSupport bool `json:"disabledSupport,omitempty"`
	DataSupport bool `json:"dataSupport,omitempty"`
	ResolveSupport *ClientCodeActionResolveOptions `json:"resolveSupport,omitempty"`
	HonorsChangeAnnotations bool `json:"honorsChangeAnnotations,omitempty"`
	DocumentationSupport bool `json:"documentationSupport,omitempty"`
}
type CodeActionContext struct {
	Diagnostics []Diagnostic `json:"diagnostics"`
	Only []CodeActionKind `json:"only,omitempty"`
	TriggerKind *CodeActionTriggerKind `json:"triggerKind,omitempty"`
}
type CodeActionDisabled struct {
	Reason string `json:"reason"`
}
type CodeActionKind string
type CodeActionKindDocumentation struct {
	Kind CodeActionKind `json:"kind"`
	Command Command `json:"command"`
}
type CodeActionOptions struct {
	CodeActionKinds []CodeActionKind `json:"codeActionKinds,omitempty"`
	Documentation []CodeActionKindDocumentation `json:"documentation,omitempty"`
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	WorkDoneProgressOptions
}
type CodeActionParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range Range `json:"range"`
	Context CodeActionContext `json:"context"`
	WorkDoneProgressParams
	PartialResultParams
}
type CodeActionRegistrationOptions struct {
	TextDocumentRegistrationOptions
	CodeActionOptions
}
type CodeActionTriggerKind uint32
type CodeDescription struct {
	Href URI `json:"href"`
}
type CodeLens struct {
	Range Range `json:"range"`
	Command *Command `json:"command,omitempty"`
	Data interface{} `json:"data,omitempty"`
type CodeLensClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	ResolveSupport *ClientCodeLensResolveOptions `json:"resolveSupport,omitempty"`
}
type CodeLensOptions struct {
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	WorkDoneProgressOptions
}
type CodeLensParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type CodeLensRegistrationOptions struct {
	TextDocumentRegistrationOptions
	CodeLensOptions
}
type CodeLensWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type Color struct {
	Red float64 `json:"red"`
	Green float64 `json:"green"`
	Blue float64 `json:"blue"`
	Alpha float64 `json:"alpha"`
}
type ColorInformation struct {
	Range Range `json:"range"`
	Color Color `json:"color"`
}
type ColorPresentation struct {
	Label string `json:"label"`
	TextEdit *TextEdit `json:"textEdit,omitempty"`
	AdditionalTextEdits []TextEdit `json:"additionalTextEdits,omitempty"`
}
type ColorPresentationParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Color Color `json:"color"`
	Range Range `json:"range"`
	WorkDoneProgressParams
	PartialResultParams
}
type Command struct {
	Title string `json:"title"`
	Tooltip string `json:"tooltip,omitempty"`
	Command string `json:"command"`
	Arguments []json.RawMessage `json:"arguments,omitempty"`
}
type CompletionClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	CompletionItem     ClientCompletionItemOptions      `json:"completionItem,omitempty"`
	CompletionItemKind *ClientCompletionItemOptionsKind `json:"completionItemKind,omitempty"`
	InsertTextMode InsertTextMode `json:"insertTextMode,omitempty"`
	ContextSupport bool `json:"contextSupport,omitempty"`
	CompletionList *CompletionListCapabilities `json:"completionList,omitempty"`
}
type CompletionContext struct {
	TriggerKind CompletionTriggerKind `json:"triggerKind"`
	TriggerCharacter string `json:"triggerCharacter,omitempty"`
}
type CompletionItem struct {
	Label string `json:"label"`
	LabelDetails *CompletionItemLabelDetails `json:"labelDetails,omitempty"`
	Kind CompletionItemKind `json:"kind,omitempty"`
	Tags []CompletionItemTag `json:"tags,omitempty"`
	Detail string `json:"detail,omitempty"`
	Documentation *Or_CompletionItem_documentation `json:"documentation,omitempty"`
	Deprecated bool `json:"deprecated,omitempty"`
	Preselect bool `json:"preselect,omitempty"`
	SortText string `json:"sortText,omitempty"`
	FilterText string `json:"filterText,omitempty"`
	InsertText string `json:"insertText,omitempty"`
	InsertTextFormat *InsertTextFormat `json:"insertTextFormat,omitempty"`
	InsertTextMode *InsertTextMode `json:"insertTextMode,omitempty"`
	TextEdit *Or_CompletionItem_textEdit `json:"textEdit,omitempty"`
	TextEditText string `json:"textEditText,omitempty"`
	AdditionalTextEdits []TextEdit `json:"additionalTextEdits,omitempty"`
	CommitCharacters []string `json:"commitCharacters,omitempty"`
	Command *Command `json:"command,omitempty"`
	Data interface{} `json:"data,omitempty"`
type CompletionItemDefaults struct {
	CommitCharacters []string `json:"commitCharacters,omitempty"`
	EditRange *Or_CompletionItemDefaults_editRange `json:"editRange,omitempty"`
	InsertTextFormat *InsertTextFormat `json:"insertTextFormat,omitempty"`
	InsertTextMode *InsertTextMode `json:"insertTextMode,omitempty"`
	Data interface{} `json:"data,omitempty"`
type CompletionItemKind uint32
type CompletionItemLabelDetails struct {
	Detail string `json:"detail,omitempty"`
	Description string `json:"description,omitempty"`
}
type CompletionItemTag uint32
type CompletionItemTagOptions struct {
	ValueSet []CompletionItemTag `json:"valueSet"`
}
type CompletionList struct {
	IsIncomplete bool `json:"isIncomplete"`
	ItemDefaults *CompletionItemDefaults `json:"itemDefaults,omitempty"`
	Items []CompletionItem `json:"items"`
}
type CompletionListCapabilities struct {
	ItemDefaults []string `json:"itemDefaults,omitempty"`
}
type CompletionOptions struct {
	TriggerCharacters []string `json:"triggerCharacters,omitempty"`
	AllCommitCharacters []string `json:"allCommitCharacters,omitempty"`
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	CompletionItem *ServerCompletionItemOptions `json:"completionItem,omitempty"`
	WorkDoneProgressOptions
}
type CompletionParams struct {
	Context CompletionContext `json:"context,omitempty"`
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type CompletionRegistrationOptions struct {
	TextDocumentRegistrationOptions
	CompletionOptions
}
type CompletionTriggerKind uint32
type ConfigurationItem struct {
	ScopeURI *URI `json:"scopeUri,omitempty"`
	Section string `json:"section,omitempty"`
}
type ConfigurationParams struct {
	Items []ConfigurationItem `json:"items"`
}
type CreateFile struct {
	Kind string `json:"kind"`
	URI DocumentUri `json:"uri"`
	Options *CreateFileOptions `json:"options,omitempty"`
	ResourceOperation
}
type CreateFileOptions struct {
	Overwrite bool `json:"overwrite,omitempty"`
	IgnoreIfExists bool `json:"ignoreIfExists,omitempty"`
}
type CreateFilesParams struct {
	Files []FileCreate `json:"files"`
}
⋮----
type DeclarationClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	LinkSupport bool `json:"linkSupport,omitempty"`
}
⋮----
type DeclarationOptions struct {
	WorkDoneProgressOptions
}
type DeclarationParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type DeclarationRegistrationOptions struct {
	DeclarationOptions
	TextDocumentRegistrationOptions
	StaticRegistrationOptions
}
⋮----
type DefinitionClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	LinkSupport bool `json:"linkSupport,omitempty"`
}
⋮----
type DefinitionOptions struct {
	WorkDoneProgressOptions
}
type DefinitionParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type DefinitionRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DefinitionOptions
}
type DeleteFile struct {
	Kind string `json:"kind"`
	URI DocumentUri `json:"uri"`
	Options *DeleteFileOptions `json:"options,omitempty"`
	ResourceOperation
}
type DeleteFileOptions struct {
	Recursive bool `json:"recursive,omitempty"`
	IgnoreIfNotExists bool `json:"ignoreIfNotExists,omitempty"`
}
type DeleteFilesParams struct {
	Files []FileDelete `json:"files"`
}
type Diagnostic struct {
	Range Range `json:"range"`
	Severity DiagnosticSeverity `json:"severity,omitempty"`
	Code interface{} `json:"code,omitempty"`
type DiagnosticClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	RelatedDocumentSupport bool `json:"relatedDocumentSupport,omitempty"`
	DiagnosticsCapabilities
}
type DiagnosticOptions struct {
	Identifier string `json:"identifier,omitempty"`
	InterFileDependencies bool `json:"interFileDependencies"`
	WorkspaceDiagnostics bool `json:"workspaceDiagnostics"`
	WorkDoneProgressOptions
}
type DiagnosticRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DiagnosticOptions
	StaticRegistrationOptions
}
type DiagnosticRelatedInformation struct {
	Location Location `json:"location"`
	Message string `json:"message"`
}
type DiagnosticServerCancellationData struct {
	RetriggerRequest bool `json:"retriggerRequest"`
}
type DiagnosticSeverity uint32
type DiagnosticTag uint32
type DiagnosticWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type DiagnosticsCapabilities struct {
	RelatedInformation bool `json:"relatedInformation,omitempty"`
	TagSupport *ClientDiagnosticsTagOptions `json:"tagSupport,omitempty"`
	CodeDescriptionSupport bool `json:"codeDescriptionSupport,omitempty"`
	DataSupport bool `json:"dataSupport,omitempty"`
}
type DidChangeConfigurationClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type DidChangeConfigurationParams struct {
	Settings interface{} `json:"settings"`
type DidChangeConfigurationRegistrationOptions struct {
	Section *Or_DidChangeConfigurationRegistrationOptions_section `json:"section,omitempty"`
}
type DidChangeNotebookDocumentParams struct {
	NotebookDocument VersionedNotebookDocumentIdentifier `json:"notebookDocument"`
	Change NotebookDocumentChangeEvent `json:"change"`
}
type DidChangeTextDocumentParams struct {
	TextDocument VersionedTextDocumentIdentifier `json:"textDocument"`
	ContentChanges []TextDocumentContentChangeEvent `json:"contentChanges"`
}
type DidChangeWatchedFilesClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	RelativePatternSupport bool `json:"relativePatternSupport,omitempty"`
}
type DidChangeWatchedFilesParams struct {
	Changes []FileEvent `json:"changes"`
}
type DidChangeWatchedFilesRegistrationOptions struct {
	Watchers []FileSystemWatcher `json:"watchers"`
}
type DidChangeWorkspaceFoldersParams struct {
	Event WorkspaceFoldersChangeEvent `json:"event"`
}
type DidCloseNotebookDocumentParams struct {
	NotebookDocument NotebookDocumentIdentifier `json:"notebookDocument"`
	CellTextDocuments []TextDocumentIdentifier `json:"cellTextDocuments"`
}
type DidCloseTextDocumentParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
}
type DidOpenNotebookDocumentParams struct {
	NotebookDocument NotebookDocument `json:"notebookDocument"`
	CellTextDocuments []TextDocumentItem `json:"cellTextDocuments"`
}
type DidOpenTextDocumentParams struct {
	TextDocument TextDocumentItem `json:"textDocument"`
}
type DidSaveNotebookDocumentParams struct {
	NotebookDocument NotebookDocumentIdentifier `json:"notebookDocument"`
}
type DidSaveTextDocumentParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Text *string `json:"text,omitempty"`
}
type DocumentColorClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type DocumentColorOptions struct {
	WorkDoneProgressOptions
}
type DocumentColorParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type DocumentColorRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentColorOptions
	StaticRegistrationOptions
}
type DocumentDiagnosticParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Identifier string `json:"identifier,omitempty"`
	PreviousResultID string `json:"previousResultId,omitempty"`
	WorkDoneProgressParams
	PartialResultParams
}
⋮----
type DocumentDiagnosticReportKind string
type DocumentDiagnosticReportPartialResult struct {
	RelatedDocuments map[DocumentUri]interface{} `json:"relatedDocuments"`
⋮----
type DocumentFormattingClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type DocumentFormattingOptions struct {
	WorkDoneProgressOptions
}
type DocumentFormattingParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Options FormattingOptions `json:"options"`
	WorkDoneProgressParams
}
type DocumentFormattingRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentFormattingOptions
}
type DocumentHighlight struct {
	Range Range `json:"range"`
	Kind DocumentHighlightKind `json:"kind,omitempty"`
}
type DocumentHighlightClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type DocumentHighlightKind uint32
type DocumentHighlightOptions struct {
	WorkDoneProgressOptions
}
type DocumentHighlightParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type DocumentHighlightRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentHighlightOptions
}
type DocumentLink struct {
	Range Range `json:"range"`
	Target *URI `json:"target,omitempty"`
	Tooltip string `json:"tooltip,omitempty"`
	Data interface{} `json:"data,omitempty"`
type DocumentLinkClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	TooltipSupport bool `json:"tooltipSupport,omitempty"`
}
type DocumentLinkOptions struct {
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	WorkDoneProgressOptions
}
type DocumentLinkParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type DocumentLinkRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentLinkOptions
}
type DocumentOnTypeFormattingClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type DocumentOnTypeFormattingOptions struct {
	FirstTriggerCharacter string `json:"firstTriggerCharacter"`
	MoreTriggerCharacter []string `json:"moreTriggerCharacter,omitempty"`
}
type DocumentOnTypeFormattingParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Position Position `json:"position"`
	Ch string `json:"ch"`
	Options FormattingOptions `json:"options"`
}
type DocumentOnTypeFormattingRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentOnTypeFormattingOptions
}
type DocumentRangeFormattingClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	RangesSupport bool `json:"rangesSupport,omitempty"`
}
type DocumentRangeFormattingOptions struct {
	RangesSupport bool `json:"rangesSupport,omitempty"`
	WorkDoneProgressOptions
}
type DocumentRangeFormattingParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range Range `json:"range"`
	Options FormattingOptions `json:"options"`
	WorkDoneProgressParams
}
type DocumentRangeFormattingRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentRangeFormattingOptions
}
type DocumentRangesFormattingParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Ranges []Range `json:"ranges"`
	Options FormattingOptions `json:"options"`
	WorkDoneProgressParams
}
⋮----
type DocumentSymbol struct {
	Name string `json:"name"`
	Detail string `json:"detail,omitempty"`
	Kind SymbolKind `json:"kind"`
	Tags []SymbolTag `json:"tags,omitempty"`
	Deprecated bool `json:"deprecated,omitempty"`
	Range Range `json:"range"`
	SelectionRange Range `json:"selectionRange"`
	Children []DocumentSymbol `json:"children,omitempty"`
}
type DocumentSymbolClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	SymbolKind *ClientSymbolKindOptions `json:"symbolKind,omitempty"`
	HierarchicalDocumentSymbolSupport bool `json:"hierarchicalDocumentSymbolSupport,omitempty"`
	TagSupport *ClientSymbolTagOptions `json:"tagSupport,omitempty"`
	LabelSupport bool `json:"labelSupport,omitempty"`
}
type DocumentSymbolOptions struct {
	Label string `json:"label,omitempty"`
	WorkDoneProgressOptions
}
type DocumentSymbolParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type DocumentSymbolRegistrationOptions struct {
	TextDocumentRegistrationOptions
	DocumentSymbolOptions
}
type EditRangeWithInsertReplace struct {
	Insert  Range `json:"insert"`
	Replace Range `json:"replace"`
}
type ErrorCodes int32
type ExecuteCommandClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type ExecuteCommandOptions struct {
	Commands []string `json:"commands"`
	WorkDoneProgressOptions
}
type ExecuteCommandParams struct {
	Command string `json:"command"`
	Arguments []json.RawMessage `json:"arguments,omitempty"`
	WorkDoneProgressParams
}
type ExecuteCommandRegistrationOptions struct {
	ExecuteCommandOptions
}
type ExecutionSummary struct {
	ExecutionOrder uint32 `json:"executionOrder"`
	Success bool `json:"success,omitempty"`
}
type FailureHandlingKind string
type FileChangeType uint32
type FileCreate struct {
	URI string `json:"uri"`
}
type FileDelete struct {
	URI string `json:"uri"`
}
type FileEvent struct {
	URI DocumentUri `json:"uri"`
	Type FileChangeType `json:"type"`
}
type FileOperationClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	DidCreate bool `json:"didCreate,omitempty"`
	WillCreate bool `json:"willCreate,omitempty"`
	DidRename bool `json:"didRename,omitempty"`
	WillRename bool `json:"willRename,omitempty"`
	DidDelete bool `json:"didDelete,omitempty"`
	WillDelete bool `json:"willDelete,omitempty"`
}
type FileOperationFilter struct {
	Scheme string `json:"scheme,omitempty"`
	Pattern FileOperationPattern `json:"pattern"`
}
type FileOperationOptions struct {
	DidCreate *FileOperationRegistrationOptions `json:"didCreate,omitempty"`
	WillCreate *FileOperationRegistrationOptions `json:"willCreate,omitempty"`
	DidRename *FileOperationRegistrationOptions `json:"didRename,omitempty"`
	WillRename *FileOperationRegistrationOptions `json:"willRename,omitempty"`
	DidDelete *FileOperationRegistrationOptions `json:"didDelete,omitempty"`
	WillDelete *FileOperationRegistrationOptions `json:"willDelete,omitempty"`
}
type FileOperationPattern struct {
	Glob string `json:"glob"`
	Matches *FileOperationPatternKind `json:"matches,omitempty"`
	Options *FileOperationPatternOptions `json:"options,omitempty"`
}
type FileOperationPatternKind string
type FileOperationPatternOptions struct {
	IgnoreCase bool `json:"ignoreCase,omitempty"`
}
type FileOperationRegistrationOptions struct {
	Filters []FileOperationFilter `json:"filters"`
}
type FileRename struct {
	OldURI string `json:"oldUri"`
	NewURI string `json:"newUri"`
}
type FileSystemWatcher struct {
	GlobPattern GlobPattern `json:"globPattern"`
	Kind *WatchKind `json:"kind,omitempty"`
}
type FoldingRange struct {
	StartLine uint32 `json:"startLine"`
	StartCharacter uint32 `json:"startCharacter,omitempty"`
	EndLine uint32 `json:"endLine"`
	EndCharacter uint32 `json:"endCharacter,omitempty"`
	Kind string `json:"kind,omitempty"`
	CollapsedText string `json:"collapsedText,omitempty"`
}
type FoldingRangeClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	RangeLimit uint32 `json:"rangeLimit,omitempty"`
	LineFoldingOnly bool `json:"lineFoldingOnly,omitempty"`
	FoldingRangeKind *ClientFoldingRangeKindOptions `json:"foldingRangeKind,omitempty"`
	FoldingRange *ClientFoldingRangeOptions `json:"foldingRange,omitempty"`
}
type FoldingRangeKind string
type FoldingRangeOptions struct {
	WorkDoneProgressOptions
}
type FoldingRangeParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type FoldingRangeRegistrationOptions struct {
	TextDocumentRegistrationOptions
	FoldingRangeOptions
	StaticRegistrationOptions
}
type FoldingRangeWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type FormattingOptions struct {
	TabSize uint32 `json:"tabSize"`
	InsertSpaces bool `json:"insertSpaces"`
	TrimTrailingWhitespace bool `json:"trimTrailingWhitespace,omitempty"`
	InsertFinalNewline bool `json:"insertFinalNewline,omitempty"`
	TrimFinalNewlines bool `json:"trimFinalNewlines,omitempty"`
}
type FullDocumentDiagnosticReport struct {
	Kind string `json:"kind"`
	ResultID string `json:"resultId,omitempty"`
	Items []Diagnostic `json:"items"`
}
type GeneralClientCapabilities struct {
	StaleRequestSupport *StaleRequestSupportOptions `json:"staleRequestSupport,omitempty"`
	RegularExpressions *RegularExpressionsClientCapabilities `json:"regularExpressions,omitempty"`
	Markdown *MarkdownClientCapabilities `json:"markdown,omitempty"`
	PositionEncodings []PositionEncodingKind `json:"positionEncodings,omitempty"`
}
⋮----
type Hover struct {
	Contents MarkupContent `json:"contents"`
	Range Range `json:"range,omitempty"`
}
type HoverClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	ContentFormat []MarkupKind `json:"contentFormat,omitempty"`
}
type HoverOptions struct {
	WorkDoneProgressOptions
}
type HoverParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type HoverRegistrationOptions struct {
	TextDocumentRegistrationOptions
	HoverOptions
}
type ImplementationClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	LinkSupport bool `json:"linkSupport,omitempty"`
}
type ImplementationOptions struct {
	WorkDoneProgressOptions
}
type ImplementationParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type ImplementationRegistrationOptions struct {
	TextDocumentRegistrationOptions
	ImplementationOptions
	StaticRegistrationOptions
}
type InitializeError struct {
	Retry bool `json:"retry"`
}
type InitializeParams struct {
	XInitializeParams
	WorkspaceFoldersInitializeParams
}
type InitializeResult struct {
	Capabilities ServerCapabilities `json:"capabilities"`
	ServerInfo *ServerInfo `json:"serverInfo,omitempty"`
}
type InitializedParams struct {
}
type InlayHint struct {
	Position Position `json:"position"`
	Label []InlayHintLabelPart `json:"label"`
	Kind InlayHintKind `json:"kind,omitempty"`
	TextEdits []TextEdit `json:"textEdits,omitempty"`
	Tooltip *Or_InlayHint_tooltip `json:"tooltip,omitempty"`
	PaddingLeft bool `json:"paddingLeft,omitempty"`
	PaddingRight bool `json:"paddingRight,omitempty"`
	Data interface{} `json:"data,omitempty"`
type InlayHintClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	ResolveSupport *ClientInlayHintResolveOptions `json:"resolveSupport,omitempty"`
}
type InlayHintKind uint32
type InlayHintLabelPart struct {
	Value string `json:"value"`
	Tooltip *Or_InlayHintLabelPart_tooltip `json:"tooltip,omitempty"`
	Location *Location `json:"location,omitempty"`
	Command *Command `json:"command,omitempty"`
}
type InlayHintOptions struct {
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	WorkDoneProgressOptions
}
type InlayHintParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range Range `json:"range"`
	WorkDoneProgressParams
}
type InlayHintRegistrationOptions struct {
	InlayHintOptions
	TextDocumentRegistrationOptions
	StaticRegistrationOptions
}
type InlayHintWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type InlineCompletionClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type InlineCompletionContext struct {
	TriggerKind InlineCompletionTriggerKind `json:"triggerKind"`
	SelectedCompletionInfo *SelectedCompletionInfo `json:"selectedCompletionInfo,omitempty"`
}
type InlineCompletionItem struct {
	InsertText Or_InlineCompletionItem_insertText `json:"insertText"`
	FilterText string `json:"filterText,omitempty"`
	Range *Range `json:"range,omitempty"`
	Command *Command `json:"command,omitempty"`
}
type InlineCompletionList struct {
	Items []InlineCompletionItem `json:"items"`
}
type InlineCompletionOptions struct {
	WorkDoneProgressOptions
}
type InlineCompletionParams struct {
	Context InlineCompletionContext `json:"context"`
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type InlineCompletionRegistrationOptions struct {
	InlineCompletionOptions
	TextDocumentRegistrationOptions
	StaticRegistrationOptions
}
type InlineCompletionTriggerKind uint32
⋮----
type InlineValueClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type InlineValueContext struct {
	FrameID int32 `json:"frameId"`
	StoppedLocation Range `json:"stoppedLocation"`
}
type InlineValueEvaluatableExpression struct {
	Range Range `json:"range"`
	Expression string `json:"expression,omitempty"`
}
type InlineValueOptions struct {
	WorkDoneProgressOptions
}
type InlineValueParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range Range `json:"range"`
	Context InlineValueContext `json:"context"`
	WorkDoneProgressParams
}
type InlineValueRegistrationOptions struct {
	InlineValueOptions
	TextDocumentRegistrationOptions
	StaticRegistrationOptions
}
type InlineValueText struct {
	Range Range `json:"range"`
	Text string `json:"text"`
}
type InlineValueVariableLookup struct {
	Range Range `json:"range"`
	VariableName string `json:"variableName,omitempty"`
	CaseSensitiveLookup bool `json:"caseSensitiveLookup"`
}
type InlineValueWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type InsertReplaceEdit struct {
	NewText string `json:"newText"`
	Insert Range `json:"insert"`
	Replace Range `json:"replace"`
}
type InsertTextFormat uint32
type InsertTextMode uint32
⋮----
type LSPErrorCodes int32
⋮----
type LanguageKind string
type LinkedEditingRangeClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type LinkedEditingRangeOptions struct {
	WorkDoneProgressOptions
}
type LinkedEditingRangeParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type LinkedEditingRangeRegistrationOptions struct {
	TextDocumentRegistrationOptions
	LinkedEditingRangeOptions
	StaticRegistrationOptions
}
type LinkedEditingRanges struct {
	Ranges []Range `json:"ranges"`
	WordPattern string `json:"wordPattern,omitempty"`
}
type Lit_ClientSemanticTokensRequestOptions_range_Item1 struct {
}
type Lit_SemanticTokensOptions_range_Item1 struct {
}
type Location struct {
	URI   DocumentUri `json:"uri"`
	Range Range       `json:"range"`
}
type LocationLink struct {
	OriginSelectionRange *Range `json:"originSelectionRange,omitempty"`
	TargetURI DocumentUri `json:"targetUri"`
	TargetRange Range `json:"targetRange"`
	TargetSelectionRange Range `json:"targetSelectionRange"`
}
type LocationUriOnly struct {
	URI DocumentUri `json:"uri"`
}
type LogMessageParams struct {
	Type MessageType `json:"type"`
	Message string `json:"message"`
}
type LogTraceParams struct {
	Message string `json:"message"`
	Verbose string `json:"verbose,omitempty"`
}
type MarkdownClientCapabilities struct {
	Parser string `json:"parser"`
	Version string `json:"version,omitempty"`
	AllowedTags []string `json:"allowedTags,omitempty"`
}
⋮----
type MarkedStringWithLanguage struct {
	Language string `json:"language"`
	Value    string `json:"value"`
}
type MarkupContent struct {
	Kind MarkupKind `json:"kind"`
	Value string `json:"value"`
}
type MarkupKind string
type MessageActionItem struct {
	Title string `json:"title"`
}
type MessageType uint32
type Moniker struct {
	Scheme string `json:"scheme"`
	Identifier string `json:"identifier"`
	Unique UniquenessLevel `json:"unique"`
	Kind *MonikerKind `json:"kind,omitempty"`
}
type MonikerClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type MonikerKind string
type MonikerOptions struct {
	WorkDoneProgressOptions
}
type MonikerParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type MonikerRegistrationOptions struct {
	TextDocumentRegistrationOptions
	MonikerOptions
}
type NotebookCell struct {
	Kind NotebookCellKind `json:"kind"`
	Document DocumentUri `json:"document"`
	Metadata *LSPObject `json:"metadata,omitempty"`
	ExecutionSummary *ExecutionSummary `json:"executionSummary,omitempty"`
}
type NotebookCellArrayChange struct {
	Start uint32 `json:"start"`
	DeleteCount uint32 `json:"deleteCount"`
	Cells []NotebookCell `json:"cells,omitempty"`
}
type NotebookCellKind uint32
type NotebookCellLanguage struct {
	Language string `json:"language"`
}
type NotebookCellTextDocumentFilter struct {
	Notebook Or_NotebookCellTextDocumentFilter_notebook `json:"notebook"`
	Language string `json:"language,omitempty"`
}
type NotebookDocument struct {
	URI URI `json:"uri"`
	NotebookType string `json:"notebookType"`
	Version int32 `json:"version"`
	Metadata *LSPObject `json:"metadata,omitempty"`
	Cells []NotebookCell `json:"cells"`
}
type NotebookDocumentCellChangeStructure struct {
	Array NotebookCellArrayChange `json:"array"`
	DidOpen []TextDocumentItem `json:"didOpen,omitempty"`
	DidClose []TextDocumentIdentifier `json:"didClose,omitempty"`
}
type NotebookDocumentCellChanges struct {
	Structure *NotebookDocumentCellChangeStructure `json:"structure,omitempty"`
	Data []NotebookCell `json:"data,omitempty"`
	TextContent []NotebookDocumentCellContentChanges `json:"textContent,omitempty"`
}
type NotebookDocumentCellContentChanges struct {
	Document VersionedTextDocumentIdentifier  `json:"document"`
	Changes  []TextDocumentContentChangeEvent `json:"changes"`
}
type NotebookDocumentChangeEvent struct {
	Metadata *LSPObject `json:"metadata,omitempty"`
	Cells *NotebookDocumentCellChanges `json:"cells,omitempty"`
}
type NotebookDocumentClientCapabilities struct {
	Synchronization NotebookDocumentSyncClientCapabilities `json:"synchronization"`
}
⋮----
type NotebookDocumentFilterNotebookType struct {
	NotebookType string `json:"notebookType"`
	Scheme string `json:"scheme,omitempty"`
	Pattern *GlobPattern `json:"pattern,omitempty"`
}
type NotebookDocumentFilterPattern struct {
	NotebookType string `json:"notebookType,omitempty"`
	Scheme string `json:"scheme,omitempty"`
	Pattern GlobPattern `json:"pattern"`
}
type NotebookDocumentFilterScheme struct {
	NotebookType string `json:"notebookType,omitempty"`
	Scheme string `json:"scheme"`
	Pattern *GlobPattern `json:"pattern,omitempty"`
}
type NotebookDocumentFilterWithCells struct {
	Notebook *Or_NotebookDocumentFilterWithCells_notebook `json:"notebook,omitempty"`
	Cells []NotebookCellLanguage `json:"cells"`
}
type NotebookDocumentFilterWithNotebook struct {
	Notebook Or_NotebookDocumentFilterWithNotebook_notebook `json:"notebook"`
	Cells []NotebookCellLanguage `json:"cells,omitempty"`
}
type NotebookDocumentIdentifier struct {
	URI URI `json:"uri"`
}
type NotebookDocumentSyncClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	ExecutionSummarySupport bool `json:"executionSummarySupport,omitempty"`
}
type NotebookDocumentSyncOptions struct {
	NotebookSelector []Or_NotebookDocumentSyncOptions_notebookSelector_Elem `json:"notebookSelector"`
	Save bool `json:"save,omitempty"`
}
type NotebookDocumentSyncRegistrationOptions struct {
	NotebookDocumentSyncOptions
	StaticRegistrationOptions
}
type OptionalVersionedTextDocumentIdentifier struct {
	Version int32 `json:"version"`
	TextDocumentIdentifier
}
type Or_CancelParams_id struct {
	Value interface{} `json:"value"`
type Or_ClientSemanticTokensRequestOptions_full struct {
	Value interface{} `json:"value"`
type Or_ClientSemanticTokensRequestOptions_range struct {
	Value interface{} `json:"value"`
type Or_CompletionItemDefaults_editRange struct {
	Value interface{} `json:"value"`
type Or_CompletionItem_documentation struct {
	Value interface{} `json:"value"`
type Or_CompletionItem_textEdit struct {
	Value interface{} `json:"value"`
type Or_Declaration struct {
	Value interface{} `json:"value"`
type Or_Definition struct {
	Value interface{} `json:"value"`
type Or_Diagnostic_code struct {
	Value interface{} `json:"value"`
type Or_DidChangeConfigurationRegistrationOptions_section struct {
	Value interface{} `json:"value"`
type Or_DocumentDiagnosticReport struct {
	Value interface{} `json:"value"`
type Or_DocumentDiagnosticReportPartialResult_relatedDocuments_Value struct {
	Value interface{} `json:"value"`
type Or_DocumentFilter struct {
	Value interface{} `json:"value"`
type Or_GlobPattern struct {
	Value interface{} `json:"value"`
type Or_Hover_contents struct {
	Value interface{} `json:"value"`
type Or_InlayHintLabelPart_tooltip struct {
	Value interface{} `json:"value"`
type Or_InlayHint_label struct {
	Value interface{} `json:"value"`
type Or_InlayHint_tooltip struct {
	Value interface{} `json:"value"`
type Or_InlineCompletionItem_insertText struct {
	Value interface{} `json:"value"`
type Or_InlineValue struct {
	Value interface{} `json:"value"`
type Or_LSPAny struct {
	Value interface{} `json:"value"`
type Or_MarkedString struct {
	Value interface{} `json:"value"`
type Or_NotebookCellTextDocumentFilter_notebook struct {
	Value interface{} `json:"value"`
type Or_NotebookDocumentFilter struct {
	Value interface{} `json:"value"`
type Or_NotebookDocumentFilterWithCells_notebook struct {
	Value interface{} `json:"value"`
type Or_NotebookDocumentFilterWithNotebook_notebook struct {
	Value interface{} `json:"value"`
type Or_NotebookDocumentSyncOptions_notebookSelector_Elem struct {
	Value interface{} `json:"value"`
type Or_ParameterInformation_documentation struct {
	Value interface{} `json:"value"`
type Or_ParameterInformation_label struct {
	Value interface{} `json:"value"`
type Or_PrepareRenameResult struct {
	Value interface{} `json:"value"`
type Or_ProgressToken struct {
	Value interface{} `json:"value"`
type Or_RelatedFullDocumentDiagnosticReport_relatedDocuments_Value struct {
	Value interface{} `json:"value"`
type Or_RelatedUnchangedDocumentDiagnosticReport_relatedDocuments_Value struct {
	Value interface{} `json:"value"`
type Or_RelativePattern_baseUri struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_codeAction_Item0_Elem struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_completion struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_declaration struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_definition struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_documentSymbol struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_implementation struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_inlineCompletion struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_semanticTokens_full_delta struct {
	Value interface{} `json:"value"`
type Or_Result_textDocument_typeDefinition struct {
	Value interface{} `json:"value"`
type Or_Result_workspace_symbol struct {
	Value interface{} `json:"value"`
type Or_SemanticTokensOptions_full struct {
	Value interface{} `json:"value"`
type Or_SemanticTokensOptions_range struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_callHierarchyProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_codeActionProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_colorProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_declarationProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_definitionProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_diagnosticProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_documentFormattingProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_documentHighlightProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_documentRangeFormattingProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_documentSymbolProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_foldingRangeProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_hoverProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_implementationProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_inlayHintProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_inlineCompletionProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_inlineValueProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_linkedEditingRangeProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_monikerProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_notebookDocumentSync struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_referencesProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_renameProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_selectionRangeProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_semanticTokensProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_textDocumentSync struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_typeDefinitionProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_typeHierarchyProvider struct {
	Value interface{} `json:"value"`
type Or_ServerCapabilities_workspaceSymbolProvider struct {
	Value interface{} `json:"value"`
type Or_SignatureInformation_documentation struct {
	Value interface{} `json:"value"`
type Or_TextDocumentContentChangeEvent struct {
	Value interface{} `json:"value"`
type Or_TextDocumentEdit_edits_Elem struct {
	Value interface{} `json:"value"`
type Or_TextDocumentFilter struct {
	Value interface{} `json:"value"`
type Or_TextDocumentSyncOptions_save struct {
	Value interface{} `json:"value"`
type Or_WorkspaceDocumentDiagnosticReport struct {
	Value interface{} `json:"value"`
type Or_WorkspaceEdit_documentChanges_Elem struct {
	Value interface{} `json:"value"`
type Or_WorkspaceFoldersServerCapabilities_changeNotifications struct {
	Value interface{} `json:"value"`
type Or_WorkspaceOptions_textDocumentContent struct {
	Value interface{} `json:"value"`
type Or_WorkspaceSymbol_location struct {
	Value interface{} `json:"value"`
type ParamConfiguration struct {
	Items []ConfigurationItem `json:"items"`
}
type ParamInitialize struct {
	XInitializeParams
	WorkspaceFoldersInitializeParams
}
type ParameterInformation struct {
	Label Or_ParameterInformation_label `json:"label"`
	Documentation *Or_ParameterInformation_documentation `json:"documentation,omitempty"`
}
type PartialResultParams struct {
	PartialResultToken *ProgressToken `json:"partialResultToken,omitempty"`
}
⋮----
type Position struct {
	Line uint32 `json:"line"`
	Character uint32 `json:"character"`
}
type PositionEncodingKind string
type PrepareRenameDefaultBehavior struct {
	DefaultBehavior bool `json:"defaultBehavior"`
}
type PrepareRenameParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type PrepareRenamePlaceholder struct {
	Range       Range  `json:"range"`
	Placeholder string `json:"placeholder"`
}
⋮----
type PrepareSupportDefaultBehavior uint32
type PreviousResultID struct {
	URI DocumentUri `json:"uri"`
	Value string `json:"value"`
}
type PreviousResultId struct {
	URI DocumentUri `json:"uri"`
	Value string `json:"value"`
}
type ProgressParams struct {
	Token ProgressToken `json:"token"`
	Value interface{} `json:"value"`
⋮----
type PublishDiagnosticsClientCapabilities struct {
	VersionSupport bool `json:"versionSupport,omitempty"`
	DiagnosticsCapabilities
}
type PublishDiagnosticsParams struct {
	URI DocumentUri `json:"uri"`
	Version int32 `json:"version,omitempty"`
	Diagnostics []Diagnostic `json:"diagnostics"`
}
type Range struct {
	Start Position `json:"start"`
	End Position `json:"end"`
}
type ReferenceClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type ReferenceContext struct {
	IncludeDeclaration bool `json:"includeDeclaration"`
}
type ReferenceOptions struct {
	WorkDoneProgressOptions
}
type ReferenceParams struct {
	Context ReferenceContext `json:"context"`
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type ReferenceRegistrationOptions struct {
	TextDocumentRegistrationOptions
	ReferenceOptions
}
type Registration struct {
	ID string `json:"id"`
	Method string `json:"method"`
	RegisterOptions interface{} `json:"registerOptions,omitempty"`
type RegistrationParams struct {
	Registrations []Registration `json:"registrations"`
}
⋮----
type RegularExpressionsClientCapabilities struct {
	Engine RegularExpressionEngineKind `json:"engine"`
	Version string `json:"version,omitempty"`
}
type RelatedFullDocumentDiagnosticReport struct {
	RelatedDocuments map[DocumentUri]interface{} `json:"relatedDocuments,omitempty"`
type RelatedUnchangedDocumentDiagnosticReport struct {
	RelatedDocuments map[DocumentUri]interface{} `json:"relatedDocuments,omitempty"`
type RelativePattern struct {
	BaseURI Or_RelativePattern_baseUri `json:"baseUri"`
	Pattern Pattern `json:"pattern"`
}
type RenameClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	PrepareSupport bool `json:"prepareSupport,omitempty"`
	PrepareSupportDefaultBehavior *PrepareSupportDefaultBehavior `json:"prepareSupportDefaultBehavior,omitempty"`
	HonorsChangeAnnotations bool `json:"honorsChangeAnnotations,omitempty"`
}
type RenameFile struct {
	Kind string `json:"kind"`
	OldURI DocumentUri `json:"oldUri"`
	NewURI DocumentUri `json:"newUri"`
	Options *RenameFileOptions `json:"options,omitempty"`
	ResourceOperation
}
type RenameFileOptions struct {
	Overwrite bool `json:"overwrite,omitempty"`
	IgnoreIfExists bool `json:"ignoreIfExists,omitempty"`
}
type RenameFilesParams struct {
	Files []FileRename `json:"files"`
}
type RenameOptions struct {
	PrepareProvider bool `json:"prepareProvider,omitempty"`
	WorkDoneProgressOptions
}
type RenameParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Position Position `json:"position"`
	NewName string `json:"newName"`
	WorkDoneProgressParams
}
type RenameRegistrationOptions struct {
	TextDocumentRegistrationOptions
	RenameOptions
}
type ResourceOperation struct {
	Kind string `json:"kind"`
	AnnotationID *ChangeAnnotationIdentifier `json:"annotationId,omitempty"`
}
type ResourceOperationKind string
type SaveOptions struct {
	IncludeText bool `json:"includeText,omitempty"`
}
type SelectedCompletionInfo struct {
	Range Range `json:"range"`
	Text string `json:"text"`
}
type SelectionRange struct {
	Range Range `json:"range"`
	Parent *SelectionRange `json:"parent,omitempty"`
}
type SelectionRangeClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type SelectionRangeOptions struct {
	WorkDoneProgressOptions
}
type SelectionRangeParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Positions []Position `json:"positions"`
	WorkDoneProgressParams
	PartialResultParams
}
type SelectionRangeRegistrationOptions struct {
	SelectionRangeOptions
	TextDocumentRegistrationOptions
	StaticRegistrationOptions
}
type SemanticTokenModifiers string
type SemanticTokenTypes string
type SemanticTokens struct {
	ResultID string `json:"resultId,omitempty"`
	Data []uint32 `json:"data"`
}
type SemanticTokensClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	Requests ClientSemanticTokensRequestOptions `json:"requests"`
	TokenTypes []string `json:"tokenTypes"`
	TokenModifiers []string `json:"tokenModifiers"`
	Formats []TokenFormat `json:"formats"`
	OverlappingTokenSupport bool `json:"overlappingTokenSupport,omitempty"`
	MultilineTokenSupport bool `json:"multilineTokenSupport,omitempty"`
	ServerCancelSupport bool `json:"serverCancelSupport,omitempty"`
	AugmentsSyntaxTokens bool `json:"augmentsSyntaxTokens,omitempty"`
}
type SemanticTokensDelta struct {
	ResultID string `json:"resultId,omitempty"`
	Edits []SemanticTokensEdit `json:"edits"`
}
type SemanticTokensDeltaParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	PreviousResultID string `json:"previousResultId"`
	WorkDoneProgressParams
	PartialResultParams
}
type SemanticTokensDeltaPartialResult struct {
	Edits []SemanticTokensEdit `json:"edits"`
}
type SemanticTokensEdit struct {
	Start uint32 `json:"start"`
	DeleteCount uint32 `json:"deleteCount"`
	Data []uint32 `json:"data,omitempty"`
}
type SemanticTokensFullDelta struct {
	Delta bool `json:"delta,omitempty"`
}
type SemanticTokensLegend struct {
	TokenTypes []string `json:"tokenTypes"`
	TokenModifiers []string `json:"tokenModifiers"`
}
type SemanticTokensOptions struct {
	Legend SemanticTokensLegend `json:"legend"`
	Range *Or_SemanticTokensOptions_range `json:"range,omitempty"`
	Full *Or_SemanticTokensOptions_full `json:"full,omitempty"`
	WorkDoneProgressOptions
}
type SemanticTokensParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	WorkDoneProgressParams
	PartialResultParams
}
type SemanticTokensPartialResult struct {
	Data []uint32 `json:"data"`
}
type SemanticTokensRangeParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range Range `json:"range"`
	WorkDoneProgressParams
	PartialResultParams
}
type SemanticTokensRegistrationOptions struct {
	TextDocumentRegistrationOptions
	SemanticTokensOptions
	StaticRegistrationOptions
}
type SemanticTokensWorkspaceClientCapabilities struct {
	RefreshSupport bool `json:"refreshSupport,omitempty"`
}
type ServerCapabilities struct {
	PositionEncoding *PositionEncodingKind `json:"positionEncoding,omitempty"`
	TextDocumentSync interface{} `json:"textDocumentSync,omitempty"`
type ServerCompletionItemOptions struct {
	LabelDetailsSupport bool `json:"labelDetailsSupport,omitempty"`
}
type ServerInfo struct {
	Name string `json:"name"`
	Version string `json:"version,omitempty"`
}
type SetTraceParams struct {
	Value TraceValue `json:"value"`
}
type ShowDocumentClientCapabilities struct {
	Support bool `json:"support"`
}
type ShowDocumentParams struct {
	URI URI `json:"uri"`
	External bool `json:"external,omitempty"`
	TakeFocus bool `json:"takeFocus,omitempty"`
	Selection *Range `json:"selection,omitempty"`
}
type ShowDocumentResult struct {
	Success bool `json:"success"`
}
type ShowMessageParams struct {
	Type MessageType `json:"type"`
	Message string `json:"message"`
}
type ShowMessageRequestClientCapabilities struct {
	MessageActionItem *ClientShowMessageActionItemOptions `json:"messageActionItem,omitempty"`
}
type ShowMessageRequestParams struct {
	Type MessageType `json:"type"`
	Message string `json:"message"`
	Actions []MessageActionItem `json:"actions,omitempty"`
}
type SignatureHelp struct {
	Signatures []SignatureInformation `json:"signatures"`
	ActiveSignature uint32 `json:"activeSignature,omitempty"`
	ActiveParameter uint32 `json:"activeParameter,omitempty"`
}
type SignatureHelpClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	SignatureInformation *ClientSignatureInformationOptions `json:"signatureInformation,omitempty"`
	ContextSupport bool `json:"contextSupport,omitempty"`
}
type SignatureHelpContext struct {
	TriggerKind SignatureHelpTriggerKind `json:"triggerKind"`
	TriggerCharacter string `json:"triggerCharacter,omitempty"`
	IsRetrigger bool `json:"isRetrigger"`
	ActiveSignatureHelp *SignatureHelp `json:"activeSignatureHelp,omitempty"`
}
type SignatureHelpOptions struct {
	TriggerCharacters []string `json:"triggerCharacters,omitempty"`
	RetriggerCharacters []string `json:"retriggerCharacters,omitempty"`
	WorkDoneProgressOptions
}
type SignatureHelpParams struct {
	Context *SignatureHelpContext `json:"context,omitempty"`
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type SignatureHelpRegistrationOptions struct {
	TextDocumentRegistrationOptions
	SignatureHelpOptions
}
type SignatureHelpTriggerKind uint32
type SignatureInformation struct {
	Label string `json:"label"`
	Documentation *Or_SignatureInformation_documentation `json:"documentation,omitempty"`
	Parameters []ParameterInformation `json:"parameters,omitempty"`
	ActiveParameter uint32 `json:"activeParameter,omitempty"`
}
type SnippetTextEdit struct {
	Range Range `json:"range"`
	Snippet StringValue `json:"snippet"`
	AnnotationID *ChangeAnnotationIdentifier `json:"annotationId,omitempty"`
}
type StaleRequestSupportOptions struct {
	Cancel bool `json:"cancel"`
	RetryOnContentModified []string `json:"retryOnContentModified"`
}
type StaticRegistrationOptions struct {
	ID string `json:"id,omitempty"`
}
type StringValue struct {
	Kind string `json:"kind"`
	Value string `json:"value"`
}
type SymbolInformation struct {
	Deprecated bool `json:"deprecated,omitempty"`
	Location Location `json:"location"`
	Name string `json:"name"`
	Kind SymbolKind `json:"kind"`
	Tags []SymbolTag `json:"tags,omitempty"`
	ContainerName string `json:"containerName,omitempty"`
}
type SymbolKind uint32
type SymbolTag uint32
type TextDocumentChangeRegistrationOptions struct {
	SyncKind TextDocumentSyncKind `json:"syncKind"`
	TextDocumentRegistrationOptions
}
type TextDocumentClientCapabilities struct {
	Synchronization *TextDocumentSyncClientCapabilities `json:"synchronization,omitempty"`
	Completion CompletionClientCapabilities `json:"completion,omitempty"`
	Hover *HoverClientCapabilities `json:"hover,omitempty"`
	SignatureHelp *SignatureHelpClientCapabilities `json:"signatureHelp,omitempty"`
	Declaration *DeclarationClientCapabilities `json:"declaration,omitempty"`
	Definition *DefinitionClientCapabilities `json:"definition,omitempty"`
	TypeDefinition *TypeDefinitionClientCapabilities `json:"typeDefinition,omitempty"`
	Implementation *ImplementationClientCapabilities `json:"implementation,omitempty"`
	References *ReferenceClientCapabilities `json:"references,omitempty"`
	DocumentHighlight *DocumentHighlightClientCapabilities `json:"documentHighlight,omitempty"`
	DocumentSymbol DocumentSymbolClientCapabilities `json:"documentSymbol,omitempty"`
	CodeAction CodeActionClientCapabilities `json:"codeAction,omitempty"`
	CodeLens *CodeLensClientCapabilities `json:"codeLens,omitempty"`
	DocumentLink *DocumentLinkClientCapabilities `json:"documentLink,omitempty"`
	ColorProvider *DocumentColorClientCapabilities `json:"colorProvider,omitempty"`
	Formatting *DocumentFormattingClientCapabilities `json:"formatting,omitempty"`
	RangeFormatting *DocumentRangeFormattingClientCapabilities `json:"rangeFormatting,omitempty"`
	OnTypeFormatting *DocumentOnTypeFormattingClientCapabilities `json:"onTypeFormatting,omitempty"`
	Rename *RenameClientCapabilities `json:"rename,omitempty"`
	FoldingRange *FoldingRangeClientCapabilities `json:"foldingRange,omitempty"`
	SelectionRange *SelectionRangeClientCapabilities `json:"selectionRange,omitempty"`
	PublishDiagnostics PublishDiagnosticsClientCapabilities `json:"publishDiagnostics,omitempty"`
	CallHierarchy *CallHierarchyClientCapabilities `json:"callHierarchy,omitempty"`
	SemanticTokens SemanticTokensClientCapabilities `json:"semanticTokens,omitempty"`
	LinkedEditingRange *LinkedEditingRangeClientCapabilities `json:"linkedEditingRange,omitempty"`
	Moniker *MonikerClientCapabilities `json:"moniker,omitempty"`
	TypeHierarchy *TypeHierarchyClientCapabilities `json:"typeHierarchy,omitempty"`
	InlineValue *InlineValueClientCapabilities `json:"inlineValue,omitempty"`
	InlayHint *InlayHintClientCapabilities `json:"inlayHint,omitempty"`
	Diagnostic *DiagnosticClientCapabilities `json:"diagnostic,omitempty"`
	InlineCompletion *InlineCompletionClientCapabilities `json:"inlineCompletion,omitempty"`
}
⋮----
type TextDocumentContentChangePartial struct {
	Range *Range `json:"range,omitempty"`
	RangeLength uint32 `json:"rangeLength,omitempty"`
	Text string `json:"text"`
}
type TextDocumentContentChangeWholeDocument struct {
	Text string `json:"text"`
}
type TextDocumentContentClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type TextDocumentContentOptions struct {
	Scheme string `json:"scheme"`
}
type TextDocumentContentParams struct {
	URI DocumentUri `json:"uri"`
}
type TextDocumentContentRefreshParams struct {
	URI DocumentUri `json:"uri"`
}
type TextDocumentContentRegistrationOptions struct {
	TextDocumentContentOptions
	StaticRegistrationOptions
}
type TextDocumentEdit struct {
	TextDocument OptionalVersionedTextDocumentIdentifier `json:"textDocument"`
	Edits []Or_TextDocumentEdit_edits_Elem `json:"edits"`
}
⋮----
type TextDocumentFilterLanguage struct {
	Language string `json:"language"`
	Scheme string `json:"scheme,omitempty"`
	Pattern *GlobPattern `json:"pattern,omitempty"`
}
type TextDocumentFilterPattern struct {
	Language string `json:"language,omitempty"`
	Scheme string `json:"scheme,omitempty"`
	Pattern GlobPattern `json:"pattern"`
}
type TextDocumentFilterScheme struct {
	Language string `json:"language,omitempty"`
	Scheme string `json:"scheme"`
	Pattern *GlobPattern `json:"pattern,omitempty"`
}
type TextDocumentIdentifier struct {
	URI DocumentUri `json:"uri"`
}
type TextDocumentItem struct {
	URI DocumentUri `json:"uri"`
	LanguageID LanguageKind `json:"languageId"`
	Version int32 `json:"version"`
	Text string `json:"text"`
}
type TextDocumentPositionParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Position Position `json:"position"`
}
type TextDocumentRegistrationOptions struct {
	DocumentSelector DocumentSelector `json:"documentSelector"`
}
type TextDocumentSaveReason uint32
type TextDocumentSaveRegistrationOptions struct {
	TextDocumentRegistrationOptions
	SaveOptions
}
type TextDocumentSyncClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	WillSave bool `json:"willSave,omitempty"`
	WillSaveWaitUntil bool `json:"willSaveWaitUntil,omitempty"`
	DidSave bool `json:"didSave,omitempty"`
}
type TextDocumentSyncKind uint32
type TextDocumentSyncOptions struct {
	OpenClose bool `json:"openClose,omitempty"`
	Change TextDocumentSyncKind `json:"change,omitempty"`
	WillSave bool `json:"willSave,omitempty"`
	WillSaveWaitUntil bool `json:"willSaveWaitUntil,omitempty"`
	Save *SaveOptions `json:"save,omitempty"`
}
type TextEdit struct {
	Range Range `json:"range"`
	NewText string `json:"newText"`
}
type TokenFormat string
type TraceValue string
type Tuple_ParameterInformation_label_Item1 struct {
	Fld0 uint32 `json:"fld0"`
	Fld1 uint32 `json:"fld1"`
}
type TypeDefinitionClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	LinkSupport bool `json:"linkSupport,omitempty"`
}
type TypeDefinitionOptions struct {
	WorkDoneProgressOptions
}
type TypeDefinitionParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
	PartialResultParams
}
type TypeDefinitionRegistrationOptions struct {
	TextDocumentRegistrationOptions
	TypeDefinitionOptions
	StaticRegistrationOptions
}
type TypeHierarchyClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
}
type TypeHierarchyItem struct {
	Name string `json:"name"`
	Kind SymbolKind `json:"kind"`
	Tags []SymbolTag `json:"tags,omitempty"`
	Detail string `json:"detail,omitempty"`
	URI DocumentUri `json:"uri"`
	Range Range `json:"range"`
	SelectionRange Range `json:"selectionRange"`
	Data interface{} `json:"data,omitempty"`
type TypeHierarchyOptions struct {
	WorkDoneProgressOptions
}
type TypeHierarchyPrepareParams struct {
	TextDocumentPositionParams
	WorkDoneProgressParams
}
type TypeHierarchyRegistrationOptions struct {
	TextDocumentRegistrationOptions
	TypeHierarchyOptions
	StaticRegistrationOptions
}
type TypeHierarchySubtypesParams struct {
	Item TypeHierarchyItem `json:"item"`
	WorkDoneProgressParams
	PartialResultParams
}
type TypeHierarchySupertypesParams struct {
	Item TypeHierarchyItem `json:"item"`
	WorkDoneProgressParams
	PartialResultParams
}
type UnchangedDocumentDiagnosticReport struct {
	Kind string `json:"kind"`
	ResultID string `json:"resultId"`
}
type UniquenessLevel string
type Unregistration struct {
	ID string `json:"id"`
	Method string `json:"method"`
}
type UnregistrationParams struct {
	Unregisterations []Unregistration `json:"unregisterations"`
}
type VersionedNotebookDocumentIdentifier struct {
	Version int32 `json:"version"`
	URI URI `json:"uri"`
}
type VersionedTextDocumentIdentifier struct {
	Version int32 `json:"version"`
	TextDocumentIdentifier
}
⋮----
type WillSaveTextDocumentParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Reason TextDocumentSaveReason `json:"reason"`
}
type WindowClientCapabilities struct {
	WorkDoneProgress bool `json:"workDoneProgress,omitempty"`
	ShowMessage *ShowMessageRequestClientCapabilities `json:"showMessage,omitempty"`
	ShowDocument *ShowDocumentClientCapabilities `json:"showDocument,omitempty"`
}
type WorkDoneProgressBegin struct {
	Kind string `json:"kind"`
	Title string `json:"title"`
	Cancellable bool `json:"cancellable,omitempty"`
	Message string `json:"message,omitempty"`
	Percentage uint32 `json:"percentage,omitempty"`
}
type WorkDoneProgressCancelParams struct {
	Token ProgressToken `json:"token"`
}
type WorkDoneProgressCreateParams struct {
	Token ProgressToken `json:"token"`
}
type WorkDoneProgressEnd struct {
	Kind string `json:"kind"`
	Message string `json:"message,omitempty"`
}
type WorkDoneProgressOptions struct {
	WorkDoneProgress bool `json:"workDoneProgress,omitempty"`
}
type WorkDoneProgressParams struct {
	WorkDoneToken ProgressToken `json:"workDoneToken,omitempty"`
}
type WorkDoneProgressReport struct {
	Kind string `json:"kind"`
	Cancellable bool `json:"cancellable,omitempty"`
	Message string `json:"message,omitempty"`
	Percentage uint32 `json:"percentage,omitempty"`
}
type WorkspaceClientCapabilities struct {
	ApplyEdit bool `json:"applyEdit,omitempty"`
	WorkspaceEdit *WorkspaceEditClientCapabilities `json:"workspaceEdit,omitempty"`
	DidChangeConfiguration DidChangeConfigurationClientCapabilities `json:"didChangeConfiguration,omitempty"`
	DidChangeWatchedFiles DidChangeWatchedFilesClientCapabilities `json:"didChangeWatchedFiles,omitempty"`
	Symbol *WorkspaceSymbolClientCapabilities `json:"symbol,omitempty"`
	ExecuteCommand *ExecuteCommandClientCapabilities `json:"executeCommand,omitempty"`
	WorkspaceFolders bool `json:"workspaceFolders,omitempty"`
	Configuration bool `json:"configuration,omitempty"`
	SemanticTokens *SemanticTokensWorkspaceClientCapabilities `json:"semanticTokens,omitempty"`
	CodeLens *CodeLensWorkspaceClientCapabilities `json:"codeLens,omitempty"`
	FileOperations *FileOperationClientCapabilities `json:"fileOperations,omitempty"`
	InlineValue *InlineValueWorkspaceClientCapabilities `json:"inlineValue,omitempty"`
	InlayHint *InlayHintWorkspaceClientCapabilities `json:"inlayHint,omitempty"`
	Diagnostics *DiagnosticWorkspaceClientCapabilities `json:"diagnostics,omitempty"`
	FoldingRange *FoldingRangeWorkspaceClientCapabilities `json:"foldingRange,omitempty"`
	TextDocumentContent *TextDocumentContentClientCapabilities `json:"textDocumentContent,omitempty"`
}
type WorkspaceDiagnosticParams struct {
	Identifier string `json:"identifier,omitempty"`
	PreviousResultIds []PreviousResultId `json:"previousResultIds"`
	WorkDoneProgressParams
	PartialResultParams
}
type WorkspaceDiagnosticReport struct {
	Items []WorkspaceDocumentDiagnosticReport `json:"items"`
}
type WorkspaceDiagnosticReportPartialResult struct {
	Items []WorkspaceDocumentDiagnosticReport `json:"items"`
}
⋮----
type WorkspaceEdit struct {
	Changes map[DocumentUri][]TextEdit `json:"changes,omitempty"`
	DocumentChanges []DocumentChange `json:"documentChanges,omitempty"`
	ChangeAnnotations map[ChangeAnnotationIdentifier]ChangeAnnotation `json:"changeAnnotations,omitempty"`
}
type WorkspaceEditClientCapabilities struct {
	DocumentChanges bool `json:"documentChanges,omitempty"`
	ResourceOperations []ResourceOperationKind `json:"resourceOperations,omitempty"`
	FailureHandling *FailureHandlingKind `json:"failureHandling,omitempty"`
	NormalizesLineEndings bool `json:"normalizesLineEndings,omitempty"`
	ChangeAnnotationSupport *ChangeAnnotationsSupportOptions `json:"changeAnnotationSupport,omitempty"`
	MetadataSupport bool `json:"metadataSupport,omitempty"`
	SnippetEditSupport bool `json:"snippetEditSupport,omitempty"`
}
type WorkspaceEditMetadata struct {
	IsRefactoring bool `json:"isRefactoring,omitempty"`
}
type WorkspaceFolder struct {
	URI URI `json:"uri"`
	Name string `json:"name"`
}
type WorkspaceFoldersChangeEvent struct {
	Added []WorkspaceFolder `json:"added"`
	Removed []WorkspaceFolder `json:"removed"`
}
type WorkspaceFoldersInitializeParams struct {
	WorkspaceFolders []WorkspaceFolder `json:"workspaceFolders,omitempty"`
}
type WorkspaceFoldersServerCapabilities struct {
	Supported bool `json:"supported,omitempty"`
	ChangeNotifications *Or_WorkspaceFoldersServerCapabilities_changeNotifications `json:"changeNotifications,omitempty"`
}
type WorkspaceFullDocumentDiagnosticReport struct {
	URI DocumentUri `json:"uri"`
	Version int32 `json:"version"`
	FullDocumentDiagnosticReport
}
type WorkspaceOptions struct {
	WorkspaceFolders *WorkspaceFoldersServerCapabilities `json:"workspaceFolders,omitempty"`
	FileOperations *FileOperationOptions `json:"fileOperations,omitempty"`
	TextDocumentContent *Or_WorkspaceOptions_textDocumentContent `json:"textDocumentContent,omitempty"`
}
type WorkspaceSymbol struct {
	Location Or_WorkspaceSymbol_location `json:"location"`
	Data interface{} `json:"data,omitempty"`
type WorkspaceSymbolClientCapabilities struct {
	DynamicRegistration bool `json:"dynamicRegistration,omitempty"`
	SymbolKind *ClientSymbolKindOptions `json:"symbolKind,omitempty"`
	TagSupport *ClientSymbolTagOptions `json:"tagSupport,omitempty"`
	ResolveSupport *ClientSymbolResolveOptions `json:"resolveSupport,omitempty"`
}
type WorkspaceSymbolOptions struct {
	ResolveProvider bool `json:"resolveProvider,omitempty"`
	WorkDoneProgressOptions
}
type WorkspaceSymbolParams struct {
	Query string `json:"query"`
	WorkDoneProgressParams
	PartialResultParams
}
type WorkspaceSymbolRegistrationOptions struct {
	WorkspaceSymbolOptions
}
type WorkspaceUnchangedDocumentDiagnosticReport struct {
	URI DocumentUri `json:"uri"`
	Version int32 `json:"version"`
	UnchangedDocumentDiagnosticReport
}
type XInitializeParams struct {
	ProcessID int32 `json:"processId"`
	ClientInfo *ClientInfo `json:"clientInfo,omitempty"`
	Locale string `json:"locale,omitempty"`
	RootPath string `json:"rootPath,omitempty"`
	RootURI DocumentUri `json:"rootUri"`
	Capabilities ClientCapabilities `json:"capabilities"`
	InitializationOptions interface{} `json:"initializationOptions,omitempty"`
type _InitializeParams struct {
	ProcessID int32 `json:"processId"`
	ClientInfo *ClientInfo `json:"clientInfo,omitempty"`
	Locale string `json:"locale,omitempty"`
	RootPath string `json:"rootPath,omitempty"`
	RootURI DocumentUri `json:"rootUri"`
	Capabilities ClientCapabilities `json:"capabilities"`
	InitializationOptions interface{} `json:"initializationOptions,omitempty"`
const (
	Empty CodeActionKind = ""
	// Base kind for quickfix actions: 'quickfix'
	QuickFix CodeActionKind = "quickfix"
	Refactor CodeActionKind = "refactor"
	RefactorExtract CodeActionKind = "refactor.extract"
	RefactorInline CodeActionKind = "refactor.inline"
	RefactorMove CodeActionKind = "refactor.move"
	RefactorRewrite CodeActionKind = "refactor.rewrite"
	Source CodeActionKind = "source"
	SourceOrganizeImports CodeActionKind = "source.organizeImports"
	SourceFixAll CodeActionKind = "source.fixAll"
	Notebook CodeActionKind = "notebook"
	CodeActionInvoked CodeActionTriggerKind = 1
	CodeActionAutomatic CodeActionTriggerKind = 2
	TextCompletion          CompletionItemKind = 1
	MethodCompletion        CompletionItemKind = 2
	FunctionCompletion      CompletionItemKind = 3
	ConstructorCompletion   CompletionItemKind = 4
	FieldCompletion         CompletionItemKind = 5
	VariableCompletion      CompletionItemKind = 6
	ClassCompletion         CompletionItemKind = 7
	InterfaceCompletion     CompletionItemKind = 8
	ModuleCompletion        CompletionItemKind = 9
	PropertyCompletion      CompletionItemKind = 10
	UnitCompletion          CompletionItemKind = 11
	ValueCompletion         CompletionItemKind = 12
	EnumCompletion          CompletionItemKind = 13
	KeywordCompletion       CompletionItemKind = 14
	SnippetCompletion       CompletionItemKind = 15
	ColorCompletion         CompletionItemKind = 16
	FileCompletion          CompletionItemKind = 17
	ReferenceCompletion     CompletionItemKind = 18
	FolderCompletion        CompletionItemKind = 19
	EnumMemberCompletion    CompletionItemKind = 20
	ConstantCompletion      CompletionItemKind = 21
	StructCompletion        CompletionItemKind = 22
	EventCompletion         CompletionItemKind = 23
	OperatorCompletion      CompletionItemKind = 24
	TypeParameterCompletion CompletionItemKind = 25
	ComplDeprecated CompletionItemTag = 1
	Invoked CompletionTriggerKind = 1
	TriggerCharacter CompletionTriggerKind = 2
	TriggerForIncompleteCompletions CompletionTriggerKind = 3
	SeverityError DiagnosticSeverity = 1
	SeverityWarning DiagnosticSeverity = 2
	SeverityInformation DiagnosticSeverity = 3
	SeverityHint DiagnosticSeverity = 4
	Unnecessary DiagnosticTag = 1
	Deprecated DiagnosticTag = 2
	DiagnosticFull DocumentDiagnosticReportKind = "full"
	DiagnosticUnchanged DocumentDiagnosticReportKind = "unchanged"
	Text DocumentHighlightKind = 1
	Read DocumentHighlightKind = 2
	Write DocumentHighlightKind = 3
	ParseError     ErrorCodes = -32700
	InvalidRequest ErrorCodes = -32600
	MethodNotFound ErrorCodes = -32601
	InvalidParams  ErrorCodes = -32602
	InternalError  ErrorCodes = -32603
	ServerNotInitialized ErrorCodes = -32002
	UnknownErrorCode     ErrorCodes = -32001
	Abort FailureHandlingKind = "abort"
	Transactional FailureHandlingKind = "transactional"
	TextOnlyTransactional FailureHandlingKind = "textOnlyTransactional"
	Undo FailureHandlingKind = "undo"
	Created FileChangeType = 1
	Changed FileChangeType = 2
	Deleted FileChangeType = 3
	FilePattern FileOperationPatternKind = "file"
	FolderPattern FileOperationPatternKind = "folder"
	Comment FoldingRangeKind = "comment"
	Imports FoldingRangeKind = "imports"
	Region FoldingRangeKind = "region"
	Type InlayHintKind = 1
	Parameter InlayHintKind = 2
	InlineInvoked InlineCompletionTriggerKind = 1
	InlineAutomatic InlineCompletionTriggerKind = 2
	PlainTextTextFormat InsertTextFormat = 1
	SnippetTextFormat InsertTextFormat = 2
	AsIs InsertTextMode = 1
	AdjustIndentation InsertTextMode = 2
	RequestFailed LSPErrorCodes = -32803
	ServerCancelled LSPErrorCodes = -32802
	ContentModified LSPErrorCodes = -32801
	RequestCancelled LSPErrorCodes = -32800
	LangABAP         LanguageKind = "abap"
	LangWindowsBat   LanguageKind = "bat"
	LangBibTeX       LanguageKind = "bibtex"
	LangClojure      LanguageKind = "clojure"
	LangCoffeescript LanguageKind = "coffeescript"
	LangC            LanguageKind = "c"
	LangCPP          LanguageKind = "cpp"
	LangCSharp       LanguageKind = "csharp"
	LangCSS          LanguageKind = "css"
	LangD LanguageKind = "d"
	LangDelphi          LanguageKind = "pascal"
	LangDiff            LanguageKind = "diff"
	LangDart            LanguageKind = "dart"
	LangDockerfile      LanguageKind = "dockerfile"
	LangElixir          LanguageKind = "elixir"
	LangErlang          LanguageKind = "erlang"
	LangFSharp          LanguageKind = "fsharp"
	LangGitCommit       LanguageKind = "git-commit"
	LangGitRebase       LanguageKind = "rebase"
	LangGo              LanguageKind = "go"
	LangGroovy          LanguageKind = "groovy"
	LangHandlebars      LanguageKind = "handlebars"
	LangHaskell         LanguageKind = "haskell"
	LangHTML            LanguageKind = "html"
	LangIni             LanguageKind = "ini"
	LangJava            LanguageKind = "java"
	LangJavaScript      LanguageKind = "javascript"
	LangJavaScriptReact LanguageKind = "javascriptreact"
	LangJSON            LanguageKind = "json"
	LangLaTeX           LanguageKind = "latex"
	LangLess            LanguageKind = "less"
	LangLua             LanguageKind = "lua"
	LangMakefile        LanguageKind = "makefile"
	LangMarkdown        LanguageKind = "markdown"
	LangObjectiveC      LanguageKind = "objective-c"
	LangObjectiveCPP    LanguageKind = "objective-cpp"
	LangPascal          LanguageKind = "pascal"
	LangPerl            LanguageKind = "perl"
	LangPerl6           LanguageKind = "perl6"
	LangPHP             LanguageKind = "php"
	LangPowershell      LanguageKind = "powershell"
	LangPug             LanguageKind = "jade"
	LangPython          LanguageKind = "python"
	LangR               LanguageKind = "r"
	LangRazor           LanguageKind = "razor"
	LangRuby            LanguageKind = "ruby"
	LangRust            LanguageKind = "rust"
	LangSCSS            LanguageKind = "scss"
	LangSASS            LanguageKind = "sass"
	LangScala           LanguageKind = "scala"
	LangShaderLab       LanguageKind = "shaderlab"
	LangShellScript     LanguageKind = "shellscript"
	LangSQL             LanguageKind = "sql"
	LangSwift           LanguageKind = "swift"
	LangTypeScript      LanguageKind = "typescript"
	LangTypeScriptReact LanguageKind = "typescriptreact"
	LangTeX             LanguageKind = "tex"
	LangVisualBasic     LanguageKind = "vb"
	LangXML             LanguageKind = "xml"
	LangXSL             LanguageKind = "xsl"
	LangYAML            LanguageKind = "yaml"
	PlainText MarkupKind = "plaintext"
	Markdown MarkupKind = "markdown"
	Error MessageType = 1
	Warning MessageType = 2
	Info MessageType = 3
	Log MessageType = 4
	Debug MessageType = 5
	Import MonikerKind = "import"
	Export MonikerKind = "export"
	Local MonikerKind = "local"
	Markup NotebookCellKind = 1
	Code NotebookCellKind = 2
	UTF8 PositionEncodingKind = "utf-8"
	UTF16 PositionEncodingKind = "utf-16"
	UTF32 PositionEncodingKind = "utf-32"
	Identifier PrepareSupportDefaultBehavior = 1
	Create ResourceOperationKind = "create"
	Rename ResourceOperationKind = "rename"
	Delete ResourceOperationKind = "delete"
	ModDeclaration    SemanticTokenModifiers = "declaration"
	ModDefinition     SemanticTokenModifiers = "definition"
	ModReadonly       SemanticTokenModifiers = "readonly"
	ModStatic         SemanticTokenModifiers = "static"
	ModDeprecated     SemanticTokenModifiers = "deprecated"
	ModAbstract       SemanticTokenModifiers = "abstract"
	ModAsync          SemanticTokenModifiers = "async"
	ModModification   SemanticTokenModifiers = "modification"
	ModDocumentation  SemanticTokenModifiers = "documentation"
	ModDefaultLibrary SemanticTokenModifiers = "defaultLibrary"
	NamespaceType SemanticTokenTypes = "namespace"
	TypeType          SemanticTokenTypes = "type"
	ClassType         SemanticTokenTypes = "class"
	EnumType          SemanticTokenTypes = "enum"
	InterfaceType     SemanticTokenTypes = "interface"
	StructType        SemanticTokenTypes = "struct"
	TypeParameterType SemanticTokenTypes = "typeParameter"
	ParameterType     SemanticTokenTypes = "parameter"
	VariableType      SemanticTokenTypes = "variable"
	PropertyType      SemanticTokenTypes = "property"
	EnumMemberType    SemanticTokenTypes = "enumMember"
	EventType         SemanticTokenTypes = "event"
	FunctionType      SemanticTokenTypes = "function"
	MethodType        SemanticTokenTypes = "method"
	MacroType         SemanticTokenTypes = "macro"
	KeywordType       SemanticTokenTypes = "keyword"
	ModifierType      SemanticTokenTypes = "modifier"
	CommentType       SemanticTokenTypes = "comment"
	StringType        SemanticTokenTypes = "string"
	NumberType        SemanticTokenTypes = "number"
	RegexpType        SemanticTokenTypes = "regexp"
	OperatorType      SemanticTokenTypes = "operator"
	DecoratorType SemanticTokenTypes = "decorator"
	LabelType SemanticTokenTypes = "label"
	SigInvoked SignatureHelpTriggerKind = 1
	SigTriggerCharacter SignatureHelpTriggerKind = 2
	SigContentChange SignatureHelpTriggerKind = 3
	File          SymbolKind = 1
	Module        SymbolKind = 2
	Namespace     SymbolKind = 3
	Package       SymbolKind = 4
	Class         SymbolKind = 5
	Method        SymbolKind = 6
	Property      SymbolKind = 7
	Field         SymbolKind = 8
	Constructor   SymbolKind = 9
	Enum          SymbolKind = 10
	Interface     SymbolKind = 11
	Function      SymbolKind = 12
	Variable      SymbolKind = 13
	Constant      SymbolKind = 14
	String        SymbolKind = 15
	Number        SymbolKind = 16
	Boolean       SymbolKind = 17
	Array         SymbolKind = 18
	Object        SymbolKind = 19
	Key           SymbolKind = 20
	Null          SymbolKind = 21
	EnumMember    SymbolKind = 22
	Struct        SymbolKind = 23
	Event         SymbolKind = 24
	Operator      SymbolKind = 25
	TypeParameter SymbolKind = 26
	DeprecatedSymbol SymbolTag = 1
	Manual TextDocumentSaveReason = 1
	AfterDelay TextDocumentSaveReason = 2
	FocusOut TextDocumentSaveReason = 3
	None TextDocumentSyncKind = 0
	Full TextDocumentSyncKind = 1
	Incremental TextDocumentSyncKind = 2
	Relative    TokenFormat          = "relative"
	Off TraceValue = "off"
	Messages TraceValue = "messages"
	Verbose TraceValue = "verbose"
	Document UniquenessLevel = "document"
	Project UniquenessLevel = "project"
	Group UniquenessLevel = "group"
	Scheme UniquenessLevel = "scheme"
	Global UniquenessLevel = "global"
	WatchCreate WatchKind = 1
	WatchChange WatchKind = 2
	WatchDelete WatchKind = 4
)
⋮----
// Base kind for quickfix actions: 'quickfix'
</file>

<file path="internal/lsp/protocol/uri.go">
package protocol
import (
	"fmt"
	"net/url"
	"path/filepath"
	"strings"
	"unicode"
)
⋮----
"fmt"
"net/url"
"path/filepath"
"strings"
"unicode"
⋮----
type DocumentUri string
⋮----
func (uri *DocumentUri) UnmarshalText(data []byte) (err error)
func (uri DocumentUri) Path() string
func (uri DocumentUri) Dir() DocumentUri
func (uri DocumentUri) DirPath() string
func filename(uri DocumentUri) (string, error)
⋮----
// This conservative check for the common case
// of a simple non-empty absolute POSIX filename
// avoids the allocation of a net.URL.
⋮----
func ParseDocumentUri(s string) (DocumentUri, error)
⋮----
// File URIs from Windows may have lowercase drive letters.
// Since drive letters are guaranteed to be case insensitive,
// we change them to uppercase to remain consistent.
// For example, file:///c:/x/y/z becomes file:///C:/x/y/z.
⋮----
// URIFromPath returns DocumentUri for the supplied file path.
// Given "", it returns "".
func URIFromPath(path string) DocumentUri
⋮----
// Check the file path again, in case it became absolute.
⋮----
const fileScheme = "file"
func isWindowsDrivePath(path string) bool
func isWindowsDriveURIPath(uri string) bool
</file>

<file path="internal/lsp/protocol.go">
package lsp
import (
	"encoding/json"
)
⋮----
"encoding/json"
⋮----
type Message struct {
	JSONRPC string          `json:"jsonrpc"`
	ID      int32           `json:"id,omitempty"`
	Method  string          `json:"method,omitempty"`
	Params  json.RawMessage `json:"params,omitempty"`
	Result  json.RawMessage `json:"result,omitempty"`
	Error   *ResponseError  `json:"error,omitempty"`
}
type ResponseError struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
}
func NewRequest(id int32, method string, params any) (*Message, error)
func NewNotification(method string, params any) (*Message, error)
</file>

<file path="internal/pubsub/events.go">
package pubsub
import "context"
const (
	CreatedEvent EventType = "created"
	UpdatedEvent EventType = "updated"
	DeletedEvent EventType = "deleted"
)
type Suscriber[T any] interface {
	Subscribe(context.Context) <-chan Event[T]
}
⋮----
EventType string
Event[T any] struct {
		Type    EventType
		Payload T
	}
Publisher[T any] interface {
		Publish(EventType, T)
	}
</file>

<file path="internal/request/tracker.go">
package request
import (
	"sync"
)
⋮----
"sync"
⋮----
type RequestInfo struct {
	Provider string
	Model    string
	URL      string
}
var (
	currentRequest RequestInfo
	mu             sync.RWMutex
)
func SetCurrent(provider, model, url string)
func GetCurrent() RequestInfo
func Clear()
</file>

<file path="internal/tui/layout/layout.go">
package layout
import (
	"reflect"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
)
⋮----
"reflect"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
⋮----
type Focusable interface {
	Focus() tea.Cmd
	Blur() tea.Cmd
	IsFocused() bool
}
type Sizeable interface {
	SetSize(width, height int) tea.Cmd
	GetSize() (int, int)
}
type Bindings interface {
	BindingKeys() []key.Binding
}
func KeyMapToSlice(t any) (bindings []key.Binding)
</file>

<file path="internal/tui/page/page.go">
package page
type PageID string
type PageChangeMsg struct {
	ID PageID
}
</file>

<file path="internal/tui/styles/background.go">
package styles
import (
	"fmt"
	"regexp"
	"strings"
	"github.com/charmbracelet/lipgloss"
)
⋮----
"fmt"
"regexp"
"strings"
"github.com/charmbracelet/lipgloss"
⋮----
var ansiEscape = regexp.MustCompile("\x1b\\[[0-9;]*m")
func getColorRGB(c lipgloss.TerminalColor) (uint8, uint8, uint8)
func ForceReplaceBackgroundWithLipgloss(input string, newBgColor lipgloss.TerminalColor) string
⋮----
const (
			escPrefixLen = 2
			escSuffixLen = 1
		)
⋮----
var sb strings.Builder
</file>

<file path="internal/tui/util/util.go">
package util
import (
	"time"
	tea "github.com/charmbracelet/bubbletea"
)
⋮----
"time"
tea "github.com/charmbracelet/bubbletea"
⋮----
func CmdHandler(msg tea.Msg) tea.Cmd
func ReportError(err error) tea.Cmd
type InfoType int
const (
	InfoTypeInfo InfoType = iota
	InfoTypeWarn
	InfoTypeError
)
func ReportInfo(info string) tea.Cmd
func ReportWarn(warn string) tea.Cmd
⋮----
InfoMsg struct {
		Type InfoType
		Msg  string
		TTL  time.Duration
	}
ClearStatusMsg struct{}
⋮----
func Clamp(v, low, high int) int
</file>

<file path="repomix.config.json">
{
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "removeComments": true,
    "removeEmptyLines": true,
    "topFilesLength": 10,
    "showLineNumbers": false,
    "copyToClipboard": false,
    "compress": true
  },
  "include": [
    "**/*.go",
    "**/*.md",
    "go.mod",
    "go.sum",
    "Makefile",
    ".goreleaser.yaml",
    "**/*.json",
    "**/*.yaml",
    "**/*.yml",
    "**/*.sh"
  ],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": [
      "**/vendor/**",
      "**/node_modules/**",
      "**/.git/**",
      "**/dist/**",
      "**/build/**",
      "**/*.log",
      "**/*.db",
      "**/*.db-*",
      "**/tmp/**",
      "**/.opencode/**",
      "**/testdata/**",
      "**/mocks/**",
      "**/*_test.go",
      "**/docs/api/**",
      "**/*.png",
      "**/*.jpg",
      "**/*.gif",
      "**/*.ico",
      "**/*.svg",
      "**/internal/llm/provider/xai.go.bak",
      "**/kb/**",
      "**/*.patch"
    ]
  },
  "security": {
    "enableSecurityCheck": true
  }
}
</file>

<file path="sqlc.yaml">
version: "2"
sql:
  - engine: "sqlite"
    schema: "internal/db/migrations"
    queries: "internal/db/sql"
    gen:
      go:
        package: "db"
        out: "internal/db"
        emit_json_tags: true
        emit_prepared_queries: true
        emit_interface: true
        emit_exact_table_names: false
        emit_empty_slices: true
</file>

<file path="test_request_display.sh">
echo "Testing request display functionality..."
echo "1. Start OpenCode"
echo "2. Send a message to trigger a request"
echo "3. Check that request info appears below LSP Configuration"
echo "4. Switch models to verify the request info updates"
echo "5. Test error handling by canceling a request"
echo ""
echo "Monitoring requests.log for activity..."
tail -f ~/.opencode/requests.log &
TAIL_PID=$!
# Give user instructions
echo ""
echo "Press Ctrl+C to stop monitoring"
echo ""
# Wait for user to stop
trap "kill $TAIL_PID 2>/dev/null; exit" INT
wait
</file>

<file path="internal/app/lsp.go">
package app
import (
	"context"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/lsp/watcher"
)
⋮----
"context"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/lsp/watcher"
⋮----
func (app *App) initLSPClients(ctx context.Context)
func (app *App) createAndStartLSPClient(ctx context.Context, name string, command string, args ...string)
func (app *App) runWorkspaceWatcher(ctx context.Context, name string, workspaceWatcher *watcher.WorkspaceWatcher)
func (app *App) restartLSPClient(ctx context.Context, name string)
</file>

<file path="internal/completions/files-folders.go">
package completions
import (
	"bytes"
	"fmt"
	"os/exec"
	"path/filepath"
	"github.com/lithammer/fuzzysearch/fuzzy"
	"github.com/opencode-ai/opencode/internal/fileutil"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/tui/components/dialog"
)
⋮----
"bytes"
"fmt"
"os/exec"
"path/filepath"
"github.com/lithammer/fuzzysearch/fuzzy"
"github.com/opencode-ai/opencode/internal/fileutil"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/tui/components/dialog"
⋮----
type filesAndFoldersContextGroup struct {
	prefix string
}
func (cg *filesAndFoldersContextGroup) GetId() string
func (cg *filesAndFoldersContextGroup) GetEntry() dialog.CompletionItemI
func processNullTerminatedOutput(outputBytes []byte) []string
func (cg *filesAndFoldersContextGroup) getFiles(query string) ([]string, error)
⋮----
cmdRg := fileutil.GetRgCmd("") // No glob pattern for this use case
⋮----
var matches []string
// Case 1: Both rg and fzf available
⋮----
var fzfOut bytes.Buffer
var fzfErr bytes.Buffer
⋮----
var rgOut bytes.Buffer
var rgErr bytes.Buffer
⋮----
var fzfIn bytes.Buffer
⋮----
func (cg *filesAndFoldersContextGroup) GetChildEntries(query string) ([]dialog.CompletionItemI, error)
func NewFileAndFolderContextGroup() dialog.CompletionProvider
</file>

<file path="internal/config/init.go">
package config
import (
	"fmt"
	"os"
	"path/filepath"
)
⋮----
"fmt"
"os"
"path/filepath"
⋮----
const (
	InitFlagFilename = "init"
)
type ProjectInitFlag struct {
	Initialized bool `json:"initialized"`
}
func ShouldShowInitDialog() (bool, error)
func MarkProjectInitialized() error
</file>

<file path="internal/db/db.go">
package db
import (
	"context"
	"database/sql"
	"fmt"
)
⋮----
"context"
"database/sql"
"fmt"
⋮----
type DBTX interface {
	ExecContext(context.Context, string, ...interface{}) (sql.Result, error)
func New(db DBTX) *Queries
func Prepare(ctx context.Context, db DBTX) (*Queries, error)
⋮----
var err error
⋮----
func (q *Queries) Close() error
func (q *Queries) exec(ctx context.Context, stmt *sql.Stmt, query string, args ...interface
func (q *Queries) query(ctx context.Context, stmt *sql.Stmt, query string, args ...interface
func (q *Queries) queryRow(ctx context.Context, stmt *sql.Stmt, query string, args ...interface
type Queries struct {
	db                          DBTX
	tx                          *sql.Tx
	createFileStmt              *sql.Stmt
	createMessageStmt           *sql.Stmt
	createSessionStmt           *sql.Stmt
	deleteFileStmt              *sql.Stmt
	deleteMessageStmt           *sql.Stmt
	deleteSessionStmt           *sql.Stmt
	deleteSessionFilesStmt      *sql.Stmt
	deleteSessionMessagesStmt   *sql.Stmt
	getFileStmt                 *sql.Stmt
	getFileByPathAndSessionStmt *sql.Stmt
	getMessageStmt              *sql.Stmt
	getSessionByIDStmt          *sql.Stmt
	listFilesByPathStmt         *sql.Stmt
	listFilesBySessionStmt      *sql.Stmt
	listLatestSessionFilesStmt  *sql.Stmt
	listMessagesBySessionStmt   *sql.Stmt
	listNewFilesStmt            *sql.Stmt
	listSessionsStmt            *sql.Stmt
	updateFileStmt              *sql.Stmt
	updateMessageStmt           *sql.Stmt
	updateSessionStmt           *sql.Stmt
}
func (q *Queries) WithTx(tx *sql.Tx) *Queries
</file>

<file path="internal/db/files.sql.go">
package db
import (
	"context"
)
⋮----
"context"
⋮----
const createFile = `-- name: CreateFile :one
INSERT INTO files (
    id,
    session_id,
    path,
    content,
    version,
    created_at,
    updated_at
) VALUES (
    ?, ?, ?, ?, ?, strftime('%s', 'now'), strftime('%s', 'now')
)
RETURNING id, session_id, path, content, version, created_at, updated_at
`
type CreateFileParams struct {
	ID        string `json:"id"`
	SessionID string `json:"session_id"`
	Path      string `json:"path"`
	Content   string `json:"content"`
	Version   string `json:"version"`
}
func (q *Queries) CreateFile(ctx context.Context, arg CreateFileParams) (File, error)
⋮----
var i File
⋮----
const deleteFile = `-- name: DeleteFile :exec
DELETE FROM files
WHERE id = ?
`
func (q *Queries) DeleteFile(ctx context.Context, id string) error
const deleteSessionFiles = `-- name: DeleteSessionFiles :exec
DELETE FROM files
WHERE session_id = ?
`
func (q *Queries) DeleteSessionFiles(ctx context.Context, sessionID string) error
const getFile = `-- name: GetFile :one
SELECT id, session_id, path, content, version, created_at, updated_at
FROM files
WHERE id = ? LIMIT 1
`
func (q *Queries) GetFile(ctx context.Context, id string) (File, error)
const getFileByPathAndSession = `-- name: GetFileByPathAndSession :one
SELECT id, session_id, path, content, version, created_at, updated_at
FROM files
WHERE path = ? AND session_id = ?
ORDER BY created_at DESC
LIMIT 1
`
type GetFileByPathAndSessionParams struct {
	Path      string `json:"path"`
	SessionID string `json:"session_id"`
}
func (q *Queries) GetFileByPathAndSession(ctx context.Context, arg GetFileByPathAndSessionParams) (File, error)
const listFilesByPath = `-- name: ListFilesByPath :many
SELECT id, session_id, path, content, version, created_at, updated_at
FROM files
WHERE path = ?
ORDER BY created_at DESC
`
func (q *Queries) ListFilesByPath(ctx context.Context, path string) ([]File, error)
⋮----
var i File
⋮----
const listFilesBySession = `-- name: ListFilesBySession :many
SELECT id, session_id, path, content, version, created_at, updated_at
FROM files
WHERE session_id = ?
ORDER BY created_at ASC
`
func (q *Queries) ListFilesBySession(ctx context.Context, sessionID string) ([]File, error)
const listLatestSessionFiles = `-- name: ListLatestSessionFiles :many
SELECT f.id, f.session_id, f.path, f.content, f.version, f.created_at, f.updated_at
FROM files f
INNER JOIN (
    SELECT path, MAX(created_at) as max_created_at
    FROM files
    GROUP BY path
) latest ON f.path = latest.path AND f.created_at = latest.max_created_at
WHERE f.session_id = ?
ORDER BY f.path
`
func (q *Queries) ListLatestSessionFiles(ctx context.Context, sessionID string) ([]File, error)
const listNewFiles = `-- name: ListNewFiles :many
SELECT id, session_id, path, content, version, created_at, updated_at
FROM files
WHERE is_new = 1
ORDER BY created_at DESC
`
func (q *Queries) ListNewFiles(ctx context.Context) ([]File, error)
const updateFile = `-- name: UpdateFile :one
UPDATE files
SET
    content = ?,
    version = ?,
    updated_at = strftime('%s', 'now')
WHERE id = ?
RETURNING id, session_id, path, content, version, created_at, updated_at
`
type UpdateFileParams struct {
	Content string `json:"content"`
	Version string `json:"version"`
	ID      string `json:"id"`
}
func (q *Queries) UpdateFile(ctx context.Context, arg UpdateFileParams) (File, error)
</file>

<file path="internal/db/messages.sql.go">
package db
import (
	"context"
	"database/sql"
)
⋮----
"context"
"database/sql"
⋮----
const createMessage = `-- name: CreateMessage :one
INSERT INTO messages (
    id,
    session_id,
    role,
    parts,
    model,
    created_at,
    updated_at
) VALUES (
    ?, ?, ?, ?, ?, strftime('%s', 'now'), strftime('%s', 'now')
)
RETURNING id, session_id, role, parts, model, created_at, updated_at, finished_at
`
type CreateMessageParams struct {
	ID        string         `json:"id"`
	SessionID string         `json:"session_id"`
	Role      string         `json:"role"`
	Parts     string         `json:"parts"`
	Model     sql.NullString `json:"model"`
}
func (q *Queries) CreateMessage(ctx context.Context, arg CreateMessageParams) (Message, error)
⋮----
var i Message
⋮----
const deleteMessage = `-- name: DeleteMessage :exec
DELETE FROM messages
WHERE id = ?
`
func (q *Queries) DeleteMessage(ctx context.Context, id string) error
const deleteSessionMessages = `-- name: DeleteSessionMessages :exec
DELETE FROM messages
WHERE session_id = ?
`
func (q *Queries) DeleteSessionMessages(ctx context.Context, sessionID string) error
const getMessage = `-- name: GetMessage :one
SELECT id, session_id, role, parts, model, created_at, updated_at, finished_at
FROM messages
WHERE id = ? LIMIT 1
`
func (q *Queries) GetMessage(ctx context.Context, id string) (Message, error)
const listMessagesBySession = `-- name: ListMessagesBySession :many
SELECT id, session_id, role, parts, model, created_at, updated_at, finished_at
FROM messages
WHERE session_id = ?
ORDER BY created_at ASC
`
func (q *Queries) ListMessagesBySession(ctx context.Context, sessionID string) ([]Message, error)
⋮----
var i Message
⋮----
const updateMessage = `-- name: UpdateMessage :exec
UPDATE messages
SET
    parts = ?,
    finished_at = ?,
    updated_at = strftime('%s', 'now')
WHERE id = ?
`
type UpdateMessageParams struct {
	Parts      string        `json:"parts"`
	FinishedAt sql.NullInt64 `json:"finished_at"`
	ID         string        `json:"id"`
}
func (q *Queries) UpdateMessage(ctx context.Context, arg UpdateMessageParams) error
</file>

<file path="internal/db/models.go">
package db
import (
	"database/sql"
)
⋮----
"database/sql"
⋮----
type File struct {
	ID        string `json:"id"`
	SessionID string `json:"session_id"`
	Path      string `json:"path"`
	Content   string `json:"content"`
	Version   string `json:"version"`
	CreatedAt int64  `json:"created_at"`
	UpdatedAt int64  `json:"updated_at"`
}
type Message struct {
	ID         string         `json:"id"`
	SessionID  string         `json:"session_id"`
	Role       string         `json:"role"`
	Parts      string         `json:"parts"`
	Model      sql.NullString `json:"model"`
	CreatedAt  int64          `json:"created_at"`
	UpdatedAt  int64          `json:"updated_at"`
	FinishedAt sql.NullInt64  `json:"finished_at"`
}
type Session struct {
	ID               string         `json:"id"`
	ParentSessionID  sql.NullString `json:"parent_session_id"`
	Title            string         `json:"title"`
	MessageCount     int64          `json:"message_count"`
	PromptTokens     int64          `json:"prompt_tokens"`
	CompletionTokens int64          `json:"completion_tokens"`
	Cost             float64        `json:"cost"`
	UpdatedAt        int64          `json:"updated_at"`
	CreatedAt        int64          `json:"created_at"`
	SummaryMessageID sql.NullString `json:"summary_message_id"`
}
</file>

<file path="internal/db/querier.go">
package db
import (
	"context"
)
⋮----
"context"
⋮----
type Querier interface {
	CreateFile(ctx context.Context, arg CreateFileParams) (File, error)
	CreateMessage(ctx context.Context, arg CreateMessageParams) (Message, error)
	CreateSession(ctx context.Context, arg CreateSessionParams) (Session, error)
	DeleteFile(ctx context.Context, id string) error
	DeleteMessage(ctx context.Context, id string) error
	DeleteSession(ctx context.Context, id string) error
	DeleteSessionFiles(ctx context.Context, sessionID string) error
	DeleteSessionMessages(ctx context.Context, sessionID string) error
	GetFile(ctx context.Context, id string) (File, error)
	GetFileByPathAndSession(ctx context.Context, arg GetFileByPathAndSessionParams) (File, error)
	GetMessage(ctx context.Context, id string) (Message, error)
	GetSessionByID(ctx context.Context, id string) (Session, error)
	ListFilesByPath(ctx context.Context, path string) ([]File, error)
	ListFilesBySession(ctx context.Context, sessionID string) ([]File, error)
	ListLatestSessionFiles(ctx context.Context, sessionID string) ([]File, error)
	ListMessagesBySession(ctx context.Context, sessionID string) ([]Message, error)
	ListNewFiles(ctx context.Context) ([]File, error)
	ListSessions(ctx context.Context) ([]Session, error)
	UpdateFile(ctx context.Context, arg UpdateFileParams) (File, error)
	UpdateMessage(ctx context.Context, arg UpdateMessageParams) error
	UpdateSession(ctx context.Context, arg UpdateSessionParams) (Session, error)
}
var _ Querier = (*Queries)(nil)
</file>

<file path="internal/db/sessions.sql.go">
package db
import (
	"context"
	"database/sql"
)
⋮----
"context"
"database/sql"
⋮----
const createSession = `-- name: CreateSession :one
INSERT INTO sessions (
    id,
    parent_session_id,
    title,
    message_count,
    prompt_tokens,
    completion_tokens,
    cost,
    summary_message_id,
    updated_at,
    created_at
) VALUES (
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    null,
    strftime('%s', 'now'),
    strftime('%s', 'now')
) RETURNING id, parent_session_id, title, message_count, prompt_tokens, completion_tokens, cost, updated_at, created_at, summary_message_id
`
type CreateSessionParams struct {
	ID               string         `json:"id"`
	ParentSessionID  sql.NullString `json:"parent_session_id"`
	Title            string         `json:"title"`
	MessageCount     int64          `json:"message_count"`
	PromptTokens     int64          `json:"prompt_tokens"`
	CompletionTokens int64          `json:"completion_tokens"`
	Cost             float64        `json:"cost"`
}
func (q *Queries) CreateSession(ctx context.Context, arg CreateSessionParams) (Session, error)
⋮----
var i Session
⋮----
const deleteSession = `-- name: DeleteSession :exec
DELETE FROM sessions
WHERE id = ?
`
func (q *Queries) DeleteSession(ctx context.Context, id string) error
const getSessionByID = `-- name: GetSessionByID :one
SELECT id, parent_session_id, title, message_count, prompt_tokens, completion_tokens, cost, updated_at, created_at, summary_message_id
FROM sessions
WHERE id = ? LIMIT 1
`
func (q *Queries) GetSessionByID(ctx context.Context, id string) (Session, error)
const listSessions = `-- name: ListSessions :many
SELECT id, parent_session_id, title, message_count, prompt_tokens, completion_tokens, cost, updated_at, created_at, summary_message_id
FROM sessions
WHERE parent_session_id is NULL
ORDER BY created_at DESC
`
func (q *Queries) ListSessions(ctx context.Context) ([]Session, error)
⋮----
var i Session
⋮----
const updateSession = `-- name: UpdateSession :one
UPDATE sessions
SET
    title = ?,
    prompt_tokens = ?,
    completion_tokens = ?,
    summary_message_id = ?,
    cost = ?
WHERE id = ?
RETURNING id, parent_session_id, title, message_count, prompt_tokens, completion_tokens, cost, updated_at, created_at, summary_message_id
`
type UpdateSessionParams struct {
	Title            string         `json:"title"`
	PromptTokens     int64          `json:"prompt_tokens"`
	CompletionTokens int64          `json:"completion_tokens"`
	SummaryMessageID sql.NullString `json:"summary_message_id"`
	Cost             float64        `json:"cost"`
	ID               string         `json:"id"`
}
func (q *Queries) UpdateSession(ctx context.Context, arg UpdateSessionParams) (Session, error)
</file>

<file path="internal/fileutil/fileutil.go">
package fileutil
import (
	"fmt"
	"io/fs"
	"os"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
	"time"
	"github.com/bmatcuk/doublestar/v4"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"fmt"
"io/fs"
"os"
"os/exec"
"path/filepath"
"sort"
"strings"
"time"
"github.com/bmatcuk/doublestar/v4"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
var (
	rgPath  string
	fzfPath string
)
func init()
⋮----
var err error
⋮----
func GetRgCmd(globPattern string) *exec.Cmd
func GetFzfCmd(query string) *exec.Cmd
type FileInfo struct {
	Path    string
	ModTime time.Time
}
func SkipHidden(path string) bool
func GlobWithDoublestar(pattern, searchPath string, limit int) ([]string, bool, error)
⋮----
var matches []FileInfo
</file>

<file path="internal/format/format.go">
package format
import (
	"encoding/json"
	"fmt"
	"strings"
)
⋮----
"encoding/json"
"fmt"
"strings"
⋮----
type OutputFormat string
const (
	Text OutputFormat = "text"
	JSON OutputFormat = "json"
)
func (f OutputFormat) String() string
var SupportedFormats = []string{
	string(Text),
	string(JSON),
}
func Parse(s string) (OutputFormat, error)
func IsValid(s string) bool
func GetHelpText() string
func FormatOutput(content string, formatStr string) string
func formatAsJSON(content string) string
⋮----
// In case of an error, return a manually formatted JSON
</file>

<file path="internal/format/spinner.go">
package format
import (
	"context"
	"fmt"
	"os"
	"github.com/charmbracelet/bubbles/spinner"
	tea "github.com/charmbracelet/bubbletea"
)
⋮----
"context"
"fmt"
"os"
"github.com/charmbracelet/bubbles/spinner"
tea "github.com/charmbracelet/bubbletea"
⋮----
type Spinner struct {
	model  spinner.Model
	done   chan struct{}
type spinnerModel struct {
	spinner  spinner.Model
	message  string
	quitting bool
}
func (m spinnerModel) Init() tea.Cmd
func (m spinnerModel) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmd tea.Cmd
⋮----
func (m spinnerModel) View() string
type quitMsg struct{}
func NewSpinner(message string) *Spinner
func (s *Spinner) Start()
func (s *Spinner) Stop()
</file>

<file path="internal/history/file.go">
package history
import (
	"context"
	"database/sql"
	"fmt"
	"strconv"
	"strings"
	"time"
	"github.com/google/uuid"
	"github.com/opencode-ai/opencode/internal/db"
	"github.com/opencode-ai/opencode/internal/pubsub"
)
⋮----
"context"
"database/sql"
"fmt"
"strconv"
"strings"
"time"
"github.com/google/uuid"
"github.com/opencode-ai/opencode/internal/db"
"github.com/opencode-ai/opencode/internal/pubsub"
⋮----
const (
	InitialVersion = "initial"
)
type File struct {
	ID        string
	SessionID string
	Path      string
	Content   string
	Version   string
	CreatedAt int64
	UpdatedAt int64
}
type Service interface {
	pubsub.Suscriber[File]
	Create(ctx context.Context, sessionID, path, content string) (File, error)
	CreateVersion(ctx context.Context, sessionID, path, content string) (File, error)
	Get(ctx context.Context, id string) (File, error)
	GetByPathAndSession(ctx context.Context, path, sessionID string) (File, error)
	ListBySession(ctx context.Context, sessionID string) ([]File, error)
	ListLatestSessionFiles(ctx context.Context, sessionID string) ([]File, error)
	Update(ctx context.Context, file File) (File, error)
	Delete(ctx context.Context, id string) error
	DeleteSessionFiles(ctx context.Context, sessionID string) error
}
type service struct {
	*pubsub.Broker[File]
	db *sql.DB
	q  *db.Queries
}
func NewService(q *db.Queries, db *sql.DB) Service
func (s *service) Create(ctx context.Context, sessionID, path, content string) (File, error)
func (s *service) CreateVersion(ctx context.Context, sessionID, path, content string) (File, error)
⋮----
var nextVersion string
⋮----
func (s *service) createWithVersion(ctx context.Context, sessionID, path, content, version string) (File, error)
⋮----
const maxRetries = 3
var file File
var err error
⋮----
func (s *service) Get(ctx context.Context, id string) (File, error)
func (s *service) GetByPathAndSession(ctx context.Context, path, sessionID string) (File, error)
func (s *service) ListBySession(ctx context.Context, sessionID string) ([]File, error)
func (s *service) ListLatestSessionFiles(ctx context.Context, sessionID string) ([]File, error)
func (s *service) Update(ctx context.Context, file File) (File, error)
func (s *service) Delete(ctx context.Context, id string) error
func (s *service) DeleteSessionFiles(ctx context.Context, sessionID string) error
func (s *service) fromDBItem(item db.File) File
</file>

<file path="internal/llm/agent/tools.go">
package agent
import (
	"context"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/session"
)
⋮----
"context"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/session"
⋮----
func CoderAgentTools(
	permissions permission.Service,
	sessions session.Service,
	messages message.Service,
	history history.Service,
	lspClients map[string]*lsp.Client,
) []tools.BaseTool
func TaskAgentTools(lspClients map[string]*lsp.Client) []tools.BaseTool
</file>

<file path="internal/llm/models/copilot.go">
package models
const (
	ProviderCopilot ModelProvider = "copilot"
	CopilotGTP35Turbo      ModelID = "copilot.gpt-3.5-turbo"
	CopilotGPT4o           ModelID = "copilot.gpt-4o"
	CopilotGPT4oMini       ModelID = "copilot.gpt-4o-mini"
	CopilotGPT41           ModelID = "copilot.gpt-4.1"
	CopilotClaude35        ModelID = "copilot.claude-3.5-sonnet"
	CopilotClaude37        ModelID = "copilot.claude-3.7-sonnet"
	CopilotClaude4         ModelID = "copilot.claude-sonnet-4"
	CopilotO1              ModelID = "copilot.o1"
	CopilotO3Mini          ModelID = "copilot.o3-mini"
	CopilotO4Mini          ModelID = "copilot.o4-mini"
	CopilotGemini20        ModelID = "copilot.gemini-2.0-flash"
	CopilotGemini25        ModelID = "copilot.gemini-2.5-pro"
	CopilotGPT4            ModelID = "copilot.gpt-4"
	CopilotClaude37Thought ModelID = "copilot.claude-3.7-sonnet-thought"
)
var CopilotAnthropicModels = []ModelID{
	CopilotClaude35,
	CopilotClaude37,
	CopilotClaude37Thought,
	CopilotClaude4,
}
var CopilotModels = map[ModelID]Model{
	CopilotGTP35Turbo: {
		ID:                  CopilotGTP35Turbo,
		Name:                "GitHub Copilot GPT-3.5-turbo",
		Provider:            ProviderCopilot,
		APIModel:            "gpt-3.5-turbo",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       16_384,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	CopilotGPT4o: {
		ID:                  CopilotGPT4o,
		Name:                "GitHub Copilot GPT-4o",
		Provider:            ProviderCopilot,
		APIModel:            "gpt-4o",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    16384,
		SupportsAttachments: true,
	},
	CopilotGPT4oMini: {
		ID:                  CopilotGPT4oMini,
		Name:                "GitHub Copilot GPT-4o Mini",
		Provider:            ProviderCopilot,
		APIModel:            "gpt-4o-mini",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	CopilotGPT41: {
		ID:                  CopilotGPT41,
		Name:                "GitHub Copilot GPT-4.1",
		Provider:            ProviderCopilot,
		APIModel:            "gpt-4.1",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    16384,
		CanReason:           true,
		SupportsAttachments: true,
	},
	CopilotClaude35: {
		ID:                  CopilotClaude35,
		Name:                "GitHub Copilot Claude 3.5 Sonnet",
		Provider:            ProviderCopilot,
		APIModel:            "claude-3.5-sonnet",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       90_000,
		DefaultMaxTokens:    8192,
		SupportsAttachments: true,
	},
	CopilotClaude37: {
		ID:                  CopilotClaude37,
		Name:                "GitHub Copilot Claude 3.7 Sonnet",
		Provider:            ProviderCopilot,
		APIModel:            "claude-3.7-sonnet",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       200_000,
		DefaultMaxTokens:    16384,
		SupportsAttachments: true,
	},
	CopilotClaude4: {
		ID:                  CopilotClaude4,
		Name:                "GitHub Copilot Claude Sonnet 4",
		Provider:            ProviderCopilot,
		APIModel:            "claude-sonnet-4",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    16000,
		SupportsAttachments: true,
	},
	CopilotO1: {
		ID:                  CopilotO1,
		Name:                "GitHub Copilot o1",
		Provider:            ProviderCopilot,
		APIModel:            "o1",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       200_000,
		DefaultMaxTokens:    100_000,
		CanReason:           true,
		SupportsAttachments: false,
	},
	CopilotO3Mini: {
		ID:                  CopilotO3Mini,
		Name:                "GitHub Copilot o3-mini",
		Provider:            ProviderCopilot,
		APIModel:            "o3-mini",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       200_000,
		DefaultMaxTokens:    100_000,
		CanReason:           true,
		SupportsAttachments: false,
	},
	CopilotO4Mini: {
		ID:                  CopilotO4Mini,
		Name:                "GitHub Copilot o4-mini",
		Provider:            ProviderCopilot,
		APIModel:            "o4-mini",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    16_384,
		CanReason:           true,
		SupportsAttachments: true,
	},
	CopilotGemini20: {
		ID:                  CopilotGemini20,
		Name:                "GitHub Copilot Gemini 2.0 Flash",
		Provider:            ProviderCopilot,
		APIModel:            "gemini-2.0-flash-001",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       1_000_000,
		DefaultMaxTokens:    8192,
		SupportsAttachments: true,
	},
	CopilotGemini25: {
		ID:                  CopilotGemini25,
		Name:                "GitHub Copilot Gemini 2.5 Pro",
		Provider:            ProviderCopilot,
		APIModel:            "gemini-2.5-pro",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       128_000,
		DefaultMaxTokens:    64000,
		SupportsAttachments: true,
	},
	CopilotGPT4: {
		ID:                  CopilotGPT4,
		Name:                "GitHub Copilot GPT-4",
		Provider:            ProviderCopilot,
		APIModel:            "gpt-4",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       32_768,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	CopilotClaude37Thought: {
		ID:                  CopilotClaude37Thought,
		Name:                "GitHub Copilot Claude 3.7 Sonnet Thinking",
		Provider:            ProviderCopilot,
		APIModel:            "claude-3.7-sonnet-thought",
		CostPer1MIn:         0.0,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.0,
		ContextWindow:       200_000,
		DefaultMaxTokens:    16384,
		CanReason:           true,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/openai.go">
package models
const (
	ProviderOpenAI ModelProvider = "openai"
	GPT41        ModelID = "gpt-4.1"
	GPT41Mini    ModelID = "gpt-4.1-mini"
	GPT41Nano    ModelID = "gpt-4.1-nano"
	GPT45Preview ModelID = "gpt-4.5-preview"
	GPT4o        ModelID = "gpt-4o"
	GPT4oMini    ModelID = "gpt-4o-mini"
	O1           ModelID = "o1"
	O1Pro        ModelID = "o1-pro"
	O1Mini       ModelID = "o1-mini"
	O3           ModelID = "o3"
	O3Mini       ModelID = "o3-mini"
	O4Mini       ModelID = "o4-mini"
)
var OpenAIModels = map[ModelID]Model{
	GPT41: {
		ID:                  GPT41,
		Name:                "GPT 4.1",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4.1",
		CostPer1MIn:         2.00,
		CostPer1MInCached:   0.50,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        8.00,
		ContextWindow:       1_047_576,
		DefaultMaxTokens:    20000,
		SupportsAttachments: true,
	},
	GPT41Mini: {
		ID:                  GPT41Mini,
		Name:                "GPT 4.1 mini",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4.1",
		CostPer1MIn:         0.40,
		CostPer1MInCached:   0.10,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        1.60,
		ContextWindow:       200_000,
		DefaultMaxTokens:    20000,
		SupportsAttachments: true,
	},
	GPT41Nano: {
		ID:                  GPT41Nano,
		Name:                "GPT 4.1 nano",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4.1-nano",
		CostPer1MIn:         0.10,
		CostPer1MInCached:   0.025,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.40,
		ContextWindow:       1_047_576,
		DefaultMaxTokens:    20000,
		SupportsAttachments: true,
	},
	GPT45Preview: {
		ID:                  GPT45Preview,
		Name:                "GPT 4.5 preview",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4.5-preview",
		CostPer1MIn:         75.00,
		CostPer1MInCached:   37.50,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        150.00,
		ContextWindow:       128_000,
		DefaultMaxTokens:    15000,
		SupportsAttachments: true,
	},
	GPT4o: {
		ID:                  GPT4o,
		Name:                "GPT 4o",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4o",
		CostPer1MIn:         2.50,
		CostPer1MInCached:   1.25,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        10.00,
		ContextWindow:       128_000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	GPT4oMini: {
		ID:                  GPT4oMini,
		Name:                "GPT 4o mini",
		Provider:            ProviderOpenAI,
		APIModel:            "gpt-4o-mini",
		CostPer1MIn:         0.15,
		CostPer1MInCached:   0.075,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        0.60,
		ContextWindow:       128_000,
		SupportsAttachments: true,
	},
	O1: {
		ID:                  O1,
		Name:                "O1",
		Provider:            ProviderOpenAI,
		APIModel:            "o1",
		CostPer1MIn:         15.00,
		CostPer1MInCached:   7.50,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        60.00,
		ContextWindow:       200_000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	O1Pro: {
		ID:                  O1Pro,
		Name:                "o1 pro",
		Provider:            ProviderOpenAI,
		APIModel:            "o1-pro",
		CostPer1MIn:         150.00,
		CostPer1MInCached:   0.0,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        600.00,
		ContextWindow:       200_000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	O1Mini: {
		ID:                  O1Mini,
		Name:                "o1 mini",
		Provider:            ProviderOpenAI,
		APIModel:            "o1-mini",
		CostPer1MIn:         1.10,
		CostPer1MInCached:   0.55,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        4.40,
		ContextWindow:       128_000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	O3: {
		ID:                  O3,
		Name:                "o3",
		Provider:            ProviderOpenAI,
		APIModel:            "o3",
		CostPer1MIn:         10.00,
		CostPer1MInCached:   2.50,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        40.00,
		ContextWindow:       200_000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	O3Mini: {
		ID:                  O3Mini,
		Name:                "o3 mini",
		Provider:            ProviderOpenAI,
		APIModel:            "o3-mini",
		CostPer1MIn:         1.10,
		CostPer1MInCached:   0.55,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        4.40,
		ContextWindow:       200_000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: false,
	},
	O4Mini: {
		ID:                  O4Mini,
		Name:                "o4 mini",
		Provider:            ProviderOpenAI,
		APIModel:            "o4-mini",
		CostPer1MIn:         1.10,
		CostPer1MInCached:   0.275,
		CostPer1MOutCached:  0.0,
		CostPer1MOut:        4.40,
		ContextWindow:       128_000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/vertexai.go">
package models
const (
	ProviderVertexAI ModelProvider = "vertexai"
	VertexAIGemini25Flash ModelID = "vertexai.gemini-2.5-flash"
	VertexAIGemini25      ModelID = "vertexai.gemini-2.5"
)
var VertexAIGeminiModels = map[ModelID]Model{
	VertexAIGemini25Flash: {
		ID:                  VertexAIGemini25Flash,
		Name:                "VertexAI: Gemini 2.5 Flash",
		Provider:            ProviderVertexAI,
		APIModel:            "gemini-2.5-flash-preview-04-17",
		CostPer1MIn:         GeminiModels[Gemini25Flash].CostPer1MIn,
		CostPer1MInCached:   GeminiModels[Gemini25Flash].CostPer1MInCached,
		CostPer1MOut:        GeminiModels[Gemini25Flash].CostPer1MOut,
		CostPer1MOutCached:  GeminiModels[Gemini25Flash].CostPer1MOutCached,
		ContextWindow:       GeminiModels[Gemini25Flash].ContextWindow,
		DefaultMaxTokens:    GeminiModels[Gemini25Flash].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	VertexAIGemini25: {
		ID:                  VertexAIGemini25,
		Name:                "VertexAI: Gemini 2.5 Pro",
		Provider:            ProviderVertexAI,
		APIModel:            "gemini-2.5-pro-preview-03-25",
		CostPer1MIn:         GeminiModels[Gemini25].CostPer1MIn,
		CostPer1MInCached:   GeminiModels[Gemini25].CostPer1MInCached,
		CostPer1MOut:        GeminiModels[Gemini25].CostPer1MOut,
		CostPer1MOutCached:  GeminiModels[Gemini25].CostPer1MOutCached,
		ContextWindow:       GeminiModels[Gemini25].ContextWindow,
		DefaultMaxTokens:    GeminiModels[Gemini25].DefaultMaxTokens,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/xai.go">
package models
const (
	ProviderXAI ModelProvider = "xai"
	XAIGrok3Beta         ModelID = "grok-3-beta"
	XAIGrok3MiniBeta     ModelID = "grok-3-mini-beta"
	XAIGrok3FastBeta     ModelID = "grok-3-fast-beta"
	XAiGrok3MiniFastBeta ModelID = "grok-3-mini-fast-beta"
	XAIGrok4             ModelID = "grok-4"
)
var XAIModels = map[ModelID]Model{
	XAIGrok3Beta: {
		ID:                 XAIGrok3Beta,
		Name:               "Grok3 Beta",
		Provider:           ProviderXAI,
		APIModel:           "grok-3-beta",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0,
		CostPer1MOut:       15,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
	},
	XAIGrok3MiniBeta: {
		ID:                 XAIGrok3MiniBeta,
		Name:               "Grok3 Mini Beta",
		Provider:           ProviderXAI,
		APIModel:           "grok-3-mini-beta",
		CostPer1MIn:        0.3,
		CostPer1MInCached:  0,
		CostPer1MOut:       0.5,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
	},
	XAIGrok3FastBeta: {
		ID:                 XAIGrok3FastBeta,
		Name:               "Grok3 Fast Beta",
		Provider:           ProviderXAI,
		APIModel:           "grok-3-fast-beta",
		CostPer1MIn:        5,
		CostPer1MInCached:  0,
		CostPer1MOut:       25,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
	},
	XAiGrok3MiniFastBeta: {
		ID:                 XAiGrok3MiniFastBeta,
		Name:               "Grok3 Mini Fast Beta",
		Provider:           ProviderXAI,
		APIModel:           "grok-3-mini-fast-beta",
		CostPer1MIn:        0.6,
		CostPer1MInCached:  0,
		CostPer1MOut:       4.0,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
	},
	XAIGrok4: {
		ID:                 XAIGrok4,
		Name:               "Grok 4",
		Provider:           ProviderXAI,
		APIModel:           "grok-4-0709",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  0,
		CostPer1MOut:       15,
		CostPer1MOutCached: 0,
		ContextWindow:      131_072,
		DefaultMaxTokens:   20_000,
	},
}
</file>

<file path="internal/llm/prompt/coder.go">
package prompt
import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"runtime"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/tools"
)
⋮----
"context"
"fmt"
"os"
"path/filepath"
"runtime"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/tools"
⋮----
func CoderPrompt(provider models.ModelProvider) string
const baseOpenAICoderPrompt = `
You are operating as and within the OpenCode CLI, a terminal-based agentic coding assistant built by OpenAI. It wraps OpenAI models to enable natural language interaction with a local codebase. You are expected to be precise, safe, and helpful.
You can:
- Receive user prompts, project context, and files.
- Stream responses and emit function calls (e.g., shell commands, code edits).
- Apply patches, run commands, and manage user approvals based on policy.
- Work inside a sandboxed, git-backed workspace with rollback support.
- Log telemetry so sessions can be replayed or inspected later.
- More details on your functionality are available at "opencode --help"
You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved. If you are not sure about file content or codebase structure pertaining to the user's request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.
Please resolve the user's task by editing and testing the code files in your current code execution session. You are a deployed coding agent. Your session allows for you to modify and run code. The repo(s) are already cloned in your working directory, and you must fully solve the problem for your answer to be considered correct.
You MUST adhere to the following criteria when executing the task:
- Working on the repo(s) in the current environment is allowed, even if they are proprietary.
- Analyzing code for vulnerabilities is allowed.
- Showing user code and tool call details is allowed.
- User instructions may overwrite the *CODING GUIDELINES* section in this developer message.
- If completing the user's task requires writing or modifying files:
    - Your code and final answer should follow these *CODING GUIDELINES*:
        - Fix the problem at the root cause rather than applying surface-level patches, when possible.
        - Avoid unneeded complexity in your solution.
            - Ignore unrelated bugs or broken tests; it is not your responsibility to fix them.
        - Update documentation as necessary.
        - Keep changes consistent with the style of the existing codebase. Changes should be minimal and focused on the task.
            - Use "git log" and "git blame" to search the history of the codebase if additional context is required; internet access is disabled.
        - NEVER add copyright or license headers unless specifically requested.
        - You do not need to "git commit" your changes; this will be done automatically for you.
        - Once you finish coding, you must
            - Check "git status" to sanity check your changes; revert any scratch files or changes.
            - Remove all inline comments you added as much as possible, even if they look normal. Check using "git diff". Inline comments must be generally avoided, unless active maintainers of the repo, after long careful study of the code and the issue, will still misinterpret the code without the comments.
            - Check if you accidentally add copyright or license headers. If so, remove them.
            - For smaller tasks, describe in brief bullet points
            - For more complex tasks, include brief high-level description, use bullet points, and include details that would be relevant to a code reviewer.
- If completing the user's task DOES NOT require writing or modifying files (e.g., the user asks a question about the code base):
    - Respond in a friendly tune as a remote teammate, who is knowledgeable, capable and eager to help with coding.
- When your task involves writing or modifying files:
    - Do NOT tell the user to "save the file" or "copy the code into a file" if you already created or modified the file using "apply_patch". Instead, reference the file as already saved.
    - Do NOT show the full contents of large files you have already written, unless the user explicitly asks for them.
- When doing things with paths, always use use the full path, if the working directory is /abc/xyz  and you want to edit the file abc.go in the working dir refer to it as /abc/xyz/abc.go.
- If you send a path not including the working dir, the working dir will be prepended to it.
- Remember the user does not see the full output of tools
`
const baseXAICoderPrompt = `You are OpenCode, an interactive CLI tool that helps users with software engineering tasks powered by xAI's Grok models. Use the instructions below and the tools available to you to assist the user.
IMPORTANT: Before you begin work, think about what the code you're editing is supposed to do based on the filenames directory structure.
# Memory
If the current working directory contains a file called OpenCode.md, it will be automatically added to your context. This file serves multiple purposes:
1. Storing frequently used bash commands (build, test, lint, etc.) so you can use them without searching each time
2. Recording the user's code style preferences (naming conventions, preferred libraries, etc.)
3. Maintaining useful information about the codebase structure and organization
When you spend time searching for commands to typecheck, lint, build, or test, you should ask the user if it's okay to add those commands to OpenCode.md. Similarly, when learning about code style preferences or important codebase information, ask if it's okay to add that to OpenCode.md so you can remember it for next time.
# Tone and style
You should be concise, direct, and to the point. When you run a non-trivial bash command, you should explain what the command does and why you are running it, to make sure the user understands what you are doing (this is especially important when you are running a command that will make changes to the user's system).
Remember that your output will be displayed on a command line interface. Your responses can use Github-flavored markdown for formatting, and will be rendered in a monospace font using the CommonMark specification.
Output text to communicate with the user; all text you output outside of tool use is displayed to the user. Only use tools to complete tasks. Never use tools like Bash or code comments as means to communicate with the user during the session.
If you cannot or will not help the user with something, please do not say why or what it could lead to, since this comes across as preachy and annoying. Please offer helpful alternatives if possible, and otherwise keep your response to 1-2 sentences.
IMPORTANT: You should minimize output tokens as much as possible while maintaining helpfulness, quality, and accuracy. Only address the specific query or task at hand, avoiding tangential information unless absolutely critical for completing the request. If you can answer in 1-3 sentences or a short paragraph, please do.
IMPORTANT: You should NOT answer with unnecessary preamble or postamble (such as explaining your code or summarizing your action), unless the user asks you to.
IMPORTANT: Keep your responses short, since they will be displayed on a command line interface. You MUST answer concisely with fewer than 4 lines (not including tool use or code generation), unless user asks for detail. Answer the user's question directly, without elaboration, explanation, or details. One word answers are best. Avoid introductions, conclusions, and explanations. You MUST avoid text before/after your response, such as "The answer is <answer>.", "Here is the content of the file..." or "Based on the information provided, the answer is..." or "Here is what I will do next...". Here are some examples to demonstrate appropriate verbosity:
<example>
user: 2 + 2
assistant: 4
</example>
<example>
user: what is 2+2?
assistant: 4
</example>
<example>
user: is 11 a prime number?
assistant: true
</example>
<example>
user: what command should I run to list files in the current directory?
assistant: ls
</example>
<example>
user: what command should I run to watch files in the current directory?
assistant: [use the ls tool to list the files in the current directory, then read docs/commands in the relevant file to find out how to watch files]
npm run dev
</example>
<example>
user: How many golf balls fit inside a jetta?
assistant: 150000
</example>
<example>
user: what files are in the directory src/?
assistant: [runs ls and sees foo.c, bar.c, baz.c]
user: which file contains the implementation of foo?
assistant: src/foo.c
</example>
<example>
user: write tests for new feature
assistant: [uses grep and glob search tools to find where similar tests are defined, uses concurrent read file tool use blocks in one tool call to read relevant files at the same time, uses edit/patch file tool to write new tests]
</example>
# Proactiveness
You are allowed to be proactive, but only when the user asks you to do something. You should strive to strike a balance between:
1. Doing the right thing when asked, including taking actions and follow-up actions
2. Not surprising the user with actions you take without asking
For example, if the user asks you how to approach something, you should do your best to answer their question first, and not immediately jump into taking actions.
3. Do not add additional code explanation summary unless requested by the user. After working on a file, just stop, rather than providing an explanation of what you did.
# Following conventions
When making changes to files, first understand the file's code conventions. Mimic code style, use existing libraries and utilities, and follow existing patterns.
- NEVER assume that a given library is available, even if it is well known. Whenever you write code that uses a library or framework, first check that this codebase already uses the given library. For example, you might look at neighboring files, or check the package.json (or cargo.toml, and so on depending on the language).
- When you create a new component, first look at existing components to see how they're written; then consider framework choice, naming conventions, typing, and other conventions.
- When you edit a piece of code, first look at the code's surrounding context (especially its imports) to understand the code's choice of frameworks and libraries. Then consider how to make the given change in a way that is most idiomatic.
- Always follow security best practices. Never introduce code that exposes or logs secrets and keys. Never commit secrets or keys to the repository.
# Code style
- Do not add comments to the code you write, unless the user asks you to, or the code is complex and requires additional context.
# Doing tasks
The user will primarily request you perform software engineering tasks. This includes solving bugs, adding new functionality, refactoring code, explaining code, and more. For these tasks the following steps are recommended:
1. Use the available search tools to understand the codebase and the user's query. You are encouraged to use the search tools extensively both in parallel and sequentially.
2. Implement the solution using all tools available to you
3. Verify the solution if possible with tests. NEVER assume specific test framework or test script. Check the README or search codebase to determine the testing approach.
4. VERY IMPORTANT: When you have completed a task, you MUST run the lint and typecheck commands (eg. npm run lint, npm run typecheck, ruff, etc.) if they were provided to you to ensure your code is correct. If you are unable to find the correct command, ask the user for the command to run and if they supply it, proactively suggest writing it to opencode.md so that you will know to run it next time.
NEVER commit changes unless the user explicitly asks you to. It is VERY IMPORTANT to only commit when explicitly asked, otherwise the user will feel that you are being too proactive.
# Tool usage policy
- When doing file search, prefer to use the Agent tool in order to reduce context usage.
- If you intend to call multiple tools and there are no dependencies between the calls, make all of the independent calls in the same function_calls block.
- IMPORTANT: The user does not see the full output of the tool responses, so if you need the output of the tool for the response make sure to summarize it for the user.
You MUST answer concisely with fewer than 4 lines of text (not including tool use or code generation), unless user asks for detail.`
const baseAnthropicCoderPrompt = `You are OpenCode, an interactive CLI tool that helps users with software engineering tasks. Use the instructions below and the tools available to you to assist the user.
IMPORTANT: Before you begin work, think about what the code you're editing is supposed to do based on the filenames directory structure.
# Memory
If the current working directory contains a file called OpenCode.md, it will be automatically added to your context. This file serves multiple purposes:
1. Storing frequently used bash commands (build, test, lint, etc.) so you can use them without searching each time
2. Recording the user's code style preferences (naming conventions, preferred libraries, etc.)
3. Maintaining useful information about the codebase structure and organization
When you spend time searching for commands to typecheck, lint, build, or test, you should ask the user if it's okay to add those commands to OpenCode.md. Similarly, when learning about code style preferences or important codebase information, ask if it's okay to add that to OpenCode.md so you can remember it for next time.
# Tone and style
You should be concise, direct, and to the point. When you run a non-trivial bash command, you should explain what the command does and why you are running it, to make sure the user understands what you are doing (this is especially important when you are running a command that will make changes to the user's system).
Remember that your output will be displayed on a command line interface. Your responses can use Github-flavored markdown for formatting, and will be rendered in a monospace font using the CommonMark specification.
Output text to communicate with the user; all text you output outside of tool use is displayed to the user. Only use tools to complete tasks. Never use tools like Bash or code comments as means to communicate with the user during the session.
If you cannot or will not help the user with something, please do not say why or what it could lead to, since this comes across as preachy and annoying. Please offer helpful alternatives if possible, and otherwise keep your response to 1-2 sentences.
IMPORTANT: You should minimize output tokens as much as possible while maintaining helpfulness, quality, and accuracy. Only address the specific query or task at hand, avoiding tangential information unless absolutely critical for completing the request. If you can answer in 1-3 sentences or a short paragraph, please do.
IMPORTANT: You should NOT answer with unnecessary preamble or postamble (such as explaining your code or summarizing your action), unless the user asks you to.
IMPORTANT: Keep your responses short, since they will be displayed on a command line interface. You MUST answer concisely with fewer than 4 lines (not including tool use or code generation), unless user asks for detail. Answer the user's question directly, without elaboration, explanation, or details. One word answers are best. Avoid introductions, conclusions, and explanations. You MUST avoid text before/after your response, such as "The answer is <answer>.", "Here is the content of the file..." or "Based on the information provided, the answer is..." or "Here is what I will do next...". Here are some examples to demonstrate appropriate verbosity:
<example>
user: 2 + 2
assistant: 4
</example>
<example>
user: what is 2+2?
assistant: 4
</example>
<example>
user: is 11 a prime number?
assistant: true
</example>
<example>
user: what command should I run to list files in the current directory?
assistant: ls
</example>
<example>
user: what command should I run to watch files in the current directory?
assistant: [use the ls tool to list the files in the current directory, then read docs/commands in the relevant file to find out how to watch files]
npm run dev
</example>
<example>
user: How many golf balls fit inside a jetta?
assistant: 150000
</example>
<example>
user: what files are in the directory src/?
assistant: [runs ls and sees foo.c, bar.c, baz.c]
user: which file contains the implementation of foo?
assistant: src/foo.c
</example>
<example>
user: write tests for new feature
assistant: [uses grep and glob search tools to find where similar tests are defined, uses concurrent read file tool use blocks in one tool call to read relevant files at the same time, uses edit/patch file tool to write new tests]
</example>
# Proactiveness
You are allowed to be proactive, but only when the user asks you to do something. You should strive to strike a balance between:
1. Doing the right thing when asked, including taking actions and follow-up actions
2. Not surprising the user with actions you take without asking
For example, if the user asks you how to approach something, you should do your best to answer their question first, and not immediately jump into taking actions.
3. Do not add additional code explanation summary unless requested by the user. After working on a file, just stop, rather than providing an explanation of what you did.
# Following conventions
When making changes to files, first understand the file's code conventions. Mimic code style, use existing libraries and utilities, and follow existing patterns.
- NEVER assume that a given library is available, even if it is well known. Whenever you write code that uses a library or framework, first check that this codebase already uses the given library. For example, you might look at neighboring files, or check the package.json (or cargo.toml, and so on depending on the language).
- When you create a new component, first look at existing components to see how they're written; then consider framework choice, naming conventions, typing, and other conventions.
- When you edit a piece of code, first look at the code's surrounding context (especially its imports) to understand the code's choice of frameworks and libraries. Then consider how to make the given change in a way that is most idiomatic.
- Always follow security best practices. Never introduce code that exposes or logs secrets and keys. Never commit secrets or keys to the repository.
# Code style
- Do not add comments to the code you write, unless the user asks you to, or the code is complex and requires additional context.
# Doing tasks
The user will primarily request you perform software engineering tasks. This includes solving bugs, adding new functionality, refactoring code, explaining code, and more. For these tasks the following steps are recommended:
1. Use the available search tools to understand the codebase and the user's query. You are encouraged to use the search tools extensively both in parallel and sequentially.
2. Implement the solution using all tools available to you
3. Verify the solution if possible with tests. NEVER assume specific test framework or test script. Check the README or search codebase to determine the testing approach.
4. VERY IMPORTANT: When you have completed a task, you MUST run the lint and typecheck commands (eg. npm run lint, npm run typecheck, ruff, etc.) if they were provided to you to ensure your code is correct. If you are unable to find the correct command, ask the user for the command to run and if they supply it, proactively suggest writing it to opencode.md so that you will know to run it next time.
NEVER commit changes unless the user explicitly asks you to. It is VERY IMPORTANT to only commit when explicitly asked, otherwise the user will feel that you are being too proactive.
# Tool usage policy
- When doing file search, prefer to use the Agent tool in order to reduce context usage.
- If you intend to call multiple tools and there are no dependencies between the calls, make all of the independent calls in the same function_calls block.
- IMPORTANT: The user does not see the full output of the tool responses, so if you need the output of the tool for the response make sure to summarize it for the user.
You MUST answer concisely with fewer than 4 lines of text (not including tool use or code generation), unless user asks for detail.`
func getDefaultGrok4Prompt() string
func loadExternalGrokPrompt() string
func getEnvironmentInfo() string
func isGitRepo(dir string) bool
func lspInformation() string
func boolToYesNo(b bool) string
</file>

<file path="internal/llm/prompt/summarizer.go">
package prompt
import "github.com/opencode-ai/opencode/internal/llm/models"
func SummarizerPrompt(_ models.ModelProvider) string
</file>

<file path="internal/llm/prompt/task.go">
package prompt
import (
	"fmt"
	"github.com/opencode-ai/opencode/internal/llm/models"
)
⋮----
"fmt"
"github.com/opencode-ai/opencode/internal/llm/models"
⋮----
func TaskPrompt(_ models.ModelProvider) string
</file>

<file path="internal/llm/provider/azure.go">
package provider
import (
	"os"
	"github.com/Azure/azure-sdk-for-go/sdk/azidentity"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/azure"
	"github.com/openai/openai-go/option"
)
⋮----
"os"
"github.com/Azure/azure-sdk-for-go/sdk/azidentity"
"github.com/openai/openai-go"
"github.com/openai/openai-go/azure"
"github.com/openai/openai-go/option"
⋮----
type azureClient struct {
	*openaiClient
}
type AzureClient ProviderClient
func newAzureClient(opts providerClientOptions) AzureClient
</file>

<file path="internal/llm/provider/copilot.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"net/http"
	"os"
	"time"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/option"
	"github.com/openai/openai-go/shared"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	toolsPkg "github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"net/http"
"os"
"time"
"github.com/openai/openai-go"
"github.com/openai/openai-go/option"
"github.com/openai/openai-go/shared"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
toolsPkg "github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
⋮----
type copilotOptions struct {
	reasoningEffort string
	extraHeaders    map[string]string
	bearerToken     string
}
type CopilotOption func(*copilotOptions)
type copilotClient struct {
	providerOptions providerClientOptions
	options         copilotOptions
	client          openai.Client
	httpClient      *http.Client
}
type CopilotClient ProviderClient
type CopilotTokenResponse struct {
	Token     string `json:"token"`
	ExpiresAt int64  `json:"expires_at"`
}
func (c *copilotClient) isAnthropicModel() bool
func (c *copilotClient) exchangeGitHubToken(githubToken string) (string, error)
⋮----
var tokenResp CopilotTokenResponse
⋮----
func newCopilotClient(opts providerClientOptions) CopilotClient
⋮----
var bearerToken string
⋮----
// Try to get GitHub token from multiple sources
var githubToken string
// 1. Environment variable
⋮----
// 3. Standard GitHub CLI/Copilot locations
⋮----
var err error
⋮----
// Create a temporary client for token exchange
⋮----
// Exchange GitHub token for bearer token
var err error
⋮----
func (c *copilotClient) convertMessages(messages []message.Message) (copilotMessages []openai.ChatCompletionMessageParamUnion)
⋮----
var content []openai.ChatCompletionContentPartUnionParam
⋮----
func (c *copilotClient) convertTools(tools []toolsPkg.BaseTool) []openai.ChatCompletionToolParam
func (c *copilotClient) finishReason(reason string) message.FinishReason
func (c *copilotClient) preparedParams(messages []openai.ChatCompletionMessageParamUnion, tools []openai.ChatCompletionToolParam) openai.ChatCompletionNewParams
func (c *copilotClient) send(ctx context.Context, messages []message.Message, tools []toolsPkg.BaseTool) (response *ProviderResponse, err error)
⋮----
var sessionId string
⋮----
func (c *copilotClient) stream(ctx context.Context, messages []message.Message, tools []toolsPkg.BaseTool) <-chan ProviderEvent
⋮----
var currentToolCallId string
var currentToolCall openai.ChatCompletionMessageToolCall
var msgToolCalls []openai.ChatCompletionMessageToolCall
⋮----
// Monkeypatch adapter for Sonnet-4 multi-tool use
⋮----
// Detect tool use start
⋮----
// Detect new tool use
⋮----
func (c *copilotClient) shouldRetry(attempts int, err error) (bool, int64, error)
⋮----
var apierr *openai.Error
⋮----
// Update the client with the new token
// Note: This is a simplified approach. In a production system,
// you might want to recreate the entire client with the new token
⋮----
func (c *copilotClient) toolCalls(completion openai.ChatCompletion) []message.ToolCall
⋮----
var toolCalls []message.ToolCall
⋮----
func (c *copilotClient) usage(completion openai.ChatCompletion) TokenUsage
func WithCopilotReasoningEffort(effort string) CopilotOption
func WithCopilotExtraHeaders(headers map[string]string) CopilotOption
func WithCopilotBearerToken(bearerToken string) CopilotOption
</file>

<file path="internal/llm/provider/vertexai.go">
package provider
import (
	"context"
	"os"
	"github.com/opencode-ai/opencode/internal/logging"
	"google.golang.org/genai"
)
⋮----
"context"
"os"
"github.com/opencode-ai/opencode/internal/logging"
"google.golang.org/genai"
⋮----
type VertexAIClient ProviderClient
func newVertexAIClient(opts providerClientOptions) VertexAIClient
</file>

<file path="internal/llm/tools/diagnostics.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"maps"
	"sort"
	"strings"
	"time"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"context"
"encoding/json"
"fmt"
"maps"
"sort"
"strings"
"time"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
type DiagnosticsParams struct {
	FilePath string `json:"file_path"`
}
type diagnosticsTool struct {
	lspClients map[string]*lsp.Client
}
const (
	DiagnosticsToolName    = "diagnostics"
	diagnosticsDescription = `Get diagnostics for a file and/or project.
WHEN TO USE THIS TOOL:
- Use when you need to check for errors or warnings in your code
- Helpful for debugging and ensuring code quality
- Good for getting a quick overview of issues in a file or project
HOW TO USE:
- Provide a path to a file to get diagnostics for that file
- Leave the path empty to get diagnostics for the entire project
- Results are displayed in a structured format with severity levels
FEATURES:
- Displays errors, warnings, and hints
- Groups diagnostics by severity
- Provides detailed information about each diagnostic
LIMITATIONS:
- Results are limited to the diagnostics provided by the LSP clients
- May not cover all possible issues in the code
- Does not provide suggestions for fixing issues
TIPS:
- Use in conjunction with other tools for a comprehensive code review
- Combine with the LSP client for real-time diagnostics
`
)
func NewDiagnosticsTool(lspClients map[string]*lsp.Client) BaseTool
func (b *diagnosticsTool) Info() ToolInfo
func (b *diagnosticsTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params DiagnosticsParams
⋮----
func notifyLspOpenFile(ctx context.Context, filePath string, lsps map[string]*lsp.Client)
func waitForLspDiagnostics(ctx context.Context, filePath string, lsps map[string]*lsp.Client)
⋮----
var diagParams protocol.PublishDiagnosticsParams
⋮----
func hasDiagnosticsChanged(current, original map[protocol.DocumentUri][]protocol.Diagnostic) bool
func getDiagnostics(filePath string, lsps map[string]*lsp.Client) string
func countSeverity(diagnostics []string, severity string) int
</file>

<file path="internal/llm/tools/ls.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"github.com/opencode-ai/opencode/internal/config"
)
⋮----
"context"
"encoding/json"
"fmt"
"os"
"path/filepath"
"strings"
"github.com/opencode-ai/opencode/internal/config"
⋮----
type LSParams struct {
	Path   string   `json:"path"`
	Ignore []string `json:"ignore"`
}
type TreeNode struct {
	Name     string      `json:"name"`
	Path     string      `json:"path"`
	Type     string      `json:"type"`
	Children []*TreeNode `json:"children,omitempty"`
}
type LSResponseMetadata struct {
	NumberOfFiles int  `json:"number_of_files"`
	Truncated     bool `json:"truncated"`
}
type lsTool struct{}
const (
	LSToolName    = "ls"
	MaxLSFiles    = 1000
	lsDescription = `Directory listing tool that shows files and subdirectories in a tree structure, helping you explore and understand the project organization.
WHEN TO USE THIS TOOL:
- Use when you need to explore the structure of a directory
- Helpful for understanding the organization of a project
- Good first step when getting familiar with a new codebase
HOW TO USE:
- Provide a path to list (defaults to current working directory)
func NewLsTool() BaseTool
func (l *lsTool) Info() ToolInfo
func (l *lsTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params LSParams
⋮----
func listDirectory(initialPath string, ignorePatterns []string, limit int) ([]string, bool, error)
⋮----
var results []string
⋮----
func shouldSkip(path string, ignorePatterns []string) bool
func createFileTree(sortedPaths []string) []*TreeNode
⋮----
var parentPath string
var cleanParts []string
⋮----
func printTree(tree []*TreeNode, rootPath string) string
⋮----
var result strings.Builder
⋮----
func printNode(builder *strings.Builder, node *TreeNode, level int)
</file>

<file path="internal/logging/logger.go">
package logging
import (
	"fmt"
	"log/slog"
	"os"
	"encoding/json"
	"runtime"
	"runtime/debug"
	"sync"
	"time"
)
⋮----
"fmt"
"log/slog"
"os"
"encoding/json"
"runtime"
"runtime/debug"
"sync"
"time"
⋮----
func getCaller() string
⋮----
var caller string
⋮----
func Info(msg string, args ...any)
func Debug(msg string, args ...any)
func Warn(msg string, args ...any)
func Error(msg string, args ...any)
func InfoPersist(msg string, args ...any)
func DebugPersist(msg string, args ...any)
func WarnPersist(msg string, args ...any)
func ErrorPersist(msg string, args ...any)
func RecoverPanic(name string, cleanup func())
var MessageDir string
func GetSessionPrefix(sessionId string) string
var sessionLogMutex sync.Mutex
func AppendToSessionLogFile(sessionId string, filename string, content string) string
⋮----
// Append chunk to file
⋮----
func WriteRequestMessageJson(sessionId string, requestSeqId int, message any) string
func WriteRequestMessage(sessionId string, requestSeqId int, message string) string
func AppendToStreamSessionLogJson(sessionId string, requestSeqId int, jsonableChunk any) string
func AppendToStreamSessionLog(sessionId string, requestSeqId int, chunk string) string
func WriteChatResponseJson(sessionId string, requestSeqId int, response any) string
func WriteToolResultsJson(sessionId string, requestSeqId int, toolResults any) string
</file>

<file path="internal/lsp/util/edit.go">
package util
import (
	"bytes"
	"fmt"
	"os"
	"sort"
	"strings"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"bytes"
"fmt"
"os"
"sort"
"strings"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
func applyTextEdits(uri protocol.DocumentUri, edits []protocol.TextEdit) error
⋮----
var lineEnding string
⋮----
var newContent strings.Builder
⋮----
func applyTextEdit(lines []string, edit protocol.TextEdit) ([]string, error)
⋮----
// Split new text into lines, being careful not to add extra newlines
// newLines := strings.Split(strings.TrimRight(edit.NewText, "\n"), "\n")
⋮----
func applyDocumentChange(change protocol.DocumentChange) error
⋮----
var err error
⋮----
func ApplyWorkspaceEdit(edit protocol.WorkspaceEdit) error
func rangesOverlap(r1, r2 protocol.Range) bool
</file>

<file path="internal/lsp/handlers.go">
package lsp
import (
	"encoding/json"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
	"github.com/opencode-ai/opencode/internal/lsp/util"
)
⋮----
"encoding/json"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
"github.com/opencode-ai/opencode/internal/lsp/util"
⋮----
func HandleWorkspaceConfiguration(params json.RawMessage) (any, error)
func HandleRegisterCapability(params json.RawMessage) (any, error)
⋮----
var registerParams protocol.RegistrationParams
⋮----
var options protocol.DidChangeWatchedFilesRegistrationOptions
⋮----
func HandleApplyEdit(params json.RawMessage) (any, error)
⋮----
var edit protocol.ApplyWorkspaceEditParams
⋮----
type FileWatchRegistrationHandler func(id string, watchers []protocol.FileSystemWatcher)
var fileWatchHandler FileWatchRegistrationHandler
func RegisterFileWatchHandler(handler FileWatchRegistrationHandler)
func notifyFileWatchRegistration(id string, watchers []protocol.FileSystemWatcher)
func HandleServerMessage(params json.RawMessage)
⋮----
var msg struct {
		Type    int    `json:"type"`
		Message string `json:"message"`
	}
⋮----
func HandleDiagnostics(client *Client, params json.RawMessage)
⋮----
var diagParams protocol.PublishDiagnosticsParams
</file>

<file path="internal/lsp/language.go">
package lsp
import (
	"path/filepath"
	"strings"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"path/filepath"
"strings"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
func DetectLanguageID(uri string) protocol.LanguageKind
</file>

<file path="internal/lsp/methods.go">
package lsp
import (
	"context"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"context"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
func (c *Client) Implementation(ctx context.Context, params protocol.ImplementationParams) (protocol.Or_Result_textDocument_implementation, error)
⋮----
var result protocol.Or_Result_textDocument_implementation
⋮----
func (c *Client) TypeDefinition(ctx context.Context, params protocol.TypeDefinitionParams) (protocol.Or_Result_textDocument_typeDefinition, error)
⋮----
var result protocol.Or_Result_textDocument_typeDefinition
⋮----
func (c *Client) DocumentColor(ctx context.Context, params protocol.DocumentColorParams) ([]protocol.ColorInformation, error)
⋮----
var result []protocol.ColorInformation
⋮----
func (c *Client) ColorPresentation(ctx context.Context, params protocol.ColorPresentationParams) ([]protocol.ColorPresentation, error)
⋮----
var result []protocol.ColorPresentation
⋮----
func (c *Client) FoldingRange(ctx context.Context, params protocol.FoldingRangeParams) ([]protocol.FoldingRange, error)
⋮----
var result []protocol.FoldingRange
⋮----
func (c *Client) Declaration(ctx context.Context, params protocol.DeclarationParams) (protocol.Or_Result_textDocument_declaration, error)
⋮----
var result protocol.Or_Result_textDocument_declaration
⋮----
func (c *Client) SelectionRange(ctx context.Context, params protocol.SelectionRangeParams) ([]protocol.SelectionRange, error)
⋮----
var result []protocol.SelectionRange
⋮----
func (c *Client) PrepareCallHierarchy(ctx context.Context, params protocol.CallHierarchyPrepareParams) ([]protocol.CallHierarchyItem, error)
⋮----
var result []protocol.CallHierarchyItem
⋮----
func (c *Client) IncomingCalls(ctx context.Context, params protocol.CallHierarchyIncomingCallsParams) ([]protocol.CallHierarchyIncomingCall, error)
⋮----
var result []protocol.CallHierarchyIncomingCall
⋮----
func (c *Client) OutgoingCalls(ctx context.Context, params protocol.CallHierarchyOutgoingCallsParams) ([]protocol.CallHierarchyOutgoingCall, error)
⋮----
var result []protocol.CallHierarchyOutgoingCall
⋮----
func (c *Client) SemanticTokensFull(ctx context.Context, params protocol.SemanticTokensParams) (protocol.SemanticTokens, error)
⋮----
var result protocol.SemanticTokens
⋮----
func (c *Client) SemanticTokensFullDelta(ctx context.Context, params protocol.SemanticTokensDeltaParams) (protocol.Or_Result_textDocument_semanticTokens_full_delta, error)
⋮----
var result protocol.Or_Result_textDocument_semanticTokens_full_delta
⋮----
func (c *Client) SemanticTokensRange(ctx context.Context, params protocol.SemanticTokensRangeParams) (protocol.SemanticTokens, error)
func (c *Client) LinkedEditingRange(ctx context.Context, params protocol.LinkedEditingRangeParams) (protocol.LinkedEditingRanges, error)
⋮----
var result protocol.LinkedEditingRanges
⋮----
func (c *Client) WillCreateFiles(ctx context.Context, params protocol.CreateFilesParams) (protocol.WorkspaceEdit, error)
⋮----
var result protocol.WorkspaceEdit
⋮----
func (c *Client) WillRenameFiles(ctx context.Context, params protocol.RenameFilesParams) (protocol.WorkspaceEdit, error)
func (c *Client) WillDeleteFiles(ctx context.Context, params protocol.DeleteFilesParams) (protocol.WorkspaceEdit, error)
func (c *Client) Moniker(ctx context.Context, params protocol.MonikerParams) ([]protocol.Moniker, error)
⋮----
var result []protocol.Moniker
⋮----
func (c *Client) PrepareTypeHierarchy(ctx context.Context, params protocol.TypeHierarchyPrepareParams) ([]protocol.TypeHierarchyItem, error)
⋮----
var result []protocol.TypeHierarchyItem
⋮----
func (c *Client) Supertypes(ctx context.Context, params protocol.TypeHierarchySupertypesParams) ([]protocol.TypeHierarchyItem, error)
func (c *Client) Subtypes(ctx context.Context, params protocol.TypeHierarchySubtypesParams) ([]protocol.TypeHierarchyItem, error)
func (c *Client) InlineValue(ctx context.Context, params protocol.InlineValueParams) ([]protocol.InlineValue, error)
⋮----
var result []protocol.InlineValue
⋮----
func (c *Client) InlayHint(ctx context.Context, params protocol.InlayHintParams) ([]protocol.InlayHint, error)
⋮----
var result []protocol.InlayHint
⋮----
func (c *Client) Resolve(ctx context.Context, params protocol.InlayHint) (protocol.InlayHint, error)
⋮----
var result protocol.InlayHint
⋮----
func (c *Client) Diagnostic(ctx context.Context, params protocol.DocumentDiagnosticParams) (protocol.DocumentDiagnosticReport, error)
⋮----
var result protocol.DocumentDiagnosticReport
⋮----
func (c *Client) DiagnosticWorkspace(ctx context.Context, params protocol.WorkspaceDiagnosticParams) (protocol.WorkspaceDiagnosticReport, error)
⋮----
var result protocol.WorkspaceDiagnosticReport
⋮----
func (c *Client) InlineCompletion(ctx context.Context, params protocol.InlineCompletionParams) (protocol.Or_Result_textDocument_inlineCompletion, error)
⋮----
var result protocol.Or_Result_textDocument_inlineCompletion
⋮----
func (c *Client) TextDocumentContent(ctx context.Context, params protocol.TextDocumentContentParams) (string, error)
⋮----
var result string
⋮----
func (c *Client) Initialize(ctx context.Context, params protocol.ParamInitialize) (protocol.InitializeResult, error)
⋮----
var result protocol.InitializeResult
⋮----
func (c *Client) Shutdown(ctx context.Context) error
func (c *Client) WillSaveWaitUntil(ctx context.Context, params protocol.WillSaveTextDocumentParams) ([]protocol.TextEdit, error)
⋮----
var result []protocol.TextEdit
⋮----
func (c *Client) Completion(ctx context.Context, params protocol.CompletionParams) (protocol.Or_Result_textDocument_completion, error)
⋮----
var result protocol.Or_Result_textDocument_completion
⋮----
func (c *Client) ResolveCompletionItem(ctx context.Context, params protocol.CompletionItem) (protocol.CompletionItem, error)
⋮----
var result protocol.CompletionItem
⋮----
func (c *Client) Hover(ctx context.Context, params protocol.HoverParams) (protocol.Hover, error)
⋮----
var result protocol.Hover
⋮----
func (c *Client) SignatureHelp(ctx context.Context, params protocol.SignatureHelpParams) (protocol.SignatureHelp, error)
⋮----
var result protocol.SignatureHelp
⋮----
func (c *Client) Definition(ctx context.Context, params protocol.DefinitionParams) (protocol.Or_Result_textDocument_definition, error)
⋮----
var result protocol.Or_Result_textDocument_definition
⋮----
func (c *Client) References(ctx context.Context, params protocol.ReferenceParams) ([]protocol.Location, error)
⋮----
var result []protocol.Location
⋮----
func (c *Client) DocumentHighlight(ctx context.Context, params protocol.DocumentHighlightParams) ([]protocol.DocumentHighlight, error)
⋮----
var result []protocol.DocumentHighlight
⋮----
func (c *Client) DocumentSymbol(ctx context.Context, params protocol.DocumentSymbolParams) (protocol.Or_Result_textDocument_documentSymbol, error)
⋮----
var result protocol.Or_Result_textDocument_documentSymbol
⋮----
func (c *Client) CodeAction(ctx context.Context, params protocol.CodeActionParams) ([]protocol.Or_Result_textDocument_codeAction_Item0_Elem, error)
⋮----
var result []protocol.Or_Result_textDocument_codeAction_Item0_Elem
⋮----
func (c *Client) ResolveCodeAction(ctx context.Context, params protocol.CodeAction) (protocol.CodeAction, error)
⋮----
var result protocol.CodeAction
⋮----
func (c *Client) Symbol(ctx context.Context, params protocol.WorkspaceSymbolParams) (protocol.Or_Result_workspace_symbol, error)
⋮----
var result protocol.Or_Result_workspace_symbol
⋮----
func (c *Client) ResolveWorkspaceSymbol(ctx context.Context, params protocol.WorkspaceSymbol) (protocol.WorkspaceSymbol, error)
⋮----
var result protocol.WorkspaceSymbol
⋮----
func (c *Client) CodeLens(ctx context.Context, params protocol.CodeLensParams) ([]protocol.CodeLens, error)
⋮----
var result []protocol.CodeLens
⋮----
func (c *Client) ResolveCodeLens(ctx context.Context, params protocol.CodeLens) (protocol.CodeLens, error)
⋮----
var result protocol.CodeLens
⋮----
func (c *Client) DocumentLink(ctx context.Context, params protocol.DocumentLinkParams) ([]protocol.DocumentLink, error)
⋮----
var result []protocol.DocumentLink
⋮----
func (c *Client) ResolveDocumentLink(ctx context.Context, params protocol.DocumentLink) (protocol.DocumentLink, error)
⋮----
var result protocol.DocumentLink
⋮----
func (c *Client) Formatting(ctx context.Context, params protocol.DocumentFormattingParams) ([]protocol.TextEdit, error)
func (c *Client) RangeFormatting(ctx context.Context, params protocol.DocumentRangeFormattingParams) ([]protocol.TextEdit, error)
func (c *Client) RangesFormatting(ctx context.Context, params protocol.DocumentRangesFormattingParams) ([]protocol.TextEdit, error)
func (c *Client) OnTypeFormatting(ctx context.Context, params protocol.DocumentOnTypeFormattingParams) ([]protocol.TextEdit, error)
func (c *Client) Rename(ctx context.Context, params protocol.RenameParams) (protocol.WorkspaceEdit, error)
func (c *Client) PrepareRename(ctx context.Context, params protocol.PrepareRenameParams) (protocol.PrepareRenameResult, error)
⋮----
var result protocol.PrepareRenameResult
⋮----
func (c *Client) ExecuteCommand(ctx context.Context, params protocol.ExecuteCommandParams) (any, error)
⋮----
var result any
⋮----
func (c *Client) DidChangeWorkspaceFolders(ctx context.Context, params protocol.DidChangeWorkspaceFoldersParams) error
func (c *Client) WorkDoneProgressCancel(ctx context.Context, params protocol.WorkDoneProgressCancelParams) error
func (c *Client) DidCreateFiles(ctx context.Context, params protocol.CreateFilesParams) error
func (c *Client) DidRenameFiles(ctx context.Context, params protocol.RenameFilesParams) error
func (c *Client) DidDeleteFiles(ctx context.Context, params protocol.DeleteFilesParams) error
func (c *Client) DidOpenNotebookDocument(ctx context.Context, params protocol.DidOpenNotebookDocumentParams) error
func (c *Client) DidChangeNotebookDocument(ctx context.Context, params protocol.DidChangeNotebookDocumentParams) error
func (c *Client) DidSaveNotebookDocument(ctx context.Context, params protocol.DidSaveNotebookDocumentParams) error
func (c *Client) DidCloseNotebookDocument(ctx context.Context, params protocol.DidCloseNotebookDocumentParams) error
func (c *Client) Initialized(ctx context.Context, params protocol.InitializedParams) error
func (c *Client) Exit(ctx context.Context) error
func (c *Client) DidChangeConfiguration(ctx context.Context, params protocol.DidChangeConfigurationParams) error
func (c *Client) DidOpen(ctx context.Context, params protocol.DidOpenTextDocumentParams) error
func (c *Client) DidChange(ctx context.Context, params protocol.DidChangeTextDocumentParams) error
func (c *Client) DidClose(ctx context.Context, params protocol.DidCloseTextDocumentParams) error
func (c *Client) DidSave(ctx context.Context, params protocol.DidSaveTextDocumentParams) error
func (c *Client) WillSave(ctx context.Context, params protocol.WillSaveTextDocumentParams) error
func (c *Client) DidChangeWatchedFiles(ctx context.Context, params protocol.DidChangeWatchedFilesParams) error
func (c *Client) SetTrace(ctx context.Context, params protocol.SetTraceParams) error
func (c *Client) Progress(ctx context.Context, params protocol.ProgressParams) error
</file>

<file path="internal/lsp/transport.go">
package lsp
import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"strings"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"bufio"
"context"
"encoding/json"
"fmt"
"io"
"strings"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
func WriteMessage(w io.Writer, msg *Message) error
func ReadMessage(r *bufio.Reader) (*Message, error)
⋮----
var contentLength int
⋮----
break // End of headers
⋮----
var msg Message
⋮----
func (c *Client) handleMessages()
func (c *Client) Call(ctx context.Context, method string, params any, result any) error
func (c *Client) Notify(ctx context.Context, method string, params any) error
⋮----
NotificationHandler  func(params json.RawMessage)
ServerRequestHandler func(params json.RawMessage) (any, error)
</file>

<file path="internal/message/attachment.go">
package message
type Attachment struct {
	FilePath string
	FileName string
	MimeType string
	Content  []byte
}
</file>

<file path="internal/pubsub/broker.go">
package pubsub
import (
	"context"
	"sync"
)
⋮----
"context"
"sync"
⋮----
const bufferSize = 64
type Broker[T any] struct {
	subs      map[chan Event[T]]struct{}
func NewBroker[T any]() *Broker[T]
func NewBrokerWithOptions[T any](channelBufferSize, maxEvents int) *Broker[T]
func (b *Broker[T]) Shutdown()
func (b *Broker[T]) Subscribe(ctx context.Context) <-chan Event[T]
func (b *Broker[T]) GetSubscriberCount() int
func (b *Broker[T]) Publish(t EventType, payload T)
</file>

<file path="internal/tui/components/dialog/complete.go">
package dialog
import (
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/textarea"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/logging"
	utilComponents "github.com/opencode-ai/opencode/internal/tui/components/util"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/textarea"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/logging"
utilComponents "github.com/opencode-ai/opencode/internal/tui/components/util"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type CompletionItem struct {
	title string
	Title string
	Value string
}
type CompletionItemI interface {
	utilComponents.SimpleListItem
	GetValue() string
	DisplayValue() string
}
func (ci *CompletionItem) Render(selected bool, width int) string
func (ci *CompletionItem) DisplayValue() string
func (ci *CompletionItem) GetValue() string
func NewCompletionItem(completionItem CompletionItem) CompletionItemI
type CompletionProvider interface {
	GetId() string
	GetEntry() CompletionItemI
	GetChildEntries(query string) ([]CompletionItemI, error)
}
type CompletionSelectedMsg struct {
	SearchString    string
	CompletionValue string
}
type CompletionDialogCompleteItemMsg struct {
	Value string
}
type CompletionDialogCloseMsg struct{}
type CompletionDialog interface {
	tea.Model
	layout.Bindings
	SetWidth(width int)
}
type completionDialogCmp struct {
	query                string
	completionProvider   CompletionProvider
	width                int
	height               int
	pseudoSearchTextArea textarea.Model
	listView             utilComponents.SimpleList[CompletionItemI]
}
type completionDialogKeyMap struct {
	Complete key.Binding
	Cancel   key.Binding
}
var completionDialogKeys = completionDialogKeyMap{
	Complete: key.NewBinding(
		key.WithKeys("tab", "enter"),
	),
	Cancel: key.NewBinding(
		key.WithKeys(" ", "esc", "backspace"),
	),
}
func (c *completionDialogCmp) Init() tea.Cmd
func (c *completionDialogCmp) complete(item CompletionItemI) tea.Cmd
func (c *completionDialogCmp) close() tea.Cmd
func (c *completionDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
var cmd tea.Cmd
⋮----
var query string
⋮----
func (c *completionDialogCmp) View() string
func (c *completionDialogCmp) SetWidth(width int)
func (c *completionDialogCmp) BindingKeys() []key.Binding
func NewCompletionDialogCmp(completionProvider CompletionProvider) CompletionDialog
</file>

<file path="internal/tui/components/dialog/theme.go">
package dialog
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type ThemeChangedMsg struct {
	ThemeName string
}
type CloseThemeDialogMsg struct{}
type ThemeDialog interface {
	tea.Model
	layout.Bindings
}
type themeDialogCmp struct {
	themes       []string
	selectedIdx  int
	width        int
	height       int
	currentTheme string
}
type themeKeyMap struct {
	Up     key.Binding
	Down   key.Binding
	Enter  key.Binding
	Escape key.Binding
	J      key.Binding
	K      key.Binding
}
var themeKeys = themeKeyMap{
	Up: key.NewBinding(
		key.WithKeys("up"),
		key.WithHelp("↑", "previous theme"),
	),
	Down: key.NewBinding(
		key.WithKeys("down"),
		key.WithHelp("↓", "next theme"),
	),
	Enter: key.NewBinding(
		key.WithKeys("enter"),
		key.WithHelp("enter", "select theme"),
	),
	Escape: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "close"),
	),
	J: key.NewBinding(
		key.WithKeys("j"),
		key.WithHelp("j", "next theme"),
	),
	K: key.NewBinding(
		key.WithKeys("k"),
		key.WithHelp("k", "previous theme"),
	),
}
func (t *themeDialogCmp) Init() tea.Cmd
func (t *themeDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (t *themeDialogCmp) View() string
func (t *themeDialogCmp) BindingKeys() []key.Binding
// NewThemeDialogCmp creates a new theme switching dialog
func NewThemeDialogCmp() ThemeDialog
</file>

<file path="internal/tui/components/util/simple-list.go">
package utilComponents
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type SimpleListItem interface {
	Render(selected bool, width int) string
}
type SimpleList[T SimpleListItem] interface {
	tea.Model
	layout.Bindings
	SetMaxWidth(maxWidth int)
	GetSelectedItem() (item T, idx int)
	SetItems(items []T)
	GetItems() []T
}
type simpleListCmp[T SimpleListItem] struct {
	fallbackMsg         string
	items               []T
	selectedIdx         int
	maxWidth            int
	maxVisibleItems     int
	useAlphaNumericKeys bool
	width               int
	height              int
}
type simpleListKeyMap struct {
	Up        key.Binding
	Down      key.Binding
	UpAlpha   key.Binding
	DownAlpha key.Binding
}
var simpleListKeys = simpleListKeyMap{
	Up: key.NewBinding(
		key.WithKeys("up"),
		key.WithHelp("↑", "previous list item"),
	),
	Down: key.NewBinding(
		key.WithKeys("down"),
		key.WithHelp("↓", "next list item"),
	),
	UpAlpha: key.NewBinding(
		key.WithKeys("k"),
		key.WithHelp("k", "previous list item"),
	),
	DownAlpha: key.NewBinding(
		key.WithKeys("j"),
		key.WithHelp("j", "next list item"),
	),
}
func (c *simpleListCmp[T]) Init() tea.Cmd
func (c *simpleListCmp[T]) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (c *simpleListCmp[T]) BindingKeys() []key.Binding
func (c *simpleListCmp[T]) GetSelectedItem() (T, int)
⋮----
var zero T
⋮----
func (c *simpleListCmp[T]) SetItems(items []T)
func (c *simpleListCmp[T]) GetItems() []T
func (c *simpleListCmp[T]) SetMaxWidth(width int)
func (c *simpleListCmp[T]) View() string
func NewSimpleList[T SimpleListItem](items []T, maxVisibleItems int, fallbackMsg string, useAlphaNumericKeys bool) SimpleList[T]
</file>

<file path="internal/tui/image/images.go">
package image
import (
	"fmt"
	"image"
	"os"
	"strings"
	"github.com/charmbracelet/lipgloss"
	"github.com/disintegration/imaging"
	"github.com/lucasb-eyer/go-colorful"
)
⋮----
"fmt"
"image"
"os"
"strings"
"github.com/charmbracelet/lipgloss"
"github.com/disintegration/imaging"
"github.com/lucasb-eyer/go-colorful"
⋮----
func ValidateFileSize(filePath string, sizeLimit int64) (bool, error)
func ToString(width int, img image.Image) string
⋮----
var color2 lipgloss.Color
⋮----
func ImagePreview(width int, filename string) (string, error)
</file>

<file path="internal/tui/styles/icons.go">
package styles
const (
	OpenCodeIcon string = "⌬"
	CheckIcon    string = "✓"
	ErrorIcon    string = "✖"
	WarningIcon  string = "⚠"
	InfoIcon     string = ""
	HintIcon     string = "i"
	SpinnerIcon  string = "..."
	LoadingIcon  string = "⟳"
	DocumentIcon string = "🖼"
)
</file>

<file path="internal/tui/styles/markdown.go">
package styles
import (
	"github.com/charmbracelet/glamour"
	"github.com/charmbracelet/glamour/ansi"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"github.com/charmbracelet/glamour"
"github.com/charmbracelet/glamour/ansi"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
const defaultMargin = 1
func boolPtr(b bool) *bool
func stringPtr(s string) *string
func uintPtr(u uint) *uint
func GetMarkdownRenderer(width int) *glamour.TermRenderer
func generateMarkdownStyleConfig() ansi.StyleConfig
func adaptiveColorToString(color lipgloss.AdaptiveColor) string
</file>

<file path="internal/tui/theme/catppuccin.go">
package theme
import (
	catppuccin "github.com/catppuccin/go"
	"github.com/charmbracelet/lipgloss"
)
⋮----
catppuccin "github.com/catppuccin/go"
"github.com/charmbracelet/lipgloss"
⋮----
type CatppuccinTheme struct {
	BaseTheme
}
func NewCatppuccinTheme() *CatppuccinTheme
func init()
</file>

<file path="internal/tui/theme/dracula.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type DraculaTheme struct {
	BaseTheme
}
func NewDraculaTheme() *DraculaTheme
func init()
</file>

<file path="internal/tui/theme/flexoki.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
const (
	flexokiPaper    = "#FFFCF0"
	flexokiBase50   = "#F2F0E5"
	flexokiBase100  = "#E6E4D9"
	flexokiBase150  = "#DAD8CE"
	flexokiBase200  = "#CECDC3"
	flexokiBase300  = "#B7B5AC"
	flexokiBase500  = "#878580"
	flexokiBase600  = "#6F6E69"
	flexokiBase700  = "#575653"
	flexokiBase800  = "#403E3C"
	flexokiBase850  = "#343331"
	flexokiBase900  = "#282726"
	flexokiBase950  = "#1C1B1A"
	flexokiBlack    = "#100F0F"
	flexokiRed600     = "#AF3029"
	flexokiOrange600  = "#BC5215"
	flexokiYellow600  = "#AD8301"
	flexokiGreen600   = "#66800B"
	flexokiCyan600    = "#24837B"
	flexokiBlue600    = "#205EA6"
	flexokiPurple600  = "#5E409D"
	flexokiMagenta600 = "#A02F6F"
	flexokiRed400     = "#D14D41"
	flexokiOrange400  = "#DA702C"
	flexokiYellow400  = "#D0A215"
	flexokiGreen400   = "#879A39"
	flexokiCyan400    = "#3AA99F"
	flexokiBlue400    = "#4385BE"
	flexokiPurple400  = "#8B7EC8"
	flexokiMagenta400 = "#CE5D97"
)
type FlexokiTheme struct {
	BaseTheme
}
func NewFlexokiTheme() *FlexokiTheme
func init()
</file>

<file path="internal/tui/theme/gruvbox.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
const (
	gruvboxDarkBg0          = "#282828"
	gruvboxDarkBg0Soft      = "#32302f"
	gruvboxDarkBg1          = "#3c3836"
	gruvboxDarkBg2          = "#504945"
	gruvboxDarkBg3          = "#665c54"
	gruvboxDarkBg4          = "#7c6f64"
	gruvboxDarkFg0          = "#fbf1c7"
	gruvboxDarkFg1          = "#ebdbb2"
	gruvboxDarkFg2          = "#d5c4a1"
	gruvboxDarkFg3          = "#bdae93"
	gruvboxDarkFg4          = "#a89984"
	gruvboxDarkGray         = "#928374"
	gruvboxDarkRed          = "#cc241d"
	gruvboxDarkRedBright    = "#fb4934"
	gruvboxDarkGreen        = "#98971a"
	gruvboxDarkGreenBright  = "#b8bb26"
	gruvboxDarkYellow       = "#d79921"
	gruvboxDarkYellowBright = "#fabd2f"
	gruvboxDarkBlue         = "#458588"
	gruvboxDarkBlueBright   = "#83a598"
	gruvboxDarkPurple       = "#b16286"
	gruvboxDarkPurpleBright = "#d3869b"
	gruvboxDarkAqua         = "#689d6a"
	gruvboxDarkAquaBright   = "#8ec07c"
	gruvboxDarkOrange       = "#d65d0e"
	gruvboxDarkOrangeBright = "#fe8019"
	gruvboxLightBg0          = "#fbf1c7"
	gruvboxLightBg0Soft      = "#f2e5bc"
	gruvboxLightBg1          = "#ebdbb2"
	gruvboxLightBg2          = "#d5c4a1"
	gruvboxLightBg3          = "#bdae93"
	gruvboxLightBg4          = "#a89984"
	gruvboxLightFg0          = "#282828"
	gruvboxLightFg1          = "#3c3836"
	gruvboxLightFg2          = "#504945"
	gruvboxLightFg3          = "#665c54"
	gruvboxLightFg4          = "#7c6f64"
	gruvboxLightGray         = "#928374"
	gruvboxLightRed          = "#9d0006"
	gruvboxLightRedBright    = "#cc241d"
	gruvboxLightGreen        = "#79740e"
	gruvboxLightGreenBright  = "#98971a"
	gruvboxLightYellow       = "#b57614"
	gruvboxLightYellowBright = "#d79921"
	gruvboxLightBlue         = "#076678"
	gruvboxLightBlueBright   = "#458588"
	gruvboxLightPurple       = "#8f3f71"
	gruvboxLightPurpleBright = "#b16286"
	gruvboxLightAqua         = "#427b58"
	gruvboxLightAquaBright   = "#689d6a"
	gruvboxLightOrange       = "#af3a03"
	gruvboxLightOrangeBright = "#d65d0e"
)
type GruvboxTheme struct {
	BaseTheme
}
func NewGruvboxTheme() *GruvboxTheme
func init()
</file>

<file path="internal/tui/theme/manager.go">
package theme
import (
	"fmt"
	"slices"
	"strings"
	"sync"
	"github.com/alecthomas/chroma/v2/styles"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"fmt"
"slices"
"strings"
"sync"
"github.com/alecthomas/chroma/v2/styles"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
type Manager struct {
	themes      map[string]Theme
	currentName string
	mu          sync.RWMutex
}
var globalManager = &Manager{
	themes:      make(map[string]Theme),
	currentName: "",
}
// RegisterTheme adds a new theme to the registry.
// If this is the first theme registered, it becomes the default.
func RegisterTheme(name string, theme Theme)
⋮----
// If this is the first theme, make it the default
⋮----
// SetTheme changes the active theme to the one with the specified name.
// Returns an error if the theme doesn't exist.
func SetTheme(name string) error
func CurrentTheme() Theme
// CurrentThemeName returns the name of the currently active theme.
func CurrentThemeName() string
// AvailableThemes returns a list of all registered theme names.
func AvailableThemes() []string
func GetTheme(name string) Theme
func updateConfigTheme(themeName string) error
</file>

<file path="internal/tui/theme/monokai.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type MonokaiProTheme struct {
	BaseTheme
}
func NewMonokaiProTheme() *MonokaiProTheme
func init()
</file>

<file path="internal/tui/theme/onedark.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type OneDarkTheme struct {
	BaseTheme
}
func NewOneDarkTheme() *OneDarkTheme
func init()
</file>

<file path="internal/tui/theme/opencode.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type OpenCodeTheme struct {
	BaseTheme
}
func NewOpenCodeTheme() *OpenCodeTheme
func init()
</file>

<file path="internal/tui/theme/theme.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type Theme interface {
	Primary() lipgloss.AdaptiveColor
	Secondary() lipgloss.AdaptiveColor
	Accent() lipgloss.AdaptiveColor
	Error() lipgloss.AdaptiveColor
	Warning() lipgloss.AdaptiveColor
	Success() lipgloss.AdaptiveColor
	Info() lipgloss.AdaptiveColor
	Text() lipgloss.AdaptiveColor
	TextMuted() lipgloss.AdaptiveColor
	TextEmphasized() lipgloss.AdaptiveColor
	Background() lipgloss.AdaptiveColor
	BackgroundSecondary() lipgloss.AdaptiveColor
	BackgroundDarker() lipgloss.AdaptiveColor
	BorderNormal() lipgloss.AdaptiveColor
	BorderFocused() lipgloss.AdaptiveColor
	BorderDim() lipgloss.AdaptiveColor
	DiffAdded() lipgloss.AdaptiveColor
	DiffRemoved() lipgloss.AdaptiveColor
	DiffContext() lipgloss.AdaptiveColor
	DiffHunkHeader() lipgloss.AdaptiveColor
	DiffHighlightAdded() lipgloss.AdaptiveColor
	DiffHighlightRemoved() lipgloss.AdaptiveColor
	DiffAddedBg() lipgloss.AdaptiveColor
	DiffRemovedBg() lipgloss.AdaptiveColor
	DiffContextBg() lipgloss.AdaptiveColor
	DiffLineNumber() lipgloss.AdaptiveColor
	DiffAddedLineNumberBg() lipgloss.AdaptiveColor
	DiffRemovedLineNumberBg() lipgloss.AdaptiveColor
	MarkdownText() lipgloss.AdaptiveColor
	MarkdownHeading() lipgloss.AdaptiveColor
	MarkdownLink() lipgloss.AdaptiveColor
	MarkdownLinkText() lipgloss.AdaptiveColor
	MarkdownCode() lipgloss.AdaptiveColor
	MarkdownBlockQuote() lipgloss.AdaptiveColor
	MarkdownEmph() lipgloss.AdaptiveColor
	MarkdownStrong() lipgloss.AdaptiveColor
	MarkdownHorizontalRule() lipgloss.AdaptiveColor
	MarkdownListItem() lipgloss.AdaptiveColor
	MarkdownListEnumeration() lipgloss.AdaptiveColor
	MarkdownImage() lipgloss.AdaptiveColor
	MarkdownImageText() lipgloss.AdaptiveColor
	MarkdownCodeBlock() lipgloss.AdaptiveColor
	SyntaxComment() lipgloss.AdaptiveColor
	SyntaxKeyword() lipgloss.AdaptiveColor
	SyntaxFunction() lipgloss.AdaptiveColor
	SyntaxVariable() lipgloss.AdaptiveColor
	SyntaxString() lipgloss.AdaptiveColor
	SyntaxNumber() lipgloss.AdaptiveColor
	SyntaxType() lipgloss.AdaptiveColor
	SyntaxOperator() lipgloss.AdaptiveColor
	SyntaxPunctuation() lipgloss.AdaptiveColor
}
type BaseTheme struct {
	PrimaryColor       lipgloss.AdaptiveColor
	SecondaryColor     lipgloss.AdaptiveColor
	AccentColor        lipgloss.AdaptiveColor
	ErrorColor         lipgloss.AdaptiveColor
	WarningColor       lipgloss.AdaptiveColor
	SuccessColor       lipgloss.AdaptiveColor
	InfoColor          lipgloss.AdaptiveColor
	TextColor          lipgloss.AdaptiveColor
	TextMutedColor     lipgloss.AdaptiveColor
	TextEmphasizedColor lipgloss.AdaptiveColor
	BackgroundColor    lipgloss.AdaptiveColor
	BackgroundSecondaryColor lipgloss.AdaptiveColor
	BackgroundDarkerColor lipgloss.AdaptiveColor
	BorderNormalColor  lipgloss.AdaptiveColor
	BorderFocusedColor lipgloss.AdaptiveColor
	BorderDimColor     lipgloss.AdaptiveColor
	DiffAddedColor     lipgloss.AdaptiveColor
	DiffRemovedColor   lipgloss.AdaptiveColor
	DiffContextColor   lipgloss.AdaptiveColor
	DiffHunkHeaderColor lipgloss.AdaptiveColor
	DiffHighlightAddedColor lipgloss.AdaptiveColor
	DiffHighlightRemovedColor lipgloss.AdaptiveColor
	DiffAddedBgColor   lipgloss.AdaptiveColor
	DiffRemovedBgColor lipgloss.AdaptiveColor
	DiffContextBgColor lipgloss.AdaptiveColor
	DiffLineNumberColor lipgloss.AdaptiveColor
	DiffAddedLineNumberBgColor lipgloss.AdaptiveColor
	DiffRemovedLineNumberBgColor lipgloss.AdaptiveColor
	MarkdownTextColor  lipgloss.AdaptiveColor
	MarkdownHeadingColor lipgloss.AdaptiveColor
	MarkdownLinkColor  lipgloss.AdaptiveColor
	MarkdownLinkTextColor lipgloss.AdaptiveColor
	MarkdownCodeColor  lipgloss.AdaptiveColor
	MarkdownBlockQuoteColor lipgloss.AdaptiveColor
	MarkdownEmphColor  lipgloss.AdaptiveColor
	MarkdownStrongColor lipgloss.AdaptiveColor
	MarkdownHorizontalRuleColor lipgloss.AdaptiveColor
	MarkdownListItemColor lipgloss.AdaptiveColor
	MarkdownListEnumerationColor lipgloss.AdaptiveColor
	MarkdownImageColor lipgloss.AdaptiveColor
	MarkdownImageTextColor lipgloss.AdaptiveColor
	MarkdownCodeBlockColor lipgloss.AdaptiveColor
	SyntaxCommentColor lipgloss.AdaptiveColor
	SyntaxKeywordColor lipgloss.AdaptiveColor
	SyntaxFunctionColor lipgloss.AdaptiveColor
	SyntaxVariableColor lipgloss.AdaptiveColor
	SyntaxStringColor  lipgloss.AdaptiveColor
	SyntaxNumberColor  lipgloss.AdaptiveColor
	SyntaxTypeColor    lipgloss.AdaptiveColor
	SyntaxOperatorColor lipgloss.AdaptiveColor
	SyntaxPunctuationColor lipgloss.AdaptiveColor
}
func (t *BaseTheme) Primary() lipgloss.AdaptiveColor
func (t *BaseTheme) Secondary() lipgloss.AdaptiveColor
func (t *BaseTheme) Accent() lipgloss.AdaptiveColor
func (t *BaseTheme) Error() lipgloss.AdaptiveColor
func (t *BaseTheme) Warning() lipgloss.AdaptiveColor
func (t *BaseTheme) Success() lipgloss.AdaptiveColor
func (t *BaseTheme) Info() lipgloss.AdaptiveColor
func (t *BaseTheme) Text() lipgloss.AdaptiveColor
func (t *BaseTheme) TextMuted() lipgloss.AdaptiveColor
func (t *BaseTheme) TextEmphasized() lipgloss.AdaptiveColor
func (t *BaseTheme) Background() lipgloss.AdaptiveColor
func (t *BaseTheme) BackgroundSecondary() lipgloss.AdaptiveColor
func (t *BaseTheme) BackgroundDarker() lipgloss.AdaptiveColor
func (t *BaseTheme) BorderNormal() lipgloss.AdaptiveColor
func (t *BaseTheme) BorderFocused() lipgloss.AdaptiveColor
func (t *BaseTheme) BorderDim() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffAdded() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffRemoved() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffContext() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffHunkHeader() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffHighlightAdded() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffHighlightRemoved() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffAddedBg() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffRemovedBg() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffContextBg() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffLineNumber() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffAddedLineNumberBg() lipgloss.AdaptiveColor
func (t *BaseTheme) DiffRemovedLineNumberBg() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownText() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownHeading() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownLink() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownLinkText() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownCode() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownBlockQuote() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownEmph() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownStrong() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownHorizontalRule() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownListItem() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownListEnumeration() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownImage() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownImageText() lipgloss.AdaptiveColor
func (t *BaseTheme) MarkdownCodeBlock() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxComment() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxKeyword() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxFunction() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxVariable() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxString() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxNumber() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxType() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxOperator() lipgloss.AdaptiveColor
func (t *BaseTheme) SyntaxPunctuation() lipgloss.AdaptiveColor
</file>

<file path="internal/tui/theme/tokyonight.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type TokyoNightTheme struct {
	BaseTheme
}
func NewTokyoNightTheme() *TokyoNightTheme
func init()
</file>

<file path="internal/tui/theme/tron.go">
package theme
import (
	"github.com/charmbracelet/lipgloss"
)
⋮----
"github.com/charmbracelet/lipgloss"
⋮----
type TronTheme struct {
	BaseTheme
}
func NewTronTheme() *TronTheme
func init()
</file>

<file path="scripts/check_hidden_chars.sh">
echo "Checking Go files for hidden characters..."
go_files=$(find . -name "*.go" -type f)
files_with_hidden=0
for file in $go_files; do
  if hexdump -C "$file" | grep -E 'e2 80 8b|e2 80 8c|e2 80 8d|e2 80 8e|e2 80 8f|e2 80 aa|e2 80 ab|e2 80 ac|e2 80 ad|e2 80 ae|ef bb bf' > /dev/null 2>&1; then
    echo "Hidden characters found in: $file"
    echo "  Hexdump showing suspicious characters:"
    hexdump -C "$file" | grep -E 'e2 80 8b|e2 80 8c|e2 80 8d|e2 80 8e|e2 80 8f|e2 80 aa|e2 80 ab|e2 80 ac|e2 80 ad|e2 80 ae|ef bb bf' | head -10
    files_with_hidden=$((files_with_hidden + 1))
  fi
done
if [ $files_with_hidden -eq 0 ]; then
  echo "No hidden characters found in any Go files."
else
  echo "Found hidden characters in $files_with_hidden Go file(s)."
fi
exit $files_with_hidden
</file>

<file path="main.go">
package main
import (
	"github.com/opencode-ai/opencode/cmd"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"github.com/opencode-ai/opencode/cmd"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
func main()
</file>

<file path="cmd/schema/README.md">
# OpenCode Configuration Schema Generator

This tool generates a JSON Schema for the OpenCode configuration file. The schema can be used to validate configuration files and provide autocompletion in editors that support JSON Schema.

## Usage

```bash
go run cmd/schema/main.go > opencode-schema.json
```

This will generate a JSON Schema file that can be used to validate configuration files.

## Schema Features

The generated schema includes:

- All configuration options with descriptions
- Default values where applicable
- Validation for enum values (e.g., model IDs, provider types)
- Required fields
- Type checking

## Using the Schema

You can use the generated schema in several ways:

1. **Editor Integration**: Many editors (VS Code, JetBrains IDEs, etc.) support JSON Schema for validation and autocompletion. You can configure your editor to use the generated schema for `.opencode.json` files.

2. **Validation Tools**: You can use tools like [jsonschema](https://github.com/Julian/jsonschema) to validate your configuration files against the schema.

3. **Documentation**: The schema serves as documentation for the configuration options.

## Example Configuration

Here's an example configuration that conforms to the schema:

```json
{
  "data": {
    "directory": ".opencode"
  },
  "debug": false,
  "providers": {
    "anthropic": {
      "apiKey": "your-api-key"
    }
  },
  "agents": {
    "coder": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 5000,
      "reasoningEffort": "medium"
    },
    "task": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 5000
    },
    "title": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 80
    }
  }
}
```
</file>

<file path="internal/llm/agent/agent-tool.go">
package agent
import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/session"
)
⋮----
"context"
"encoding/json"
"fmt"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/session"
⋮----
type agentTool struct {
	sessions   session.Service
	messages   message.Service
	lspClients map[string]*lsp.Client
}
const (
	AgentToolName = "agent"
)
type AgentParams struct {
	Prompt string `json:"prompt"`
}
func (b *agentTool) Info() tools.ToolInfo
func (b *agentTool) Run(ctx context.Context, call tools.ToolCall) (tools.ToolResponse, error)
⋮----
var params AgentParams
⋮----
func NewAgentTool(
	Sessions session.Service,
	Messages message.Service,
	LspClients map[string]*lsp.Client,
) tools.BaseTool
</file>

<file path="internal/llm/models/azure.go">
package models
const ProviderAzure ModelProvider = "azure"
const (
	AzureGPT41        ModelID = "azure.gpt-4.1"
	AzureGPT41Mini    ModelID = "azure.gpt-4.1-mini"
	AzureGPT41Nano    ModelID = "azure.gpt-4.1-nano"
	AzureGPT45Preview ModelID = "azure.gpt-4.5-preview"
	AzureGPT4o        ModelID = "azure.gpt-4o"
	AzureGPT4oMini    ModelID = "azure.gpt-4o-mini"
	AzureO1           ModelID = "azure.o1"
	AzureO1Mini       ModelID = "azure.o1-mini"
	AzureO3           ModelID = "azure.o3"
	AzureO3Mini       ModelID = "azure.o3-mini"
	AzureO4Mini       ModelID = "azure.o4-mini"
)
var AzureModels = map[ModelID]Model{
	AzureGPT41: {
		ID:                  AzureGPT41,
		Name:                "Azure OpenAI – GPT 4.1",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4.1",
		CostPer1MIn:         OpenAIModels[GPT41].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT41].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT41].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT41].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT41].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT41].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureGPT41Mini: {
		ID:                  AzureGPT41Mini,
		Name:                "Azure OpenAI – GPT 4.1 mini",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4.1-mini",
		CostPer1MIn:         OpenAIModels[GPT41Mini].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT41Mini].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT41Mini].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT41Mini].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT41Mini].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT41Mini].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureGPT41Nano: {
		ID:                  AzureGPT41Nano,
		Name:                "Azure OpenAI – GPT 4.1 nano",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4.1-nano",
		CostPer1MIn:         OpenAIModels[GPT41Nano].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT41Nano].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT41Nano].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT41Nano].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT41Nano].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT41Nano].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureGPT45Preview: {
		ID:                  AzureGPT45Preview,
		Name:                "Azure OpenAI – GPT 4.5 preview",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4.5-preview",
		CostPer1MIn:         OpenAIModels[GPT45Preview].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT45Preview].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT45Preview].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT45Preview].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT45Preview].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT45Preview].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureGPT4o: {
		ID:                  AzureGPT4o,
		Name:                "Azure OpenAI – GPT-4o",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4o",
		CostPer1MIn:         OpenAIModels[GPT4o].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT4o].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT4o].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT4o].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT4o].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT4o].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureGPT4oMini: {
		ID:                  AzureGPT4oMini,
		Name:                "Azure OpenAI – GPT-4o mini",
		Provider:            ProviderAzure,
		APIModel:            "gpt-4o-mini",
		CostPer1MIn:         OpenAIModels[GPT4oMini].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[GPT4oMini].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[GPT4oMini].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[GPT4oMini].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[GPT4oMini].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[GPT4oMini].DefaultMaxTokens,
		SupportsAttachments: true,
	},
	AzureO1: {
		ID:                  AzureO1,
		Name:                "Azure OpenAI – O1",
		Provider:            ProviderAzure,
		APIModel:            "o1",
		CostPer1MIn:         OpenAIModels[O1].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[O1].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[O1].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[O1].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[O1].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[O1].DefaultMaxTokens,
		CanReason:           OpenAIModels[O1].CanReason,
		SupportsAttachments: true,
	},
	AzureO1Mini: {
		ID:                  AzureO1Mini,
		Name:                "Azure OpenAI – O1 mini",
		Provider:            ProviderAzure,
		APIModel:            "o1-mini",
		CostPer1MIn:         OpenAIModels[O1Mini].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[O1Mini].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[O1Mini].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[O1Mini].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[O1Mini].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[O1Mini].DefaultMaxTokens,
		CanReason:           OpenAIModels[O1Mini].CanReason,
		SupportsAttachments: true,
	},
	AzureO3: {
		ID:                  AzureO3,
		Name:                "Azure OpenAI – O3",
		Provider:            ProviderAzure,
		APIModel:            "o3",
		CostPer1MIn:         OpenAIModels[O3].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[O3].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[O3].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[O3].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[O3].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[O3].DefaultMaxTokens,
		CanReason:           OpenAIModels[O3].CanReason,
		SupportsAttachments: true,
	},
	AzureO3Mini: {
		ID:                  AzureO3Mini,
		Name:                "Azure OpenAI – O3 mini",
		Provider:            ProviderAzure,
		APIModel:            "o3-mini",
		CostPer1MIn:         OpenAIModels[O3Mini].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[O3Mini].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[O3Mini].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[O3Mini].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[O3Mini].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[O3Mini].DefaultMaxTokens,
		CanReason:           OpenAIModels[O3Mini].CanReason,
		SupportsAttachments: false,
	},
	AzureO4Mini: {
		ID:                  AzureO4Mini,
		Name:                "Azure OpenAI – O4 mini",
		Provider:            ProviderAzure,
		APIModel:            "o4-mini",
		CostPer1MIn:         OpenAIModels[O4Mini].CostPer1MIn,
		CostPer1MInCached:   OpenAIModels[O4Mini].CostPer1MInCached,
		CostPer1MOut:        OpenAIModels[O4Mini].CostPer1MOut,
		CostPer1MOutCached:  OpenAIModels[O4Mini].CostPer1MOutCached,
		ContextWindow:       OpenAIModels[O4Mini].ContextWindow,
		DefaultMaxTokens:    OpenAIModels[O4Mini].DefaultMaxTokens,
		CanReason:           OpenAIModels[O4Mini].CanReason,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/gemini.go">
package models
const (
	ProviderGemini ModelProvider = "gemini"
	Gemini25Flash     ModelID = "gemini-2.5-flash"
	Gemini25          ModelID = "gemini-2.5"
	Gemini20Flash     ModelID = "gemini-2.0-flash"
	Gemini20FlashLite ModelID = "gemini-2.0-flash-lite"
)
var GeminiModels = map[ModelID]Model{
	Gemini25Flash: {
		ID:                  Gemini25Flash,
		Name:                "Gemini 2.5 Flash",
		Provider:            ProviderGemini,
		APIModel:            "gemini-2.5-flash-preview-04-17",
		CostPer1MIn:         0.15,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.60,
		ContextWindow:       1000000,
		DefaultMaxTokens:    50000,
		SupportsAttachments: true,
	},
	Gemini25: {
		ID:                  Gemini25,
		Name:                "Gemini 2.5 Pro",
		Provider:            ProviderGemini,
		APIModel:            "gemini-2.5-pro-preview-05-06",
		CostPer1MIn:         1.25,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        10,
		ContextWindow:       1000000,
		DefaultMaxTokens:    50000,
		SupportsAttachments: true,
	},
	Gemini20Flash: {
		ID:                  Gemini20Flash,
		Name:                "Gemini 2.0 Flash",
		Provider:            ProviderGemini,
		APIModel:            "gemini-2.0-flash",
		CostPer1MIn:         0.10,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.40,
		ContextWindow:       1000000,
		DefaultMaxTokens:    6000,
		SupportsAttachments: true,
	},
	Gemini20FlashLite: {
		ID:                  Gemini20FlashLite,
		Name:                "Gemini 2.0 Flash Lite",
		Provider:            ProviderGemini,
		APIModel:            "gemini-2.0-flash-lite",
		CostPer1MIn:         0.05,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.30,
		ContextWindow:       1000000,
		DefaultMaxTokens:    6000,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/groq.go">
package models
const (
	ProviderGROQ ModelProvider = "groq"
	QWENQwq ModelID = "qwen-qwq"
	Llama4Scout               ModelID = "meta-llama/llama-4-scout-17b-16e-instruct"
	Llama4Maverick            ModelID = "meta-llama/llama-4-maverick-17b-128e-instruct"
	Llama3_3_70BVersatile     ModelID = "llama-3.3-70b-versatile"
	DeepseekR1DistillLlama70b ModelID = "deepseek-r1-distill-llama-70b"
)
var GroqModels = map[ModelID]Model{
	QWENQwq: {
		ID:                 QWENQwq,
		Name:               "Qwen Qwq",
		Provider:           ProviderGROQ,
		APIModel:           "qwen-qwq-32b",
		CostPer1MIn:        0.29,
		CostPer1MInCached:  0.275,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       0.39,
		ContextWindow:      128_000,
		DefaultMaxTokens:   50000,
		CanReason:           false,
		SupportsAttachments: false,
	},
	Llama4Scout: {
		ID:                  Llama4Scout,
		Name:                "Llama4Scout",
		Provider:            ProviderGROQ,
		APIModel:            "meta-llama/llama-4-scout-17b-16e-instruct",
		CostPer1MIn:         0.11,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.34,
		ContextWindow:       128_000,
		SupportsAttachments: true,
	},
	Llama4Maverick: {
		ID:                  Llama4Maverick,
		Name:                "Llama4Maverick",
		Provider:            ProviderGROQ,
		APIModel:            "meta-llama/llama-4-maverick-17b-128e-instruct",
		CostPer1MIn:         0.20,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.20,
		ContextWindow:       128_000,
		SupportsAttachments: true,
	},
	Llama3_3_70BVersatile: {
		ID:                  Llama3_3_70BVersatile,
		Name:                "Llama3_3_70BVersatile",
		Provider:            ProviderGROQ,
		APIModel:            "llama-3.3-70b-versatile",
		CostPer1MIn:         0.59,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.79,
		ContextWindow:       128_000,
		SupportsAttachments: false,
	},
	DeepseekR1DistillLlama70b: {
		ID:                  DeepseekR1DistillLlama70b,
		Name:                "DeepseekR1DistillLlama70b",
		Provider:            ProviderGROQ,
		APIModel:            "deepseek-r1-distill-llama-70b",
		CostPer1MIn:         0.75,
		CostPer1MInCached:   0,
		CostPer1MOutCached:  0,
		CostPer1MOut:        0.99,
		ContextWindow:       128_000,
		CanReason:           true,
		SupportsAttachments: false,
	},
}
</file>

<file path="internal/llm/models/openrouter.go">
package models
const (
	ProviderOpenRouter ModelProvider = "openrouter"
	OpenRouterGPT41          ModelID = "openrouter.gpt-4.1"
	OpenRouterGPT41Mini      ModelID = "openrouter.gpt-4.1-mini"
	OpenRouterGPT41Nano      ModelID = "openrouter.gpt-4.1-nano"
	OpenRouterGPT45Preview   ModelID = "openrouter.gpt-4.5-preview"
	OpenRouterGPT4o          ModelID = "openrouter.gpt-4o"
	OpenRouterGPT4oMini      ModelID = "openrouter.gpt-4o-mini"
	OpenRouterO1             ModelID = "openrouter.o1"
	OpenRouterO1Pro          ModelID = "openrouter.o1-pro"
	OpenRouterO1Mini         ModelID = "openrouter.o1-mini"
	OpenRouterO3             ModelID = "openrouter.o3"
	OpenRouterO3Mini         ModelID = "openrouter.o3-mini"
	OpenRouterO4Mini         ModelID = "openrouter.o4-mini"
	OpenRouterGemini25Flash  ModelID = "openrouter.gemini-2.5-flash"
	OpenRouterGemini25       ModelID = "openrouter.gemini-2.5"
	OpenRouterClaude35Sonnet ModelID = "openrouter.claude-3.5-sonnet"
	OpenRouterClaude3Haiku   ModelID = "openrouter.claude-3-haiku"
	OpenRouterClaude37Sonnet ModelID = "openrouter.claude-3.7-sonnet"
	OpenRouterClaude35Haiku  ModelID = "openrouter.claude-3.5-haiku"
	OpenRouterClaude3Opus    ModelID = "openrouter.claude-3-opus"
	OpenRouterDeepSeekR1Free ModelID = "openrouter.deepseek-r1-free"
)
var OpenRouterModels = map[ModelID]Model{
	OpenRouterGPT41: {
		ID:                 OpenRouterGPT41,
		Name:               "OpenRouter – GPT 4.1",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4.1",
		CostPer1MIn:        OpenAIModels[GPT41].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT41].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT41].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT41].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT41].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[GPT41].DefaultMaxTokens,
	},
	OpenRouterGPT41Mini: {
		ID:                 OpenRouterGPT41Mini,
		Name:               "OpenRouter – GPT 4.1 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4.1-mini",
		CostPer1MIn:        OpenAIModels[GPT41Mini].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT41Mini].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT41Mini].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT41Mini].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT41Mini].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[GPT41Mini].DefaultMaxTokens,
	},
	OpenRouterGPT41Nano: {
		ID:                 OpenRouterGPT41Nano,
		Name:               "OpenRouter – GPT 4.1 nano",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4.1-nano",
		CostPer1MIn:        OpenAIModels[GPT41Nano].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT41Nano].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT41Nano].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT41Nano].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT41Nano].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[GPT41Nano].DefaultMaxTokens,
	},
	OpenRouterGPT45Preview: {
		ID:                 OpenRouterGPT45Preview,
		Name:               "OpenRouter – GPT 4.5 preview",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4.5-preview",
		CostPer1MIn:        OpenAIModels[GPT45Preview].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT45Preview].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT45Preview].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT45Preview].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT45Preview].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[GPT45Preview].DefaultMaxTokens,
	},
	OpenRouterGPT4o: {
		ID:                 OpenRouterGPT4o,
		Name:               "OpenRouter – GPT 4o",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4o",
		CostPer1MIn:        OpenAIModels[GPT4o].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT4o].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT4o].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT4o].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT4o].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[GPT4o].DefaultMaxTokens,
	},
	OpenRouterGPT4oMini: {
		ID:                 OpenRouterGPT4oMini,
		Name:               "OpenRouter – GPT 4o mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/gpt-4o-mini",
		CostPer1MIn:        OpenAIModels[GPT4oMini].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[GPT4oMini].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[GPT4oMini].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[GPT4oMini].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[GPT4oMini].ContextWindow,
	},
	OpenRouterO1: {
		ID:                 OpenRouterO1,
		Name:               "OpenRouter – O1",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o1",
		CostPer1MIn:        OpenAIModels[O1].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O1].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O1].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O1].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O1].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O1].DefaultMaxTokens,
		CanReason:          OpenAIModels[O1].CanReason,
	},
	OpenRouterO1Pro: {
		ID:                 OpenRouterO1Pro,
		Name:               "OpenRouter – o1 pro",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o1-pro",
		CostPer1MIn:        OpenAIModels[O1Pro].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O1Pro].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O1Pro].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O1Pro].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O1Pro].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O1Pro].DefaultMaxTokens,
		CanReason:          OpenAIModels[O1Pro].CanReason,
	},
	OpenRouterO1Mini: {
		ID:                 OpenRouterO1Mini,
		Name:               "OpenRouter – o1 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o1-mini",
		CostPer1MIn:        OpenAIModels[O1Mini].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O1Mini].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O1Mini].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O1Mini].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O1Mini].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O1Mini].DefaultMaxTokens,
		CanReason:          OpenAIModels[O1Mini].CanReason,
	},
	OpenRouterO3: {
		ID:                 OpenRouterO3,
		Name:               "OpenRouter – o3",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o3",
		CostPer1MIn:        OpenAIModels[O3].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O3].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O3].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O3].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O3].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O3].DefaultMaxTokens,
		CanReason:          OpenAIModels[O3].CanReason,
	},
	OpenRouterO3Mini: {
		ID:                 OpenRouterO3Mini,
		Name:               "OpenRouter – o3 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o3-mini-high",
		CostPer1MIn:        OpenAIModels[O3Mini].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O3Mini].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O3Mini].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O3Mini].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O3Mini].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O3Mini].DefaultMaxTokens,
		CanReason:          OpenAIModels[O3Mini].CanReason,
	},
	OpenRouterO4Mini: {
		ID:                 OpenRouterO4Mini,
		Name:               "OpenRouter – o4 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "openai/o4-mini-high",
		CostPer1MIn:        OpenAIModels[O4Mini].CostPer1MIn,
		CostPer1MInCached:  OpenAIModels[O4Mini].CostPer1MInCached,
		CostPer1MOut:       OpenAIModels[O4Mini].CostPer1MOut,
		CostPer1MOutCached: OpenAIModels[O4Mini].CostPer1MOutCached,
		ContextWindow:      OpenAIModels[O4Mini].ContextWindow,
		DefaultMaxTokens:   OpenAIModels[O4Mini].DefaultMaxTokens,
		CanReason:          OpenAIModels[O4Mini].CanReason,
	},
	OpenRouterGemini25Flash: {
		ID:                 OpenRouterGemini25Flash,
		Name:               "OpenRouter – Gemini 2.5 Flash",
		Provider:           ProviderOpenRouter,
		APIModel:           "google/gemini-2.5-flash-preview:thinking",
		CostPer1MIn:        GeminiModels[Gemini25Flash].CostPer1MIn,
		CostPer1MInCached:  GeminiModels[Gemini25Flash].CostPer1MInCached,
		CostPer1MOut:       GeminiModels[Gemini25Flash].CostPer1MOut,
		CostPer1MOutCached: GeminiModels[Gemini25Flash].CostPer1MOutCached,
		ContextWindow:      GeminiModels[Gemini25Flash].ContextWindow,
		DefaultMaxTokens:   GeminiModels[Gemini25Flash].DefaultMaxTokens,
	},
	OpenRouterGemini25: {
		ID:                 OpenRouterGemini25,
		Name:               "OpenRouter – Gemini 2.5 Pro",
		Provider:           ProviderOpenRouter,
		APIModel:           "google/gemini-2.5-pro-preview-03-25",
		CostPer1MIn:        GeminiModels[Gemini25].CostPer1MIn,
		CostPer1MInCached:  GeminiModels[Gemini25].CostPer1MInCached,
		CostPer1MOut:       GeminiModels[Gemini25].CostPer1MOut,
		CostPer1MOutCached: GeminiModels[Gemini25].CostPer1MOutCached,
		ContextWindow:      GeminiModels[Gemini25].ContextWindow,
		DefaultMaxTokens:   GeminiModels[Gemini25].DefaultMaxTokens,
	},
	OpenRouterClaude35Sonnet: {
		ID:                 OpenRouterClaude35Sonnet,
		Name:               "OpenRouter – Claude 3.5 Sonnet",
		Provider:           ProviderOpenRouter,
		APIModel:           "anthropic/claude-3.5-sonnet",
		CostPer1MIn:        AnthropicModels[Claude35Sonnet].CostPer1MIn,
		CostPer1MInCached:  AnthropicModels[Claude35Sonnet].CostPer1MInCached,
		CostPer1MOut:       AnthropicModels[Claude35Sonnet].CostPer1MOut,
		CostPer1MOutCached: AnthropicModels[Claude35Sonnet].CostPer1MOutCached,
		ContextWindow:      AnthropicModels[Claude35Sonnet].ContextWindow,
		DefaultMaxTokens:   AnthropicModels[Claude35Sonnet].DefaultMaxTokens,
	},
	OpenRouterClaude3Haiku: {
		ID:                 OpenRouterClaude3Haiku,
		Name:               "OpenRouter – Claude 3 Haiku",
		Provider:           ProviderOpenRouter,
		APIModel:           "anthropic/claude-3-haiku",
		CostPer1MIn:        AnthropicModels[Claude3Haiku].CostPer1MIn,
		CostPer1MInCached:  AnthropicModels[Claude3Haiku].CostPer1MInCached,
		CostPer1MOut:       AnthropicModels[Claude3Haiku].CostPer1MOut,
		CostPer1MOutCached: AnthropicModels[Claude3Haiku].CostPer1MOutCached,
		ContextWindow:      AnthropicModels[Claude3Haiku].ContextWindow,
		DefaultMaxTokens:   AnthropicModels[Claude3Haiku].DefaultMaxTokens,
	},
	OpenRouterClaude37Sonnet: {
		ID:                 OpenRouterClaude37Sonnet,
		Name:               "OpenRouter – Claude 3.7 Sonnet",
		Provider:           ProviderOpenRouter,
		APIModel:           "anthropic/claude-3.7-sonnet",
		CostPer1MIn:        AnthropicModels[Claude37Sonnet].CostPer1MIn,
		CostPer1MInCached:  AnthropicModels[Claude37Sonnet].CostPer1MInCached,
		CostPer1MOut:       AnthropicModels[Claude37Sonnet].CostPer1MOut,
		CostPer1MOutCached: AnthropicModels[Claude37Sonnet].CostPer1MOutCached,
		ContextWindow:      AnthropicModels[Claude37Sonnet].ContextWindow,
		DefaultMaxTokens:   AnthropicModels[Claude37Sonnet].DefaultMaxTokens,
		CanReason:          AnthropicModels[Claude37Sonnet].CanReason,
	},
	OpenRouterClaude35Haiku: {
		ID:                 OpenRouterClaude35Haiku,
		Name:               "OpenRouter – Claude 3.5 Haiku",
		Provider:           ProviderOpenRouter,
		APIModel:           "anthropic/claude-3.5-haiku",
		CostPer1MIn:        AnthropicModels[Claude35Haiku].CostPer1MIn,
		CostPer1MInCached:  AnthropicModels[Claude35Haiku].CostPer1MInCached,
		CostPer1MOut:       AnthropicModels[Claude35Haiku].CostPer1MOut,
		CostPer1MOutCached: AnthropicModels[Claude35Haiku].CostPer1MOutCached,
		ContextWindow:      AnthropicModels[Claude35Haiku].ContextWindow,
		DefaultMaxTokens:   AnthropicModels[Claude35Haiku].DefaultMaxTokens,
	},
	OpenRouterClaude3Opus: {
		ID:                 OpenRouterClaude3Opus,
		Name:               "OpenRouter – Claude 3 Opus",
		Provider:           ProviderOpenRouter,
		APIModel:           "anthropic/claude-3-opus",
		CostPer1MIn:        AnthropicModels[Claude3Opus].CostPer1MIn,
		CostPer1MInCached:  AnthropicModels[Claude3Opus].CostPer1MInCached,
		CostPer1MOut:       AnthropicModels[Claude3Opus].CostPer1MOut,
		CostPer1MOutCached: AnthropicModels[Claude3Opus].CostPer1MOutCached,
		ContextWindow:      AnthropicModels[Claude3Opus].ContextWindow,
		DefaultMaxTokens:   AnthropicModels[Claude3Opus].DefaultMaxTokens,
	},
	OpenRouterDeepSeekR1Free: {
		ID:                 OpenRouterDeepSeekR1Free,
		Name:               "OpenRouter – DeepSeek R1 Free",
		Provider:           ProviderOpenRouter,
		APIModel:           "deepseek/deepseek-r1-0528:free",
		CostPer1MIn:        0,
		CostPer1MInCached:  0,
		CostPer1MOut:       0,
		CostPer1MOutCached: 0,
		ContextWindow:      163_840,
		DefaultMaxTokens:   10000,
	},
}
</file>

<file path="internal/llm/provider/bedrock.go">
package provider
import (
	"context"
	"errors"
	"fmt"
	"os"
	"strings"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/message"
)
⋮----
"context"
"errors"
"fmt"
"os"
"strings"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/message"
⋮----
type bedrockOptions struct {
}
type BedrockOption func(*bedrockOptions)
type bedrockClient struct {
	providerOptions providerClientOptions
	options         bedrockOptions
	childProvider   ProviderClient
}
type BedrockClient ProviderClient
func newBedrockClient(opts providerClientOptions) BedrockClient
func (b *bedrockClient) send(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
func (b *bedrockClient) stream(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
</file>

<file path="internal/llm/tools/bash.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"strings"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/tools/shell"
	"github.com/opencode-ai/opencode/internal/permission"
)
⋮----
"context"
"encoding/json"
"fmt"
"strings"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/tools/shell"
"github.com/opencode-ai/opencode/internal/permission"
⋮----
type BashParams struct {
	Command string `json:"command"`
	Timeout int    `json:"timeout"`
}
type BashPermissionsParams struct {
	Command string `json:"command"`
	Timeout int    `json:"timeout"`
}
type BashResponseMetadata struct {
	StartTime int64 `json:"start_time"`
	EndTime   int64 `json:"end_time"`
}
type bashTool struct {
	permissions permission.Service
}
const (
	BashToolName = "bash"
	DefaultTimeout  = 1 * 60 * 1000
	MaxTimeout      = 10 * 60 * 1000
	MaxOutputLength = 30000
)
var bannedCommands = []string{
	"alias", "curl", "curlie", "wget", "axel", "aria2c",
	"nc", "telnet", "lynx", "w3m", "links", "httpie", "xh",
	"http-prompt", "chrome", "firefox", "safari",
}
var safeReadOnlyCommands = []string{
	"ls", "echo", "pwd", "date", "cal", "uptime", "whoami", "id", "groups", "env", "printenv", "set", "unset", "which", "type", "whereis",
	"whatis", "uname", "hostname", "df", "du", "free", "top", "ps", "kill", "killall", "nice", "nohup", "time", "timeout",
	"git status", "git log", "git diff", "git show", "git branch", "git tag", "git remote", "git ls-files", "git ls-remote",
	"git rev-parse", "git config --get", "git config --list", "git describe", "git blame", "git grep", "git shortlog",
	"go version", "go help", "go list", "go env", "go doc", "go vet", "go fmt", "go mod", "go test", "go build", "go run", "go install", "go clean",
}
func bashDescription() string
func NewBashTool(permission permission.Service) BaseTool
func (b *bashTool) Info() ToolInfo
func (b *bashTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params BashParams
⋮----
func truncateOutput(content string) string
func countLines(s string) int
</file>

<file path="internal/llm/tools/fetch.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"
	md "github.com/JohannesKaufmann/html-to-markdown"
	"github.com/PuerkitoBio/goquery"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/permission"
)
⋮----
"context"
"encoding/json"
"fmt"
"io"
"net/http"
"strings"
"time"
md "github.com/JohannesKaufmann/html-to-markdown"
"github.com/PuerkitoBio/goquery"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/permission"
⋮----
type FetchParams struct {
	URL     string `json:"url"`
	Format  string `json:"format"`
	Timeout int    `json:"timeout,omitempty"`
}
type FetchPermissionsParams struct {
	URL     string `json:"url"`
	Format  string `json:"format"`
	Timeout int    `json:"timeout,omitempty"`
}
type fetchTool struct {
	client      *http.Client
	permissions permission.Service
}
const (
	FetchToolName        = "fetch"
	fetchToolDescription = `Fetches content from a URL and returns it in the specified format.
WHEN TO USE THIS TOOL:
- Use when you need to download content from a URL
- Helpful for retrieving documentation, API responses, or web content
- Useful for getting external information to assist with tasks
HOW TO USE:
- Provide the URL to fetch content from
- Specify the desired output format (text, markdown, or html)
func NewFetchTool(permissions permission.Service) BaseTool
func (t *fetchTool) Info() ToolInfo
func (t *fetchTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params FetchParams
⋮----
func extractTextFromHTML(html string) (string, error)
func convertHTMLToMarkdown(html string) (string, error)
</file>

<file path="internal/llm/tools/view.go">
package tools
import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
)
⋮----
"bufio"
"context"
"encoding/json"
"fmt"
"io"
"os"
"path/filepath"
"strings"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
⋮----
type ViewParams struct {
	FilePath string `json:"file_path"`
	Offset   int    `json:"offset"`
	Limit    int    `json:"limit"`
}
type viewTool struct {
	lspClients map[string]*lsp.Client
}
type ViewResponseMetadata struct {
	FilePath string `json:"file_path"`
	Content  string `json:"content"`
}
const (
	ViewToolName     = "view"
	MaxReadSize      = 250 * 1024
	DefaultReadLimit = 2000
	MaxLineLength    = 2000
	viewDescription  = `File viewing tool that reads and displays the contents of files with line numbers, allowing you to examine code, logs, or text data.
WHEN TO USE THIS TOOL:
- Use when you need to read the contents of a specific file
- Helpful for examining source code, configuration files, or log files
- Perfect for looking at text-based file formats
HOW TO USE:
- Provide the path to the file you want to view
- Optionally specify an offset to start reading from a specific line
- Optionally specify a limit to control how many lines are read
FEATURES:
- Displays file contents with line numbers for easy reference
- Can read from any position in a file using the offset parameter
- Handles large files by limiting the number of lines read
- Automatically truncates very long lines for better display
- Suggests similar file names when the requested file isn't found
LIMITATIONS:
- Maximum file size is 250KB
- Default reading limit is 2000 lines
- Lines longer than 2000 characters are truncated
- Cannot display binary files or images
- Images can be identified but not displayed
TIPS:
- Use with Glob tool to first find files you want to view
- For code exploration, first use Grep to find relevant files, then View to examine them
- When viewing large files, use the offset parameter to read specific sections`
)
func NewViewTool(lspClients map[string]*lsp.Client) BaseTool
func (v *viewTool) Info() ToolInfo
func (v *viewTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params ViewParams
⋮----
var suggestions []string
⋮----
func addLineNumbers(content string, startLine int) string
⋮----
var result []string
⋮----
func readTextFile(filePath string, offset, limit int) (string, int, error)
⋮----
var lines []string
⋮----
// Continue scanning to get total line count
⋮----
func isImageFile(filePath string) (bool, string)
type LineScanner struct {
	scanner *bufio.Scanner
}
func NewLineScanner(r io.Reader) *LineScanner
func (s *LineScanner) Scan() bool
func (s *LineScanner) Text() string
func (s *LineScanner) Err() error
</file>

<file path="internal/logging/writer.go">
package logging
import (
	"bytes"
	"context"
	"fmt"
	"strings"
	"sync"
	"time"
	"github.com/go-logfmt/logfmt"
	"github.com/opencode-ai/opencode/internal/pubsub"
)
⋮----
"bytes"
"context"
"fmt"
"strings"
"sync"
"time"
"github.com/go-logfmt/logfmt"
"github.com/opencode-ai/opencode/internal/pubsub"
⋮----
const (
	persistKeyArg  = "$_persist"
	PersistTimeArg = "$_persist_time"
)
type LogData struct {
	messages []LogMessage
	*pubsub.Broker[LogMessage]
	lock sync.Mutex
}
func (l *LogData) Add(msg LogMessage)
func (l *LogData) List() []LogMessage
var defaultLogData = &LogData{
	messages: make([]LogMessage, 0),
	Broker:   pubsub.NewBroker[LogMessage](),
}
type writer struct{}
func (w *writer) Write(p []byte) (int, error)
func NewWriter() *writer
func Subscribe(ctx context.Context) <-chan pubsub.Event[LogMessage]
func List() []LogMessage
</file>

<file path="internal/lsp/client.go">
package lsp
import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"sync"
	"sync/atomic"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"bufio"
"context"
"encoding/json"
"fmt"
"io"
"os"
"os/exec"
"path/filepath"
"strings"
"sync"
"sync/atomic"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
type Client struct {
	Cmd    *exec.Cmd
	stdin  io.WriteCloser
	stdout *bufio.Reader
	stderr io.ReadCloser
	nextID atomic.Int32
	handlers   map[int32]chan *Message
	handlersMu sync.RWMutex
	serverRequestHandlers map[string]ServerRequestHandler
	serverHandlersMu      sync.RWMutex
	notificationHandlers map[string]NotificationHandler
	notificationMu       sync.RWMutex
	diagnostics   map[protocol.DocumentUri][]protocol.Diagnostic
	diagnosticsMu sync.RWMutex
	openFiles   map[string]*OpenFileInfo
	openFilesMu sync.RWMutex
	serverState atomic.Value
}
func NewClient(ctx context.Context, command string, args ...string) (*Client, error)
func (c *Client) RegisterNotificationHandler(method string, handler NotificationHandler)
func (c *Client) RegisterServerRequestHandler(method string, handler ServerRequestHandler)
func (c *Client) InitializeLSPClient(ctx context.Context, workspaceDir string) (*protocol.InitializeResult, error)
⋮----
var result protocol.InitializeResult
⋮----
func (c *Client) Close() error
type ServerState int
const (
	StateStarting ServerState = iota
	StateReady
	StateError
)
func (c *Client) GetServerState() ServerState
func (c *Client) SetServerState(state ServerState)
func (c *Client) WaitForServerReady(ctx context.Context) error
type ServerType int
const (
	ServerTypeUnknown ServerType = iota
	ServerTypeGo
	ServerTypeTypeScript
	ServerTypeRust
	ServerTypePython
	ServerTypeGeneric
)
func (c *Client) detectServerType() ServerType
func (c *Client) openKeyConfigFiles(ctx context.Context)
⋮----
var filesToOpen []string
⋮----
func (c *Client) pingServerByType(ctx context.Context, serverType ServerType) error
func (c *Client) pingTypeScriptServer(ctx context.Context) error
⋮----
var symbols []protocol.DocumentSymbol
⋮----
func (c *Client) openTypeScriptFiles(ctx context.Context, workDir string)
func shouldSkipDir(path string) bool
func (c *Client) pingWithWorkspaceSymbol(ctx context.Context) error
⋮----
var result []protocol.SymbolInformation
⋮----
// pingWithServerCapabilities tries to get server capabilities
func (c *Client) pingWithServerCapabilities(ctx context.Context) error
⋮----
// This is a very lightweight request that should work for most servers
⋮----
type OpenFileInfo struct {
	Version int32
	URI     protocol.DocumentUri
}
func (c *Client) OpenFile(ctx context.Context, filepath string) error
func (c *Client) NotifyChange(ctx context.Context, filepath string) error
func (c *Client) CloseFile(ctx context.Context, filepath string) error
func (c *Client) IsFileOpen(filepath string) bool
func (c *Client) CloseAllFiles(ctx context.Context)
func (c *Client) GetFileDiagnostics(uri protocol.DocumentUri) []protocol.Diagnostic
func (c *Client) GetDiagnostics() map[protocol.DocumentUri][]protocol.Diagnostic
func (c *Client) OpenFileOnDemand(ctx context.Context, filepath string) error
func (c *Client) GetDiagnosticsForFile(ctx context.Context, filepath string) ([]protocol.Diagnostic, error)
func (c *Client) ClearDiagnosticsForURI(uri protocol.DocumentUri)
</file>

<file path="internal/message/content.go">
package message
import (
	"encoding/base64"
	"slices"
	"time"
	"github.com/opencode-ai/opencode/internal/llm/models"
)
⋮----
"encoding/base64"
"slices"
"time"
"github.com/opencode-ai/opencode/internal/llm/models"
⋮----
type MessageRole string
const (
	Assistant MessageRole = "assistant"
	User      MessageRole = "user"
	System    MessageRole = "system"
	Tool      MessageRole = "tool"
)
type FinishReason string
const (
	FinishReasonEndTurn          FinishReason = "end_turn"
	FinishReasonMaxTokens        FinishReason = "max_tokens"
	FinishReasonToolUse          FinishReason = "tool_use"
	FinishReasonCanceled         FinishReason = "canceled"
	FinishReasonError            FinishReason = "error"
	FinishReasonPermissionDenied FinishReason = "permission_denied"
	FinishReasonUnknown FinishReason = "unknown"
)
type ContentPart interface {
	isPart()
}
type ReasoningContent struct {
	Thinking string `json:"thinking"`
}
func (tc ReasoningContent) String() string
func (ReasoningContent) isPart()
type TextContent struct {
	Text string `json:"text"`
}
⋮----
type ImageURLContent struct {
	URL    string `json:"url"`
	Detail string `json:"detail,omitempty"`
}
⋮----
type BinaryContent struct {
	Path     string
	MIMEType string
	Data     []byte
}
⋮----
type ToolCall struct {
	ID       string `json:"id"`
	Name     string `json:"name"`
	Input    string `json:"input"`
	Type     string `json:"type"`
	Finished bool   `json:"finished"`
}
⋮----
type ToolResult struct {
	ToolCallID string `json:"tool_call_id"`
	Name       string `json:"name"`
	Content    string `json:"content"`
	Metadata   string `json:"metadata"`
	IsError    bool   `json:"is_error"`
}
⋮----
type Finish struct {
	Reason FinishReason `json:"reason"`
	Time   int64        `json:"time"`
}
⋮----
type Message struct {
	ID        string
	Role      MessageRole
	SessionID string
	Parts     []ContentPart
	Model     models.ModelID
	CreatedAt int64
	UpdatedAt int64
}
func (m *Message) Content() TextContent
func (m *Message) ReasoningContent() ReasoningContent
func (m *Message) ImageURLContent() []ImageURLContent
func (m *Message) BinaryContent() []BinaryContent
func (m *Message) ToolCalls() []ToolCall
func (m *Message) ToolResults() []ToolResult
func (m *Message) IsFinished() bool
func (m *Message) FinishPart() *Finish
func (m *Message) FinishReason() FinishReason
func (m *Message) IsThinking() bool
func (m *Message) AppendContent(delta string)
func (m *Message) AppendReasoningContent(delta string)
func (m *Message) FinishToolCall(toolCallID string)
func (m *Message) AppendToolCallInput(toolCallID string, inputDelta string)
func (m *Message) AddToolCall(tc ToolCall)
func (m *Message) SetToolCalls(tc []ToolCall)
func (m *Message) AddToolResult(tr ToolResult)
func (m *Message) SetToolResults(tr []ToolResult)
func (m *Message) AddFinish(reason FinishReason)
func (m *Message) AddImageURL(url, detail string)
func (m *Message) AddBinary(mimeType string, data []byte)
</file>

<file path="internal/message/message.go">
package message
import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"
	"github.com/google/uuid"
	"github.com/opencode-ai/opencode/internal/db"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/pubsub"
)
⋮----
"context"
"database/sql"
"encoding/json"
"fmt"
"time"
"github.com/google/uuid"
"github.com/opencode-ai/opencode/internal/db"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/pubsub"
⋮----
type CreateMessageParams struct {
	Role  MessageRole
	Parts []ContentPart
	Model models.ModelID
}
type Service interface {
	pubsub.Suscriber[Message]
	Create(ctx context.Context, sessionID string, params CreateMessageParams) (Message, error)
	Update(ctx context.Context, message Message) error
	Get(ctx context.Context, id string) (Message, error)
	List(ctx context.Context, sessionID string) ([]Message, error)
	Delete(ctx context.Context, id string) error
	DeleteSessionMessages(ctx context.Context, sessionID string) error
}
type service struct {
	*pubsub.Broker[Message]
	q db.Querier
}
func NewService(q db.Querier) Service
func (s *service) Delete(ctx context.Context, id string) error
func (s *service) Create(ctx context.Context, sessionID string, params CreateMessageParams) (Message, error)
func (s *service) DeleteSessionMessages(ctx context.Context, sessionID string) error
func (s *service) Update(ctx context.Context, message Message) error
func (s *service) Get(ctx context.Context, id string) (Message, error)
func (s *service) List(ctx context.Context, sessionID string) ([]Message, error)
func (s *service) fromDBItem(item db.Message) (Message, error)
type partType string
const (
	reasoningType  partType = "reasoning"
	textType       partType = "text"
	imageURLType   partType = "image_url"
	binaryType     partType = "binary"
	toolCallType   partType = "tool_call"
	toolResultType partType = "tool_result"
	finishType     partType = "finish"
)
type partWrapper struct {
	Type partType    `json:"type"`
	Data ContentPart `json:"data"`
}
func marshallParts(parts []ContentPart) ([]byte, error)
⋮----
var typ partType
⋮----
func unmarshallParts(data []byte) ([]ContentPart, error)
⋮----
var wrapper struct {
			Type partType        `json:"type"`
			Data json.RawMessage `json:"data"`
		}
</file>

<file path="internal/session/session.go">
package session
import (
	"context"
	"database/sql"
	"github.com/google/uuid"
	"github.com/opencode-ai/opencode/internal/db"
	"github.com/opencode-ai/opencode/internal/pubsub"
)
⋮----
"context"
"database/sql"
"github.com/google/uuid"
"github.com/opencode-ai/opencode/internal/db"
"github.com/opencode-ai/opencode/internal/pubsub"
⋮----
type Session struct {
	ID               string
	ParentSessionID  string
	Title            string
	MessageCount     int64
	PromptTokens     int64
	CompletionTokens int64
	SummaryMessageID string
	Cost             float64
	CreatedAt        int64
	UpdatedAt        int64
}
type Service interface {
	pubsub.Suscriber[Session]
	Create(ctx context.Context, title string) (Session, error)
	CreateTitleSession(ctx context.Context, parentSessionID string) (Session, error)
	CreateTaskSession(ctx context.Context, toolCallID, parentSessionID, title string) (Session, error)
	Get(ctx context.Context, id string) (Session, error)
	List(ctx context.Context) ([]Session, error)
	Save(ctx context.Context, session Session) (Session, error)
	Delete(ctx context.Context, id string) error
}
type service struct {
	*pubsub.Broker[Session]
	q db.Querier
}
func (s *service) Create(ctx context.Context, title string) (Session, error)
func (s *service) CreateTaskSession(ctx context.Context, toolCallID, parentSessionID, title string) (Session, error)
func (s *service) CreateTitleSession(ctx context.Context, parentSessionID string) (Session, error)
func (s *service) Delete(ctx context.Context, id string) error
func (s *service) Get(ctx context.Context, id string) (Session, error)
func (s *service) Save(ctx context.Context, session Session) (Session, error)
func (s *service) List(ctx context.Context) ([]Session, error)
func (s service) fromDBItem(item db.Session) Session
func NewService(q db.Querier) Service
</file>

<file path="internal/tui/components/dialog/arguments.go">
package dialog
import (
	"fmt"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/textinput"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/textinput"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type argumentsDialogKeyMap struct {
	Enter  key.Binding
	Escape key.Binding
}
func (k argumentsDialogKeyMap) ShortHelp() []key.Binding
func (k argumentsDialogKeyMap) FullHelp() [][]key.Binding
type ShowMultiArgumentsDialogMsg struct {
	CommandID string
	Content   string
	ArgNames  []string
}
type CloseMultiArgumentsDialogMsg struct {
	Submit    bool
	CommandID string
	Content   string
	Args      map[string]string
}
type MultiArgumentsDialogCmp struct {
	width, height int
	inputs        []textinput.Model
	focusIndex    int
	keys          argumentsDialogKeyMap
	commandID     string
	content       string
	argNames      []string
}
func NewMultiArgumentsDialogCmp(commandID, content string, argNames []string) MultiArgumentsDialogCmp
⋮----
// Only focus the first input initially
⋮----
// Init implements tea.Model.
func (m MultiArgumentsDialogCmp) Init() tea.Cmd
⋮----
// Make sure only the first input is focused
⋮----
// Update implements tea.Model.
func (m MultiArgumentsDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
var cmd tea.Cmd
⋮----
func (m MultiArgumentsDialogCmp) View() string
func (m *MultiArgumentsDialogCmp) SetSize(width, height int)
func (m MultiArgumentsDialogCmp) Bindings() []key.Binding
</file>

<file path="internal/tui/components/dialog/custom_commands.go">
package dialog
import (
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"os"
"path/filepath"
"regexp"
"strings"
tea "github.com/charmbracelet/bubbletea"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
const (
	UserCommandPrefix    = "user:"
	ProjectCommandPrefix = "project:"
)
var namedArgPattern = regexp.MustCompile(`\$([A-Z][A-Z0-9_]*)`)
func LoadCustomCommands() ([]Command, error)
⋮----
var commands []Command
⋮----
// Default to ~/.config if XDG_CONFIG_HOME is not set
⋮----
func loadCommandsFromDir(commandsDir string, prefix string) ([]Command, error)
type CommandRunCustomMsg struct {
	Content string
	Args    map[string]string
}
</file>

<file path="internal/tui/components/dialog/quit.go">
package dialog
import (
	"strings"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"strings"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
const question = "Are you sure you want to quit?"
type CloseQuitMsg struct{}
type QuitDialog interface {
	tea.Model
	layout.Bindings
}
type quitDialogCmp struct {
	selectedNo bool
}
type helpMapping struct {
	LeftRight  key.Binding
	EnterSpace key.Binding
	Yes        key.Binding
	No         key.Binding
	Tab        key.Binding
}
var helpKeys = helpMapping{
	LeftRight: key.NewBinding(
		key.WithKeys("left", "right"),
		key.WithHelp("←/→", "switch options"),
	),
	EnterSpace: key.NewBinding(
		key.WithKeys("enter", " "),
		key.WithHelp("enter/space", "confirm"),
	),
	Yes: key.NewBinding(
		key.WithKeys("y", "Y"),
		key.WithHelp("y/Y", "yes"),
	),
	No: key.NewBinding(
		key.WithKeys("n", "N"),
		key.WithHelp("n/N", "no"),
	),
	Tab: key.NewBinding(
		key.WithKeys("tab"),
		key.WithHelp("tab", "switch options"),
	),
}
func (q *quitDialogCmp) Init() tea.Cmd
func (q *quitDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (q *quitDialogCmp) View() string
func (q *quitDialogCmp) BindingKeys() []key.Binding
func NewQuitCmp() QuitDialog
</file>

<file path="internal/tui/components/logs/details.go">
package logs
import (
	"fmt"
	"strings"
	"time"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"fmt"
"strings"
"time"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/viewport"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type DetailComponent interface {
	tea.Model
	layout.Sizeable
	layout.Bindings
}
type detailCmp struct {
	width, height int
	currentLog    logging.LogMessage
	viewport      viewport.Model
}
func (i *detailCmp) Init() tea.Cmd
func (i *detailCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (i *detailCmp) updateContent()
⋮----
var content strings.Builder
⋮----
func getLevelStyle(level string) lipgloss.Style
func (i *detailCmp) View() string
func (i *detailCmp) GetSize() (int, int)
func (i *detailCmp) SetSize(width int, height int) tea.Cmd
func (i *detailCmp) BindingKeys() []key.Binding
func NewLogsDetails() DetailComponent
</file>

<file path="internal/tui/components/logs/table.go">
package logs
import (
	"encoding/json"
	"slices"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/table"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"encoding/json"
"slices"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/table"
tea "github.com/charmbracelet/bubbletea"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type TableComponent interface {
	tea.Model
	layout.Sizeable
	layout.Bindings
}
type tableCmp struct {
	table table.Model
}
type selectedLogMsg logging.LogMessage
func (i *tableCmp) Init() tea.Cmd
func (i *tableCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
var log logging.LogMessage
⋮----
func (i *tableCmp) View() string
func (i *tableCmp) GetSize() (int, int)
func (i *tableCmp) SetSize(width int, height int) tea.Cmd
func (i *tableCmp) BindingKeys() []key.Binding
func (i *tableCmp) setRows()
func NewLogsTable() TableComponent
</file>

<file path="internal/tui/layout/container.go">
package layout
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type Container interface {
	tea.Model
	Sizeable
	Bindings
}
type container struct {
	width  int
	height int
	content tea.Model
	paddingTop    int
	paddingRight  int
	paddingBottom int
	paddingLeft   int
	borderTop    bool
	borderRight  bool
	borderBottom bool
	borderLeft   bool
	borderStyle  lipgloss.Border
}
func (c *container) Init() tea.Cmd
func (c *container) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (c *container) View() string
func (c *container) SetSize(width, height int) tea.Cmd
func (c *container) GetSize() (int, int)
func (c *container) BindingKeys() []key.Binding
type ContainerOption func(*container)
func NewContainer(content tea.Model, options ...ContainerOption) Container
func WithPadding(top, right, bottom, left int) ContainerOption
func WithPaddingAll(padding int) ContainerOption
func WithPaddingHorizontal(padding int) ContainerOption
func WithPaddingVertical(padding int) ContainerOption
func WithBorder(top, right, bottom, left bool) ContainerOption
func WithBorderAll() ContainerOption
func WithBorderHorizontal() ContainerOption
func WithBorderVertical() ContainerOption
func WithBorderStyle(style lipgloss.Border) ContainerOption
func WithRoundedBorder() ContainerOption
func WithThickBorder() ContainerOption
func WithDoubleBorder() ContainerOption
</file>

<file path="internal/tui/layout/split.go">
package layout
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type SplitPaneLayout interface {
	tea.Model
	Sizeable
	Bindings
	SetLeftPanel(panel Container) tea.Cmd
	SetRightPanel(panel Container) tea.Cmd
	SetBottomPanel(panel Container) tea.Cmd
	ClearLeftPanel() tea.Cmd
	ClearRightPanel() tea.Cmd
	ClearBottomPanel() tea.Cmd
}
type splitPaneLayout struct {
	width         int
	height        int
	ratio         float64
	verticalRatio float64
	rightPanel  Container
	leftPanel   Container
	bottomPanel Container
}
type SplitPaneOption func(*splitPaneLayout)
func (s *splitPaneLayout) Init() tea.Cmd
⋮----
var cmds []tea.Cmd
⋮----
func (s *splitPaneLayout) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (s *splitPaneLayout) View() string
⋮----
var topSection string
⋮----
var finalView string
⋮----
func (s *splitPaneLayout) SetSize(width, height int) tea.Cmd
⋮----
var topHeight, bottomHeight int
⋮----
var leftWidth, rightWidth int
⋮----
func (s *splitPaneLayout) GetSize() (int, int)
func (s *splitPaneLayout) SetLeftPanel(panel Container) tea.Cmd
func (s *splitPaneLayout) SetRightPanel(panel Container) tea.Cmd
func (s *splitPaneLayout) SetBottomPanel(panel Container) tea.Cmd
func (s *splitPaneLayout) ClearLeftPanel() tea.Cmd
func (s *splitPaneLayout) ClearRightPanel() tea.Cmd
func (s *splitPaneLayout) ClearBottomPanel() tea.Cmd
func (s *splitPaneLayout) BindingKeys() []key.Binding
func NewSplitPane(options ...SplitPaneOption) SplitPaneLayout
func WithLeftPanel(panel Container) SplitPaneOption
func WithRightPanel(panel Container) SplitPaneOption
func WithRatio(ratio float64) SplitPaneOption
func WithBottomPanel(panel Container) SplitPaneOption
func WithVerticalRatio(ratio float64) SplitPaneOption
</file>

<file path="internal/tui/page/logs.go">
package page
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/components/logs"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/components/logs"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
⋮----
var LogsPage PageID = "logs"
type LogPage interface {
	tea.Model
	layout.Sizeable
	layout.Bindings
}
type logsPage struct {
	width, height int
	table         layout.Container
	details       layout.Container
}
func (p *logsPage) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
func (p *logsPage) View() string
func (p *logsPage) BindingKeys() []key.Binding
func (p *logsPage) GetSize() (int, int)
func (p *logsPage) SetSize(width int, height int) tea.Cmd
func (p *logsPage) Init() tea.Cmd
func NewLogsPage() LogPage
</file>

<file path="internal/tui/styles/styles.go">
package styles
import (
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
var (
	ImageBakcground = "#212121"
)
func BaseStyle() lipgloss.Style
func Regular() lipgloss.Style
func Bold() lipgloss.Style
func Padded() lipgloss.Style
func Border() lipgloss.Style
func ThickBorder() lipgloss.Style
func DoubleBorder() lipgloss.Style
func FocusedBorder() lipgloss.Style
func DimBorder() lipgloss.Style
func PrimaryColor() lipgloss.AdaptiveColor
func SecondaryColor() lipgloss.AdaptiveColor
func AccentColor() lipgloss.AdaptiveColor
func ErrorColor() lipgloss.AdaptiveColor
func WarningColor() lipgloss.AdaptiveColor
func SuccessColor() lipgloss.AdaptiveColor
func InfoColor() lipgloss.AdaptiveColor
func TextColor() lipgloss.AdaptiveColor
func TextMutedColor() lipgloss.AdaptiveColor
func TextEmphasizedColor() lipgloss.AdaptiveColor
func BackgroundColor() lipgloss.AdaptiveColor
func BackgroundSecondaryColor() lipgloss.AdaptiveColor
func BackgroundDarkerColor() lipgloss.AdaptiveColor
func BorderNormalColor() lipgloss.AdaptiveColor
func BorderFocusedColor() lipgloss.AdaptiveColor
func BorderDimColor() lipgloss.AdaptiveColor
</file>

<file path="internal/version/version.go">
package version
import "runtime/debug"
var Version = "unknown"
func init()
</file>

<file path=".github/workflows/build.yml">
name: build
on:
  workflow_dispatch:
  push:
    branches:
      - main
concurrency: ${{ github.workflow }}-${{ github.ref }}
permissions:
  contents: write
  packages: write
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - run: git fetch --force --tags
      - uses: actions/setup-go@v5
        with:
          go-version: ">=1.23.2"
          cache: true
          cache-dependency-path: go.sum
      - run: go mod download
      - uses: goreleaser/goreleaser-action@v6
        with:
          distribution: goreleaser
          version: latest
          args: build --snapshot --clean
</file>

<file path=".github/workflows/release.yml">
name: release
on:
  workflow_dispatch:
  push:
    tags:
      - "*"
concurrency: ${{ github.workflow }}-${{ github.ref }}
permissions:
  contents: write
  packages: write
jobs:
  goreleaser:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - run: git fetch --force --tags
      - uses: actions/setup-go@v5
        with:
          go-version: ">=1.23.2"
          cache: true
          cache-dependency-path: go.sum
      - run: go mod download
      - uses: goreleaser/goreleaser-action@v6
        with:
          distribution: goreleaser
          version: latest
          args: release --clean
        env:
          GITHUB_TOKEN: ${{ secrets.HOMEBREW_GITHUB_TOKEN }}
          AUR_KEY: ${{ secrets.AUR_KEY }}
</file>

<file path="internal/db/connect.go">
package db
import (
	"database/sql"
	"fmt"
	"os"
	"path/filepath"
	_ "github.com/ncruces/go-sqlite3/driver"
	_ "github.com/ncruces/go-sqlite3/embed"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/pressly/goose/v3"
)
⋮----
"database/sql"
"fmt"
"os"
"path/filepath"
_ "github.com/ncruces/go-sqlite3/driver"
_ "github.com/ncruces/go-sqlite3/embed"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/pressly/goose/v3"
⋮----
func Connect() (*sql.DB, error)
</file>

<file path="internal/diff/diff.go">
package diff
import (
	"bytes"
	"fmt"
	"io"
	"regexp"
	"strconv"
	"strings"
	"github.com/alecthomas/chroma/v2"
	"github.com/alecthomas/chroma/v2/formatters"
	"github.com/alecthomas/chroma/v2/lexers"
	"github.com/alecthomas/chroma/v2/styles"
	"github.com/aymanbagabas/go-udiff"
	"github.com/charmbracelet/lipgloss"
	"github.com/charmbracelet/x/ansi"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/sergi/go-diff/diffmatchpatch"
)
⋮----
"bytes"
"fmt"
"io"
"regexp"
"strconv"
"strings"
"github.com/alecthomas/chroma/v2"
"github.com/alecthomas/chroma/v2/formatters"
"github.com/alecthomas/chroma/v2/lexers"
"github.com/alecthomas/chroma/v2/styles"
"github.com/aymanbagabas/go-udiff"
"github.com/charmbracelet/lipgloss"
"github.com/charmbracelet/x/ansi"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/sergi/go-diff/diffmatchpatch"
⋮----
type LineType int
const (
	LineContext LineType = iota
	LineAdded
	LineRemoved
)
type Segment struct {
	Start int
	End   int
	Type  LineType
	Text  string
}
type DiffLine struct {
	OldLineNo int
	NewLineNo int
	Kind      LineType
	Content   string
	Segments  []Segment
}
type Hunk struct {
	Header string
	Lines  []DiffLine
}
type DiffResult struct {
	OldFile string
	NewFile string
	Hunks   []Hunk
}
type linePair struct {
	left  *DiffLine
	right *DiffLine
}
type ParseConfig struct {
	ContextSize int
}
type ParseOption func(*ParseConfig)
func WithContextSize(size int) ParseOption
type SideBySideConfig struct {
	TotalWidth int
}
type SideBySideOption func(*SideBySideConfig)
func NewSideBySideConfig(opts ...SideBySideOption) SideBySideConfig
func WithTotalWidth(width int) SideBySideOption
func ParseUnifiedDiff(diff string) (DiffResult, error)
⋮----
var result DiffResult
var currentHunk *Hunk
⋮----
var oldLine, newLine int
⋮----
// Add the last hunk if there is one
⋮----
// HighlightIntralineChanges updates lines in a hunk to show character-level differences
func HighlightIntralineChanges(h *Hunk)
⋮----
var updated []DiffLine
⋮----
// Look for removed line followed by added line
⋮----
// Find character-level differences
⋮----
// Context text, no highlighting needed
⋮----
i++ // Skip the next line as we've already processed it
⋮----
// pairLines converts a flat list of diff lines to pairs for side-by-side display
func pairLines(lines []DiffLine) []linePair
⋮----
var pairs []linePair
⋮----
// Check if the next line is an addition, if so pair them
⋮----
// -------------------------------------------------------------------------
// Syntax Highlighting
⋮----
// SyntaxHighlight applies syntax highlighting to text based on file extension
func SyntaxHighlight(w io.Writer, source, fileName, formatter string, bg lipgloss.TerminalColor) error
⋮----
// Determine the language lexer to use
⋮----
// Get the formatter
⋮----
// Dynamic theme based on current theme values
⋮----
getColor(t.Background()), // Background
getColor(t.Text()),       // Text
getColor(t.Text()),       // Other
getColor(t.Error()),      // Error
getColor(t.SyntaxKeyword()), // Keyword
getColor(t.SyntaxKeyword()), // KeywordConstant
getColor(t.SyntaxKeyword()), // KeywordDeclaration
getColor(t.SyntaxKeyword()), // KeywordNamespace
getColor(t.SyntaxKeyword()), // KeywordPseudo
getColor(t.SyntaxKeyword()), // KeywordReserved
getColor(t.SyntaxType()),    // KeywordType
getColor(t.Text()),           // Name
getColor(t.SyntaxVariable()), // NameAttribute
getColor(t.SyntaxType()),     // NameBuiltin
getColor(t.SyntaxVariable()), // NameBuiltinPseudo
getColor(t.SyntaxType()),     // NameClass
getColor(t.SyntaxVariable()), // NameConstant
getColor(t.SyntaxFunction()), // NameDecorator
getColor(t.SyntaxVariable()), // NameEntity
getColor(t.SyntaxType()),     // NameException
getColor(t.SyntaxFunction()), // NameFunction
getColor(t.Text()),           // NameLabel
getColor(t.SyntaxType()),     // NameNamespace
getColor(t.SyntaxVariable()), // NameOther
getColor(t.SyntaxKeyword()),  // NameTag
getColor(t.SyntaxVariable()), // NameVariable
getColor(t.SyntaxVariable()), // NameVariableClass
getColor(t.SyntaxVariable()), // NameVariableGlobal
getColor(t.SyntaxVariable()), // NameVariableInstance
getColor(t.SyntaxString()), // Literal
getColor(t.SyntaxString()), // LiteralDate
getColor(t.SyntaxString()), // LiteralString
getColor(t.SyntaxString()), // LiteralStringBacktick
getColor(t.SyntaxString()), // LiteralStringChar
getColor(t.SyntaxString()), // LiteralStringDoc
getColor(t.SyntaxString()), // LiteralStringDouble
getColor(t.SyntaxString()), // LiteralStringEscape
getColor(t.SyntaxString()), // LiteralStringHeredoc
getColor(t.SyntaxString()), // LiteralStringInterpol
getColor(t.SyntaxString()), // LiteralStringOther
getColor(t.SyntaxString()), // LiteralStringRegex
getColor(t.SyntaxString()), // LiteralStringSingle
getColor(t.SyntaxString()), // LiteralStringSymbol
getColor(t.SyntaxNumber()), // LiteralNumber
getColor(t.SyntaxNumber()), // LiteralNumberBin
getColor(t.SyntaxNumber()), // LiteralNumberFloat
getColor(t.SyntaxNumber()), // LiteralNumberHex
getColor(t.SyntaxNumber()), // LiteralNumberInteger
getColor(t.SyntaxNumber()), // LiteralNumberIntegerLong
getColor(t.SyntaxNumber()), // LiteralNumberOct
getColor(t.SyntaxOperator()),    // Operator
getColor(t.SyntaxKeyword()),     // OperatorWord
getColor(t.SyntaxPunctuation()), // Punctuation
getColor(t.SyntaxComment()), // Comment
getColor(t.SyntaxComment()), // CommentHashbang
getColor(t.SyntaxComment()), // CommentMultiline
getColor(t.SyntaxComment()), // CommentSingle
getColor(t.SyntaxComment()), // CommentSpecial
getColor(t.SyntaxKeyword()), // CommentPreproc
getColor(t.Text()),      // Generic
getColor(t.Error()),     // GenericDeleted
getColor(t.Text()),      // GenericEmph
getColor(t.Error()),     // GenericError
getColor(t.Text()),      // GenericHeading
getColor(t.Success()),   // GenericInserted
getColor(t.TextMuted()), // GenericOutput
getColor(t.Text()),      // GenericPrompt
getColor(t.Text()),      // GenericStrong
getColor(t.Text()),      // GenericSubheading
getColor(t.Error()),     // GenericTraceback
getColor(t.Text()),      // TextWhitespace
⋮----
// Modify the style to use the provided background
⋮----
// Tokenize and format
⋮----
// getColor returns the appropriate hex color string based on terminal background
func getColor(adaptiveColor lipgloss.AdaptiveColor) string
// highlightLine applies syntax highlighting to a single line
func highlightLine(fileName string, line string, bg lipgloss.TerminalColor) string
⋮----
var buf bytes.Buffer
⋮----
// createStyles generates the lipgloss styles needed for rendering diffs
func createStyles(t theme.Theme) (removedLineStyle, addedLineStyle, contextLineStyle, lineNumberStyle lipgloss.Style)
⋮----
// Rendering Functions
⋮----
func lipglossToHex(color lipgloss.Color) string
⋮----
// Scale uint32 values (0-65535) to uint8 (0-255).
⋮----
// applyHighlighting applies intra-line highlighting to a piece of text
func applyHighlighting(content string, segments []Segment, segmentType LineType, highlightBg lipgloss.AdaptiveColor) string
⋮----
// Find all ANSI sequences in the content
⋮----
var sb strings.Builder
⋮----
func renderLeftColumn(fileName string, dl *DiffLine, colWidth int) string
⋮----
// Determine line style based on line type
var marker string
var bgStyle lipgloss.Style
⋮----
// Format line number
⋮----
func renderRightColumn(fileName string, dl *DiffLine, colWidth int) string
func RenderSideBySideHunk(fileName string, h Hunk, opts ...SideBySideOption) string
func FormatDiff(diffText string, opts ...SideBySideOption) (string, error)
// GenerateDiff creates a unified diff from two file contents
func GenerateDiff(beforeContent, afterContent, fileName string) (string, int, int)
⋮----
// remove the cwd prefix and ensure consistent path format
// this prevents issues with absolute paths in different environments
⋮----
var (
		unified   = udiff.Unified("a/"+fileName, "b/"+fileName, beforeContent, afterContent)
</file>

<file path="internal/llm/models/anthropic.go">
package models
const (
	ProviderAnthropic ModelProvider = "anthropic"
	Claude35Sonnet ModelID = "claude-3.5-sonnet"
	Claude3Haiku   ModelID = "claude-3-haiku"
	Claude37Sonnet ModelID = "claude-3.7-sonnet"
	Claude35Haiku  ModelID = "claude-3.5-haiku"
	Claude3Opus    ModelID = "claude-3-opus"
	Claude4Opus    ModelID = "claude-4-opus"
	Claude4Sonnet  ModelID = "claude-4-sonnet"
)
var AnthropicModels = map[ModelID]Model{
	Claude35Sonnet: {
		ID:                  Claude35Sonnet,
		Name:                "Claude 3.5 Sonnet",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-3-5-sonnet-latest",
		CostPer1MIn:         3.0,
		CostPer1MInCached:   3.75,
		CostPer1MOutCached:  0.30,
		CostPer1MOut:        15.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    5000,
		SupportsAttachments: true,
	},
	Claude3Haiku: {
		ID:                  Claude3Haiku,
		Name:                "Claude 3 Haiku",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-3-haiku-20240307",
		CostPer1MIn:         0.25,
		CostPer1MInCached:   0.30,
		CostPer1MOutCached:  0.03,
		CostPer1MOut:        1.25,
		ContextWindow:       200000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	Claude37Sonnet: {
		ID:                  Claude37Sonnet,
		Name:                "Claude 3.7 Sonnet",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-3-7-sonnet-latest",
		CostPer1MIn:         3.0,
		CostPer1MInCached:   3.75,
		CostPer1MOutCached:  0.30,
		CostPer1MOut:        15.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	Claude35Haiku: {
		ID:                  Claude35Haiku,
		Name:                "Claude 3.5 Haiku",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-3-5-haiku-latest",
		CostPer1MIn:         0.80,
		CostPer1MInCached:   1.0,
		CostPer1MOutCached:  0.08,
		CostPer1MOut:        4.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	Claude3Opus: {
		ID:                  Claude3Opus,
		Name:                "Claude 3 Opus",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-3-opus-latest",
		CostPer1MIn:         15.0,
		CostPer1MInCached:   18.75,
		CostPer1MOutCached:  1.50,
		CostPer1MOut:        75.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
	Claude4Sonnet: {
		ID:                  Claude4Sonnet,
		Name:                "Claude 4 Sonnet",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-sonnet-4-20250514",
		CostPer1MIn:         3.0,
		CostPer1MInCached:   3.75,
		CostPer1MOutCached:  0.30,
		CostPer1MOut:        15.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    50000,
		CanReason:           true,
		SupportsAttachments: true,
	},
	Claude4Opus: {
		ID:                  Claude4Opus,
		Name:                "Claude 4 Opus",
		Provider:            ProviderAnthropic,
		APIModel:            "claude-opus-4-20250514",
		CostPer1MIn:         15.0,
		CostPer1MInCached:   18.75,
		CostPer1MOutCached:  1.50,
		CostPer1MOut:        75.0,
		ContextWindow:       200000,
		DefaultMaxTokens:    4096,
		SupportsAttachments: true,
	},
}
</file>

<file path="internal/llm/models/local.go">
package models
import (
	"cmp"
	"encoding/json"
	"net/http"
	"net/url"
	"os"
	"regexp"
	"strings"
	"unicode"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/spf13/viper"
)
⋮----
"cmp"
"encoding/json"
"net/http"
"net/url"
"os"
"regexp"
"strings"
"unicode"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/spf13/viper"
⋮----
const (
	ProviderLocal ModelProvider = "local"
	localModelsPath        = "v1/models"
	lmStudioBetaModelsPath = "api/v0/models"
)
func init()
type localModelList struct {
	Data []localModel `json:"data"`
}
type localModel struct {
	ID                  string `json:"id"`
	Object              string `json:"object"`
	Type                string `json:"type"`
	Publisher           string `json:"publisher"`
	Arch                string `json:"arch"`
	CompatibilityType   string `json:"compatibility_type"`
	Quantization        string `json:"quantization"`
	State               string `json:"state"`
	MaxContextLength    int64  `json:"max_context_length"`
	LoadedContextLength int64  `json:"loaded_context_length"`
}
func listLocalModels(modelsEndpoint string) []localModel
⋮----
var modelList localModelList
⋮----
var supportedModels []localModel
⋮----
func loadLocalModels(models []localModel)
func convertLocalModel(model localModel) Model
var modelInfoRegex = regexp.MustCompile(`(?i)^([a-z0-9]+)(?:[-_]?([rv]?\d[\.\d]*))?(?:[-_]?([a-z]+))?.*`)
func friendlyModelName(modelID string) string
⋮----
var parts []string
</file>

<file path="internal/llm/prompt/title.go">
package prompt
import "github.com/opencode-ai/opencode/internal/llm/models"
func TitlePrompt(_ models.ModelProvider) string
</file>

<file path="internal/llm/tools/grep.go">
package tools
import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/fileutil"
)
⋮----
"bufio"
"context"
"encoding/json"
"fmt"
"os"
"os/exec"
"path/filepath"
"regexp"
"sort"
"strconv"
"strings"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/fileutil"
⋮----
type GrepParams struct {
	Pattern     string `json:"pattern"`
	Path        string `json:"path"`
	Include     string `json:"include"`
	LiteralText bool   `json:"literal_text"`
}
type grepMatch struct {
	path     string
	modTime  time.Time
	lineNum  int
	lineText string
}
type GrepResponseMetadata struct {
	NumberOfMatches int  `json:"number_of_matches"`
	Truncated       bool `json:"truncated"`
}
type grepTool struct{}
const (
	GrepToolName    = "grep"
	grepDescription = `Fast content search tool that finds files containing specific text or patterns, returning matching file paths sorted by modification time (newest first).
func NewGrepTool() BaseTool
func (g *grepTool) Info() ToolInfo
func escapeRegexPattern(pattern string) string
func (g *grepTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params GrepParams
⋮----
var output string
⋮----
func searchFiles(pattern, rootPath, include string, limit int) ([]grepMatch, bool, error)
func searchWithRipgrep(pattern, path, include string) ([]grepMatch, error)
⋮----
// Parse ripgrep output format: file:line:content
⋮----
continue // Skip files we can't access
⋮----
func searchFilesWithRegex(pattern, rootPath, include string) ([]grepMatch, error)
⋮----
var includePattern *regexp.Regexp
⋮----
func fileContainsPattern(filePath string, pattern *regexp.Regexp) (bool, int, string, error)
func globToRegex(glob string) string
</file>

<file path="internal/lsp/watcher/watcher.go">
package watcher
import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
	"github.com/bmatcuk/doublestar/v4"
	"github.com/fsnotify/fsnotify"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
)
⋮----
"context"
"fmt"
"os"
"path/filepath"
"strings"
"sync"
"time"
"github.com/bmatcuk/doublestar/v4"
"github.com/fsnotify/fsnotify"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
⋮----
type WorkspaceWatcher struct {
	client        *lsp.Client
	workspacePath string
	debounceTime time.Duration
	debounceMap  map[string]*time.Timer
	debounceMu   sync.Mutex
	registrations  []protocol.FileSystemWatcher
	registrationMu sync.RWMutex
}
func NewWorkspaceWatcher(client *lsp.Client) *WorkspaceWatcher
func (w *WorkspaceWatcher) AddRegistrations(ctx context.Context, id string, watchers []protocol.FileSystemWatcher)
func (w *WorkspaceWatcher) openHighPriorityFiles(ctx context.Context, serverName string) int
⋮----
var patterns []string
⋮----
func (w *WorkspaceWatcher) WatchWorkspace(ctx context.Context, workspacePath string)
func (w *WorkspaceWatcher) isPathWatched(path string) (bool, protocol.WatchKind)
func matchesGlob(pattern, path string) bool
func matchesSimpleGlob(pattern, path string) bool
⋮----
// For patterns like "**
</file>

<file path="internal/tui/components/chat/chat.go">
package chat
import (
	"fmt"
	"sort"
	"github.com/charmbracelet/lipgloss"
	"github.com/charmbracelet/x/ansi"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/version"
)
⋮----
"fmt"
"sort"
"github.com/charmbracelet/lipgloss"
"github.com/charmbracelet/x/ansi"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/version"
⋮----
type SendMsg struct {
	Text        string
	Attachments []message.Attachment
}
⋮----
type SessionClearedMsg struct{}
type EditorFocusMsg bool
func header(width int) string
func requestInfo(width int) string
⋮----
// Get current request info
⋮----
// Title
⋮----
func lspsConfigured(width int) string
⋮----
var lspNames []string
⋮----
var lspViews []string
⋮----
func logo(width int) string
func repo(width int) string
func cwd(width int) string
</file>

<file path="internal/tui/components/chat/sidebar.go">
package chat
import (
	"context"
	"fmt"
	"sort"
	"strings"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"context"
"fmt"
"sort"
"strings"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type sidebarCmp struct {
	width, height int
	session       session.Session
	history       history.Service
	modFiles      map[string]struct {
		additions int
		removals  int
	}
func (m *sidebarCmp) Init() tea.Cmd
func (m *sidebarCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (m *sidebarCmp) View() string
func (m *sidebarCmp) sessionSection() string
func (m *sidebarCmp) modifiedFile(filePath string, additions, removals int) string
func (m *sidebarCmp) modifiedFiles() string
⋮----
var paths []string
⋮----
var fileViews []string
⋮----
func (m *sidebarCmp) SetSize(width, height int) tea.Cmd
func (m *sidebarCmp) GetSize() (int, int)
func NewSidebarCmp(session session.Session, history history.Service) tea.Model
func (m *sidebarCmp) loadModifiedFiles(ctx context.Context)
⋮----
// Get all latest files for this session
⋮----
// Get all files for this session (to find initial versions)
⋮----
// Clear the existing map to rebuild it
⋮----
// Process each latest file
⋮----
// Skip if this is the initial version (no changes to show)
⋮----
// Find the initial version for this specific file
var initialVersion history.File
⋮----
// Skip if we can't find the initial version
⋮----
// Calculate diff between initial and latest version
⋮----
// Only add to modified files if there are changes
⋮----
// Remove working directory prefix from file path
⋮----
func (m *sidebarCmp) processFileChanges(ctx context.Context, file history.File)
⋮----
// Skip if this is the initial version (no changes to show)
⋮----
// Find the initial version for this file
⋮----
// Skip if content hasn't changed
⋮----
// If this file was previously modified but now matches the initial version,
// remove it from the modified files list
⋮----
// Calculate diff between initial and latest version
⋮----
// Only add to modified files if there are changes
⋮----
// If no changes, remove from modified files
⋮----
// Helper function to find the initial version of a file
func (m *sidebarCmp) findInitialVersion(ctx context.Context, path string) (history.File, error)
⋮----
// Get all versions of this file for the session
⋮----
// Find the initial version
⋮----
func getDisplayPath(path string) string
</file>

<file path="internal/tui/components/dialog/filepicker.go">
package dialog
import (
	"fmt"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"time"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/textinput"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/tui/image"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"net/http"
"os"
"path/filepath"
"sort"
"strings"
"time"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/textinput"
"github.com/charmbracelet/bubbles/viewport"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/tui/image"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
const (
	maxAttachmentSize = int64(5 * 1024 * 1024)
type FilePrickerKeyMap struct {
	Enter          key.Binding
	Down           key.Binding
	Up             key.Binding
	Forward        key.Binding
	Backward       key.Binding
	OpenFilePicker key.Binding
	Esc            key.Binding
	InsertCWD      key.Binding
}
var filePickerKeyMap = FilePrickerKeyMap{
	Enter: key.NewBinding(
		key.WithKeys("enter"),
		key.WithHelp("enter", "select file/enter directory"),
	),
	Down: key.NewBinding(
		key.WithKeys("j", downArrow),
		key.WithHelp("↓/j", "down"),
	),
	Up: key.NewBinding(
		key.WithKeys("k", upArrow),
		key.WithHelp("↑/k", "up"),
	),
	Forward: key.NewBinding(
		key.WithKeys("l"),
		key.WithHelp("l", "enter directory"),
	),
	Backward: key.NewBinding(
		key.WithKeys("h", "backspace"),
		key.WithHelp("h/backspace", "go back"),
	),
	OpenFilePicker: key.NewBinding(
		key.WithKeys("ctrl+f"),
		key.WithHelp("ctrl+f", "open file picker"),
	),
	Esc: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "close/exit"),
	),
	InsertCWD: key.NewBinding(
		key.WithKeys("i"),
		key.WithHelp("i", "manual path input"),
	),
}
type filepickerCmp struct {
	basePath       string
	width          int
	height         int
	cursor         int
	err            error
	cursorChain    stack
	viewport       viewport.Model
	dirs           []os.DirEntry
	cwdDetails     *DirNode
	selectedFile   string
	cwd            textinput.Model
	ShowFilePicker bool
	app            *app.App
}
type DirNode struct {
	parent    *DirNode
	child     *DirNode
	directory string
}
type stack []int
func (s stack) Push(v int) stack
func (s stack) Pop() (stack, int)
type AttachmentAddedMsg struct {
	Attachment message.Attachment
}
func (f *filepickerCmp) Init() tea.Cmd
func (f *filepickerCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmd tea.Cmd
⋮----
var path string
var isPathDir bool
⋮----
func (f *filepickerCmp) addAttachmentToMessage() (tea.Model, tea.Cmd)
func (f *filepickerCmp) View() string
⋮----
const maxVisibleDirs = 20
const maxWidth = 80
⋮----
if len(file.Name()) > adjustedWidth-4 { // Account for padding
⋮----
// No need to reassign filename if it's not changing
⋮----
// Pad to always show exactly 21 lines
⋮----
var insertExitText string
⋮----
type FilepickerCmp interface {
	tea.Model
	ToggleFilepicker(showFilepicker bool)
	IsCWDFocused() bool
}
func (f *filepickerCmp) ToggleFilepicker(showFilepicker bool)
func (f *filepickerCmp) IsCWDFocused() bool
func NewFilepickerCmp(app *app.App) FilepickerCmp
func (f *filepickerCmp) getCurrentFileBelowCursor()
func readDir(path string, showHidden bool) []os.DirEntry
⋮----
var sanitizedDirEntries []os.DirEntry
⋮----
func IsHidden(file string) (bool, error)
func isExtSupported(path string) bool
</file>

<file path="internal/tui/components/dialog/models.go">
package dialog
import (
	"fmt"
	"slices"
	"strings"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"slices"
"strings"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
const (
	numVisibleModels = 10
	maxDialogWidth   = 40
)
type ModelSelectedMsg struct {
	Model models.Model
}
type CloseModelDialogMsg struct{}
type ModelDialog interface {
	tea.Model
	layout.Bindings
}
type modelDialogCmp struct {
	models             []models.Model
	provider           models.ModelProvider
	availableProviders []models.ModelProvider
	selectedIdx     int
	width           int
	height          int
	scrollOffset    int
	hScrollOffset   int
	hScrollPossible bool
}
type modelKeyMap struct {
	Up     key.Binding
	Down   key.Binding
	Left   key.Binding
	Right  key.Binding
	Enter  key.Binding
	Escape key.Binding
	J      key.Binding
	K      key.Binding
	H      key.Binding
	L      key.Binding
}
var modelKeys = modelKeyMap{
	Up: key.NewBinding(
		key.WithKeys("up"),
		key.WithHelp("↑", "previous model"),
	),
	Down: key.NewBinding(
		key.WithKeys("down"),
		key.WithHelp("↓", "next model"),
	),
	Left: key.NewBinding(
		key.WithKeys("left"),
		key.WithHelp("←", "scroll left"),
	),
	Right: key.NewBinding(
		key.WithKeys("right"),
		key.WithHelp("→", "scroll right"),
	),
	Enter: key.NewBinding(
		key.WithKeys("enter"),
		key.WithHelp("enter", "select model"),
	),
	Escape: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "close"),
	),
	J: key.NewBinding(
		key.WithKeys("j"),
		key.WithHelp("j", "next model"),
	),
	K: key.NewBinding(
		key.WithKeys("k"),
		key.WithHelp("k", "previous model"),
	),
	H: key.NewBinding(
		key.WithKeys("h"),
		key.WithHelp("h", "scroll left"),
	),
	L: key.NewBinding(
		key.WithKeys("l"),
		key.WithHelp("l", "scroll right"),
	),
}
func (m *modelDialogCmp) Init() tea.Cmd
func (m *modelDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (m *modelDialogCmp) moveSelectionUp()
func (m *modelDialogCmp) moveSelectionDown()
func (m *modelDialogCmp) switchProvider(offset int)
func (m *modelDialogCmp) View() string
func (m *modelDialogCmp) getScrollIndicators(maxWidth int) string
⋮----
var indicator string
⋮----
func (m *modelDialogCmp) BindingKeys() []key.Binding
func (m *modelDialogCmp) setupModels()
func GetSelectedModel(cfg *config.Config) models.Model
func getEnabledProviders(cfg *config.Config) []models.ModelProvider
⋮----
var providers []models.ModelProvider
⋮----
func findProviderIndex(providers []models.ModelProvider, provider models.ModelProvider) int
func (m *modelDialogCmp) setupModelsForProvider(provider models.ModelProvider)
func getModelsForProvider(provider models.ModelProvider) []models.Model
⋮----
var providerModels []models.Model
⋮----
func NewModelDialogCmp() ModelDialog
</file>

<file path="internal/tui/components/dialog/session.go">
package dialog
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type SessionSelectedMsg struct {
	Session session.Session
}
type CloseSessionDialogMsg struct{}
type SessionDialog interface {
	tea.Model
	layout.Bindings
	SetSessions(sessions []session.Session)
	SetSelectedSession(sessionID string)
}
type sessionDialogCmp struct {
	sessions          []session.Session
	selectedIdx       int
	width             int
	height            int
	selectedSessionID string
}
type sessionKeyMap struct {
	Up     key.Binding
	Down   key.Binding
	Enter  key.Binding
	Escape key.Binding
	J      key.Binding
	K      key.Binding
}
var sessionKeys = sessionKeyMap{
	Up: key.NewBinding(
		key.WithKeys("up"),
		key.WithHelp("↑", "previous session"),
	),
	Down: key.NewBinding(
		key.WithKeys("down"),
		key.WithHelp("↓", "next session"),
	),
	Enter: key.NewBinding(
		key.WithKeys("enter"),
		key.WithHelp("enter", "select session"),
	),
	Escape: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "close"),
	),
	J: key.NewBinding(
		key.WithKeys("j"),
		key.WithHelp("j", "next session"),
	),
	K: key.NewBinding(
		key.WithKeys("k"),
		key.WithHelp("k", "previous session"),
	),
}
func (s *sessionDialogCmp) Init() tea.Cmd
func (s *sessionDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (s *sessionDialogCmp) View() string
func (s *sessionDialogCmp) BindingKeys() []key.Binding
func (s *sessionDialogCmp) SetSessions(sessions []session.Session)
⋮----
// If we have a selected session ID, find its index
⋮----
// Default to first session if selected not found
⋮----
func (s *sessionDialogCmp) SetSelectedSession(sessionID string)
⋮----
// Update the selected index if sessions are already loaded
⋮----
// NewSessionDialogCmp creates a new session switching dialog
func NewSessionDialogCmp() SessionDialog
</file>

<file path="internal/tui/layout/overlay.go">
package layout
import (
	"strings"
	"github.com/charmbracelet/lipgloss"
	chAnsi "github.com/charmbracelet/x/ansi"
	"github.com/muesli/ansi"
	"github.com/muesli/reflow/truncate"
	"github.com/muesli/termenv"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"strings"
"github.com/charmbracelet/lipgloss"
chAnsi "github.com/charmbracelet/x/ansi"
"github.com/muesli/ansi"
"github.com/muesli/reflow/truncate"
"github.com/muesli/termenv"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
func getLines(s string) (lines []string, widest int)
func PlaceOverlay(
	x, y int,
	fg, bg string,
	shadow bool, opts ...WhitespaceOption,
) string
⋮----
var shadowbg string = ""
⋮----
var b strings.Builder
⋮----
func cutLeft(s string, cutWidth int) string
func max(a, b int) int
type whitespace struct {
	style termenv.Style
	chars string
}
func (w whitespace) render(width int) string
⋮----
// Cycle through runes and print them into the whitespace.
⋮----
// Fill any extra gaps white spaces. This might be necessary if any runes
// are more than one cell wide, which could leave a one-rune gap.
⋮----
type WhitespaceOption func(*whitespace)
</file>

<file path="internal/app/app.go">
package app
import (
	"context"
	"database/sql"
	"errors"
	"fmt"
	"maps"
	"sync"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/db"
	"github.com/opencode-ai/opencode/internal/format"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/llm/agent"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"context"
"database/sql"
"errors"
"fmt"
"maps"
"sync"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/db"
"github.com/opencode-ai/opencode/internal/format"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/llm/agent"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type App struct {
	Sessions    session.Service
	Messages    message.Service
	History     history.Service
	Permissions permission.Service
	CoderAgent agent.Service
	LSPClients map[string]*lsp.Client
	clientsMutex sync.RWMutex
	watcherCancelFuncs []context.CancelFunc
	cancelFuncsMutex   sync.Mutex
	watcherWG          sync.WaitGroup
}
func New(ctx context.Context, conn *sql.DB) (*App, error)
⋮----
var err error
⋮----
func (app *App) initTheme()
⋮----
return // Use default theme
⋮----
// Try to set the theme from config
⋮----
func (a *App) RunNonInteractive(ctx context.Context, prompt string, outputFormat string, quiet bool) error
⋮----
var spinner *format.Spinner
⋮----
const maxPromptLengthForTitle = 100
⋮----
var titleSuffix string
⋮----
func (app *App) Shutdown()
</file>

<file path="internal/llm/agent/mcp-tools.go">
package agent
import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/version"
	"github.com/mark3labs/mcp-go/client"
	"github.com/mark3labs/mcp-go/mcp"
)
⋮----
"context"
"encoding/json"
"fmt"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/version"
"github.com/mark3labs/mcp-go/client"
"github.com/mark3labs/mcp-go/mcp"
⋮----
type mcpTool struct {
	mcpName     string
	tool        mcp.Tool
	mcpConfig   config.MCPServer
	permissions permission.Service
}
type MCPClient interface {
	Initialize(
		ctx context.Context,
		request mcp.InitializeRequest,
	) (*mcp.InitializeResult, error)
	ListTools(ctx context.Context, request mcp.ListToolsRequest) (*mcp.ListToolsResult, error)
	CallTool(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error)
	Close() error
}
func (b *mcpTool) Info() tools.ToolInfo
func runTool(ctx context.Context, c MCPClient, toolName string, input string) (tools.ToolResponse, error)
⋮----
var args map[string]any
⋮----
func (b *mcpTool) Run(ctx context.Context, params tools.ToolCall) (tools.ToolResponse, error)
func NewMcpTool(name string, tool mcp.Tool, permissions permission.Service, mcpConfig config.MCPServer) tools.BaseTool
var mcpTools []tools.BaseTool
func getTools(ctx context.Context, name string, m config.MCPServer, permissions permission.Service, c MCPClient) []tools.BaseTool
⋮----
var stdioTools []tools.BaseTool
⋮----
func GetMcpTools(ctx context.Context, permissions permission.Service) []tools.BaseTool
</file>

<file path="internal/llm/tools/shell/shell.go">
package shell
import (
	"context"
	"errors"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"sync"
	"syscall"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
)
⋮----
"context"
"errors"
"fmt"
"os"
"os/exec"
"path/filepath"
"strings"
"sync"
"syscall"
"time"
"github.com/opencode-ai/opencode/internal/config"
⋮----
type PersistentShell struct {
	cmd          *exec.Cmd
	stdin        *os.File
	isAlive      bool
	cwd          string
	mu           sync.Mutex
	commandQueue chan *commandExecution
}
type commandExecution struct {
	command    string
	timeout    time.Duration
	resultChan chan commandResult
	ctx        context.Context
}
type commandResult struct {
	stdout      string
	stderr      string
	exitCode    int
	interrupted bool
	err         error
}
var (
	shellInstance     *PersistentShell
	shellInstanceOnce sync.Once
)
func GetPersistentShell(workingDir string) *PersistentShell
func newPersistentShell(cwd string) *PersistentShell
⋮----
var shellPath string
var shellArgs []string
⋮----
func (s *PersistentShell) processCommands()
func (s *PersistentShell) execCommand(command string, timeout time.Duration, ctx context.Context) commandResult
func (s *PersistentShell) killChildren()
⋮----
var pid int
⋮----
func (s *PersistentShell) Exec(ctx context.Context, command string, timeoutMs int) (string, string, int, bool, error)
func (s *PersistentShell) Close()
func shellQuote(s string) string
func readFileOrEmpty(path string) string
func fileExists(path string) bool
func fileSize(path string) int64
</file>

<file path="internal/llm/tools/edit.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/permission"
)
⋮----
"context"
"encoding/json"
"fmt"
"os"
"path/filepath"
"strings"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/permission"
⋮----
type EditParams struct {
	FilePath  string `json:"file_path"`
	OldString string `json:"old_string"`
	NewString string `json:"new_string"`
}
type EditPermissionsParams struct {
	FilePath string `json:"file_path"`
	Diff     string `json:"diff"`
}
type EditResponseMetadata struct {
	Diff      string `json:"diff"`
	Additions int    `json:"additions"`
	Removals  int    `json:"removals"`
}
type editTool struct {
	lspClients  map[string]*lsp.Client
	permissions permission.Service
	files       history.Service
}
const (
	EditToolName    = "edit"
	editDescription = `Edits files by replacing text, creating new files, or deleting content. For moving or renaming files, use the Bash tool with the 'mv' command instead. For larger file edits, use the FileWrite tool to overwrite files.
Before using this tool:
1. Use the FileRead tool to understand the file's contents and context
2. Verify the directory path is correct (only applicable when creating new files):
func NewEditTool(lspClients map[string]*lsp.Client, permissions permission.Service, files history.Service) BaseTool
func (e *editTool) Info() ToolInfo
func (e *editTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params EditParams
⋮----
var response ToolResponse
var err error
⋮----
// Return early if there was an error during content replacement
// This prevents unnecessary LSP diagnostics processing
⋮----
func (e *editTool) createNewFile(ctx context.Context, filePath, content string) (ToolResponse, error)
⋮----
// Log error but don't fail the operation
⋮----
func (e *editTool) deleteContent(ctx context.Context, filePath, oldString string) (ToolResponse, error)
func (e *editTool) replaceContent(ctx context.Context, filePath, oldString, newString string) (ToolResponse, error)
</file>

<file path="internal/llm/tools/glob.go">
package tools
import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/fileutil"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"bytes"
"context"
"encoding/json"
"fmt"
"os/exec"
"path/filepath"
"sort"
"strings"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/fileutil"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
const (
	GlobToolName    = "glob"
	globDescription = `Fast file pattern matching tool that finds files by name and pattern, returning matching paths sorted by modification time (newest first).
type GlobParams struct {
	Pattern string `json:"pattern"`
	Path    string `json:"path"`
}
type GlobResponseMetadata struct {
	NumberOfFiles int  `json:"number_of_files"`
	Truncated     bool `json:"truncated"`
}
type globTool struct{}
func NewGlobTool() BaseTool
func (g *globTool) Info() ToolInfo
func (g *globTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params GlobParams
⋮----
var output string
⋮----
func globFiles(pattern, searchPath string, limit int) ([]string, bool, error)
func runRipgrep(cmd *exec.Cmd, searchRoot string, limit int) ([]string, error)
⋮----
var matches []string
</file>

<file path="internal/llm/tools/patch.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/permission"
)
⋮----
"context"
"encoding/json"
"fmt"
"os"
"path/filepath"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/permission"
⋮----
type PatchParams struct {
	PatchText string `json:"patch_text"`
}
type PatchResponseMetadata struct {
	FilesChanged []string `json:"files_changed"`
	Additions    int      `json:"additions"`
	Removals     int      `json:"removals"`
}
type patchTool struct {
	lspClients  map[string]*lsp.Client
	permissions permission.Service
	files       history.Service
}
const (
	PatchToolName    = "patch"
	patchDescription = `Applies a patch to multiple files in one operation. This tool is useful for making coordinated changes across multiple files.
The patch text must follow this format:
*** Begin Patch
*** Update File: /path/to/file
@@ Context line (unique within the file)
func NewPatchTool(lspClients map[string]*lsp.Client, permissions permission.Service, files history.Service) BaseTool
func (p *patchTool) Info() ToolInfo
func (p *patchTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params PatchParams
⋮----
// Calculate diff statistics
⋮----
// Update history
⋮----
// If not adding a file, create history entry for existing file
</file>

<file path="internal/llm/tools/write.go">
package tools
import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/history"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/permission"
)
⋮----
"context"
"encoding/json"
"fmt"
"os"
"path/filepath"
"strings"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/history"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/permission"
⋮----
type WriteParams struct {
	FilePath string `json:"file_path"`
	Content  string `json:"content"`
}
type WritePermissionsParams struct {
	FilePath string `json:"file_path"`
	Diff     string `json:"diff"`
}
type writeTool struct {
	lspClients  map[string]*lsp.Client
	permissions permission.Service
	files       history.Service
}
type WriteResponseMetadata struct {
	Diff      string `json:"diff"`
	Additions int    `json:"additions"`
	Removals  int    `json:"removals"`
}
const (
	WriteToolName    = "write"
	writeDescription = `File writing tool that creates or updates files in the filesystem, allowing you to save or modify text content.
WHEN TO USE THIS TOOL:
- Use when you need to create a new file
- Helpful for updating existing files with modified content
- Perfect for saving generated code, configurations, or text data
HOW TO USE:
- Provide the path to the file you want to write
- Include the content to be written to the file
- The tool will create any necessary parent directories
FEATURES:
- Can create new files or overwrite existing ones
- Creates parent directories automatically if they don't exist
- Checks if the file has been modified since last read for safety
- Avoids unnecessary writes when content hasn't changed
LIMITATIONS:
- You should read a file before writing to it to avoid conflicts
- Cannot append to files (rewrites the entire file)
func NewWriteTool(lspClients map[string]*lsp.Client, permissions permission.Service, files history.Service) BaseTool
func (w *writeTool) Info() ToolInfo
func (w *writeTool) Run(ctx context.Context, call ToolCall) (ToolResponse, error)
⋮----
var params WriteParams
</file>

<file path="internal/permission/permission.go">
package permission
import (
	"errors"
	"path/filepath"
	"slices"
	"sync"
	"github.com/google/uuid"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/pubsub"
)
⋮----
"errors"
"path/filepath"
"slices"
"sync"
"github.com/google/uuid"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/pubsub"
⋮----
var ErrorPermissionDenied = errors.New("permission denied")
type CreatePermissionRequest struct {
	SessionID   string `json:"session_id"`
	ToolName    string `json:"tool_name"`
	Description string `json:"description"`
	Action      string `json:"action"`
	Params      any    `json:"params"`
	Path        string `json:"path"`
}
type PermissionRequest struct {
	ID          string `json:"id"`
	SessionID   string `json:"session_id"`
	ToolName    string `json:"tool_name"`
	Description string `json:"description"`
	Action      string `json:"action"`
	Params      any    `json:"params"`
	Path        string `json:"path"`
}
type Service interface {
	pubsub.Suscriber[PermissionRequest]
	GrantPersistant(permission PermissionRequest)
	Grant(permission PermissionRequest)
	Deny(permission PermissionRequest)
	Request(opts CreatePermissionRequest) bool
	AutoApproveSession(sessionID string)
}
type permissionService struct {
	*pubsub.Broker[PermissionRequest]
	sessionPermissions  []PermissionRequest
	pendingRequests     sync.Map
	autoApproveSessions []string
}
func (s *permissionService) GrantPersistant(permission PermissionRequest)
func (s *permissionService) Grant(permission PermissionRequest)
func (s *permissionService) Deny(permission PermissionRequest)
func (s *permissionService) Request(opts CreatePermissionRequest) bool
func (s *permissionService) AutoApproveSession(sessionID string)
func NewPermissionService() Service
</file>

<file path="internal/tui/components/core/status.go">
package core
import (
	"fmt"
	"strings"
	"time"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/lsp"
	"github.com/opencode-ai/opencode/internal/lsp/protocol"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/components/chat"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"strings"
"time"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/lsp"
"github.com/opencode-ai/opencode/internal/lsp/protocol"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/components/chat"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type StatusCmp interface {
	tea.Model
}
type statusCmp struct {
	info       util.InfoMsg
	width      int
	messageTTL time.Duration
	lspClients map[string]*lsp.Client
	session    session.Session
}
func (m statusCmp) clearMessageCmd(ttl time.Duration) tea.Cmd
func (m statusCmp) Init() tea.Cmd
func (m statusCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
var helpWidget = ""
// getHelpWidget returns the help widget with current theme colors
func getHelpWidget() string
func formatTokensAndCost(tokens, contextWindow int64, cost float64) string
⋮----
var formattedTokens string
⋮----
func (m statusCmp) View() string
⋮----
// Truncate message if it's longer than available width
⋮----
func (m *statusCmp) projectDiagnostics() string
⋮----
// Check if any LSP server is still initializing
⋮----
// If any server is initializing, show that status
⋮----
func (m statusCmp) availableFooterMsgWidth(diagnostics, tokenInfo string) int
func (m statusCmp) model() string
func NewStatusCmp(lspClients map[string]*lsp.Client) StatusCmp
</file>

<file path="internal/tui/components/dialog/help.go">
package dialog
import (
	"strings"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"strings"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type helpCmp struct {
	width  int
	height int
	keys   []key.Binding
}
func (h *helpCmp) Init() tea.Cmd
func (h *helpCmp) SetBindings(k []key.Binding)
func (h *helpCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func removeDuplicateBindings(bindings []key.Binding) []key.Binding
func (h *helpCmp) render() string
⋮----
var (
		pairs []string
		width int
		rows  = 12 - 2
	)
⋮----
var (
			keys  []string
			descs []string
		)
⋮----
var cols []string
⋮----
func (h *helpCmp) View() string
type HelpCmp interface {
	tea.Model
	SetBindings([]key.Binding)
}
func NewHelpCmp() HelpCmp
</file>

<file path="internal/tui/components/dialog/init.go">
package dialog
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type InitDialogCmp struct {
	width, height int
	selected      int
	keys          initDialogKeyMap
}
func NewInitDialogCmp() InitDialogCmp
type initDialogKeyMap struct {
	Tab    key.Binding
	Left   key.Binding
	Right  key.Binding
	Enter  key.Binding
	Escape key.Binding
	Y      key.Binding
	N      key.Binding
}
func (k initDialogKeyMap) ShortHelp() []key.Binding
func (k initDialogKeyMap) FullHelp() [][]key.Binding
func (m InitDialogCmp) Init() tea.Cmd
func (m InitDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
func (m InitDialogCmp) View() string
func (m *InitDialogCmp) SetSize(width, height int)
func (m InitDialogCmp) Bindings() []key.Binding
type CloseInitDialogMsg struct {
	Initialize bool
}
type ShowInitDialogMsg struct {
	Show bool
}
</file>

<file path="internal/llm/provider/openai.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"time"
	"github.com/openai/openai-go"
	"github.com/openai/openai-go/option"
	"github.com/openai/openai-go/shared"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"os"
"path/filepath"
"time"
"github.com/openai/openai-go"
"github.com/openai/openai-go/option"
"github.com/openai/openai-go/shared"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
⋮----
type openaiOptions struct {
	baseURL         string
	disableCache    bool
	reasoningEffort string
	extraHeaders    map[string]string
}
type OpenAIOption func(*openaiOptions)
type openaiClient struct {
	providerOptions providerClientOptions
	options         openaiOptions
	client          openai.Client
}
type OpenAIClient ProviderClient
func newOpenAIClient(opts providerClientOptions) OpenAIClient
func (o *openaiClient) convertMessages(messages []message.Message) (openaiMessages []openai.ChatCompletionMessageParamUnion)
⋮----
// Add system message first
⋮----
var content []openai.ChatCompletionContentPartUnionParam
⋮----
func (o *openaiClient) convertTools(tools []tools.BaseTool) []openai.ChatCompletionToolParam
func (o *openaiClient) finishReason(reason string) message.FinishReason
func (o *openaiClient) preparedParams(messages []openai.ChatCompletionMessageParamUnion, tools []openai.ChatCompletionToolParam) openai.ChatCompletionNewParams
func (o *openaiClient) send(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (response *ProviderResponse, err error)
func (o *openaiClient) sendWithParams(ctx context.Context, params openai.ChatCompletionNewParams) (response *ProviderResponse, err error)
⋮----
request.Clear() // Clear request info on successful completion
⋮----
func (o *openaiClient) stream(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
func (o *openaiClient) streamWithParams(ctx context.Context, params openai.ChatCompletionNewParams) <-chan ProviderEvent
⋮----
// Set current request info for display
⋮----
// Debug logging for xAI
⋮----
var apierr *openai.Error
⋮----
func (o *openaiClient) shouldRetry(attempts int, err error) (bool, int64, error)
⋮----
var apierr *openai.Error
⋮----
func (o *openaiClient) toolCalls(completion openai.ChatCompletion) []message.ToolCall
⋮----
var toolCalls []message.ToolCall
⋮----
func (o *openaiClient) usage(completion openai.ChatCompletion) TokenUsage
func WithOpenAIBaseURL(baseURL string) OpenAIOption
func WithOpenAIExtraHeaders(headers map[string]string) OpenAIOption
func WithOpenAIDisableCache() OpenAIOption
func WithReasoningEffort(effort string) OpenAIOption
func (o *openaiClient) logRequest()
</file>

<file path="internal/tui/components/chat/message.go">
package chat
import (
	"context"
	"encoding/json"
	"fmt"
	"path/filepath"
	"strings"
	"time"
	"github.com/charmbracelet/lipgloss"
	"github.com/charmbracelet/x/ansi"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/llm/agent"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
)
⋮----
"context"
"encoding/json"
"fmt"
"path/filepath"
"strings"
"time"
"github.com/charmbracelet/lipgloss"
"github.com/charmbracelet/x/ansi"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/llm/agent"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
⋮----
type uiMessageType int
const (
	userMessageType uiMessageType = iota
	assistantMessageType
	toolMessageType
	maxResultHeight = 50
)
type uiMessage struct {
	ID          string
	messageType uiMessageType
	position    int
	height      int
	content     string
}
func toMarkdown(content string, focused bool, width int) string
func renderMessage(msg string, isUser bool, isFocused bool, width int, info ...string) string
func renderUserMessage(msg message.Message, isFocused bool, width int, position int) uiMessage
⋮----
var styledAttachments []string
⋮----
var filename string
⋮----
// Returns multiple uiMessages because of the tool calls
func renderAssistantMessage(
	msg message.Message,
	msgIndex int,
	allMessages []message.Message, // we need this to get tool results and the user message
	messagesService message.Service, // We need this to get the task tool messages
	focusedUIMessageId string,
	isSummary bool,
	width int,
	position int,
) []uiMessage
⋮----
allMessages []message.Message, // we need this to get tool results and the user message
messagesService message.Service, // We need this to get the task tool messages
⋮----
// Add finish info if available
⋮----
// If there's no content, add an error message
⋮----
// Check if there were tool calls
⋮----
// Don't show "Finished without output" if there were tool calls
⋮----
position++ // for the space
⋮----
// Render the thinking content
⋮----
position++ // for the space
⋮----
func findToolResponse(toolCallID string, futureMessages []message.Message) *message.ToolResult
func toolName(name string) string
func getToolAction(name string) string
func renderParams(paramsWidth int, params ...string) string
⋮----
// create pairs of key/value
// if odd number of params, the last one is a key without value
⋮----
func removeWorkingDirPrefix(path string) string
func renderToolParams(paramWidth int, toolCall message.ToolCall) string
⋮----
var params agent.AgentParams
⋮----
var params tools.BashParams
⋮----
var params tools.EditParams
⋮----
var params tools.FetchParams
⋮----
var params tools.GlobParams
⋮----
var params tools.GrepParams
⋮----
var params tools.LSParams
⋮----
var params tools.SourcegraphParams
⋮----
var params tools.ViewParams
⋮----
var params tools.WriteParams
⋮----
func truncateHeight(content string, height int) string
func renderToolResponse(toolCall message.ToolCall, response message.ToolResult, width int) string
func renderToolMessage(
	toolCall message.ToolCall,
	allMessages []message.Message,
	messagesService message.Service,
	focusedUIMessageId string,
	nested bool,
	width int,
	position int,
) uiMessage
⋮----
// Get a brief description of what the tool is doing
⋮----
// Helper function to format the time difference between two Unix timestamps
func formatTimestampDiff(start, end int64) string
⋮----
diffSeconds := float64(end-start) / 1000.0 // Convert to seconds
</file>

<file path="internal/tui/components/dialog/commands.go">
package dialog
import (
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	utilComponents "github.com/opencode-ai/opencode/internal/tui/components/util"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
utilComponents "github.com/opencode-ai/opencode/internal/tui/components/util"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type Command struct {
	ID          string
	Title       string
	Description string
	Handler     func(cmd Command) tea.Cmd
}
func (ci Command) Render(selected bool, width int) string
// CommandSelectedMsg is sent when a command is selected
type CommandSelectedMsg struct {
	Command Command
}
// CloseCommandDialogMsg is sent when the command dialog is closed
type CloseCommandDialogMsg struct{}
// CommandDialog interface for the command selection dialog
type CommandDialog interface {
	tea.Model
	layout.Bindings
	SetCommands(commands []Command)
}
type commandDialogCmp struct {
	listView utilComponents.SimpleList[Command]
	width    int
	height   int
}
type commandKeyMap struct {
	Enter  key.Binding
	Escape key.Binding
}
var commandKeys = commandKeyMap{
	Enter: key.NewBinding(
		key.WithKeys("enter"),
		key.WithHelp("enter", "select command"),
	),
	Escape: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "close"),
	),
}
func (c *commandDialogCmp) Init() tea.Cmd
func (c *commandDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
func (c *commandDialogCmp) View() string
func (c *commandDialogCmp) BindingKeys() []key.Binding
func (c *commandDialogCmp) SetCommands(commands []Command)
// NewCommandDialogCmp creates a new command selection dialog
func NewCommandDialogCmp() CommandDialog
</file>

<file path="cmd/schema/main.go">
package main
import (
	"encoding/json"
	"fmt"
	"os"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
)
⋮----
"encoding/json"
"fmt"
"os"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
⋮----
type JSONSchemaType struct {
	Type                 string           `json:"type,omitempty"`
	Description          string           `json:"description,omitempty"`
	Properties           map[string]any   `json:"properties,omitempty"`
	Required             []string         `json:"required,omitempty"`
	AdditionalProperties any              `json:"additionalProperties,omitempty"`
	Enum                 []any            `json:"enum,omitempty"`
	Items                map[string]any   `json:"items,omitempty"`
	OneOf                []map[string]any `json:"oneOf,omitempty"`
	AnyOf                []map[string]any `json:"anyOf,omitempty"`
	Default              any              `json:"default,omitempty"`
}
func main()
func generateSchema() map[string]any
</file>

<file path="internal/tui/components/chat/list.go">
package chat
import (
	"context"
	"fmt"
	"math"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/spinner"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/components/dialog"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"context"
"fmt"
"math"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/spinner"
"github.com/charmbracelet/bubbles/viewport"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/components/dialog"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type cacheItem struct {
	width   int
	content []uiMessage
}
type messagesCmp struct {
	app           *app.App
	width, height int
	viewport      viewport.Model
	session       session.Session
	messages      []message.Message
	uiMessages    []uiMessage
	currentMsgID  string
	cachedContent map[string]cacheItem
	spinner       spinner.Model
	rendering     bool
	attachments   viewport.Model
}
type renderFinishedMsg struct{}
type MessageKeys struct {
	PageDown     key.Binding
	PageUp       key.Binding
	HalfPageUp   key.Binding
	HalfPageDown key.Binding
}
var messageKeys = MessageKeys{
	PageDown: key.NewBinding(
		key.WithKeys("pgdown"),
		key.WithHelp("f/pgdn", "page down"),
	),
	PageUp: key.NewBinding(
		key.WithKeys("pgup"),
		key.WithHelp("b/pgup", "page up"),
	),
	HalfPageUp: key.NewBinding(
		key.WithKeys("ctrl+u"),
		key.WithHelp("ctrl+u", "½ page up"),
	),
	HalfPageDown: key.NewBinding(
		key.WithKeys("ctrl+d", "ctrl+d"),
		key.WithHelp("ctrl+d", "½ page down"),
	),
}
func (m *messagesCmp) Init() tea.Cmd
func (m *messagesCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
// Handle half-page scrolling with custom smaller amount
⋮----
// Scroll up by 3 lines instead of half page
⋮----
// Scroll down by 3 lines instead of half page
⋮----
// Let viewport handle full page scrolling normally
⋮----
// Only handle wheel events, let click/drag pass through for text selection
⋮----
// Don't consume other mouse events - let them bubble up for text selection
⋮----
// There are tool calls from the child task
⋮----
func (m *messagesCmp) IsAgentWorking() bool
func formatTimeDifference(unixTime1, unixTime2 int64) string
func (m *messagesCmp) renderView()
func (m *messagesCmp) View() string
func hasToolsWithoutResponse(messages []message.Message) bool
func hasUnfinishedToolCalls(messages []message.Message) bool
func (m *messagesCmp) working() string
func (m *messagesCmp) help() string
func (m *messagesCmp) initialScreen() string
⋮----
// Add request info if available
⋮----
func (m *messagesCmp) rerender()
func (m *messagesCmp) SetSize(width, height int) tea.Cmd
func (m *messagesCmp) GetSize() (int, int)
func (m *messagesCmp) SetSession(session session.Session) tea.Cmd
func (m *messagesCmp) BindingKeys() []key.Binding
func NewMessagesCmp(app *app.App) tea.Model
</file>

<file path="internal/tui/components/dialog/permission.go">
package dialog
import (
	"fmt"
	"strings"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/viewport"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/diff"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"strings"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/viewport"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/diff"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type PermissionAction string
const (
	PermissionAllow           PermissionAction = "allow"
	PermissionAllowForSession PermissionAction = "allow_session"
	PermissionDeny            PermissionAction = "deny"
)
type PermissionResponseMsg struct {
	Permission permission.PermissionRequest
	Action     PermissionAction
}
type PermissionDialogCmp interface {
	tea.Model
	layout.Bindings
	SetPermissions(permission permission.PermissionRequest) tea.Cmd
}
type permissionsMapping struct {
	Left         key.Binding
	Right        key.Binding
	EnterSpace   key.Binding
	Allow        key.Binding
	AllowSession key.Binding
	Deny         key.Binding
	Tab          key.Binding
}
var permissionsKeys = permissionsMapping{
	Left: key.NewBinding(
		key.WithKeys("left"),
		key.WithHelp("←", "switch options"),
	),
	Right: key.NewBinding(
		key.WithKeys("right"),
		key.WithHelp("→", "switch options"),
	),
	EnterSpace: key.NewBinding(
		key.WithKeys("enter", " "),
		key.WithHelp("enter/space", "confirm"),
	),
	Allow: key.NewBinding(
		key.WithKeys("a"),
		key.WithHelp("a", "allow"),
	),
	AllowSession: key.NewBinding(
		key.WithKeys("s"),
		key.WithHelp("s", "allow for session"),
	),
	Deny: key.NewBinding(
		key.WithKeys("d"),
		key.WithHelp("d", "deny"),
	),
	Tab: key.NewBinding(
		key.WithKeys("tab"),
		key.WithHelp("tab", "switch options"),
	),
}
type permissionDialogCmp struct {
	width           int
	height          int
	permission      permission.PermissionRequest
	windowSize      tea.WindowSizeMsg
	contentViewPort viewport.Model
	selectedOption  int
	diffCache     map[string]string
	markdownCache map[string]string
}
func (p *permissionDialogCmp) Init() tea.Cmd
func (p *permissionDialogCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
func (p *permissionDialogCmp) selectCurrentOption() tea.Cmd
⋮----
var action PermissionAction
⋮----
func (p *permissionDialogCmp) renderButtons() string
func (p *permissionDialogCmp) renderHeader() string
func (p *permissionDialogCmp) renderBashContent() string
func (p *permissionDialogCmp) renderEditContent() string
func (p *permissionDialogCmp) renderPatchContent() string
func (p *permissionDialogCmp) renderWriteContent() string
⋮----
// Use the cache for diff rendering
⋮----
func (p *permissionDialogCmp) renderFetchContent() string
⋮----
// Use the cache for markdown rendering
⋮----
// Fix HTML entity encoding - decode entities after markdown rendering
⋮----
func (p *permissionDialogCmp) renderDefaultContent() string
⋮----
// Use the cache for markdown rendering
⋮----
// Fix HTML entity encoding - decode entities after markdown rendering
⋮----
func (p *permissionDialogCmp) styleViewport() string
func (p *permissionDialogCmp) render() string
⋮----
var contentFinal string
⋮----
func (p *permissionDialogCmp) View() string
func (p *permissionDialogCmp) BindingKeys() []key.Binding
func (p *permissionDialogCmp) SetSize() tea.Cmd
func (p *permissionDialogCmp) SetPermissions(permission permission.PermissionRequest) tea.Cmd
// Helper to get or set cached diff content
func (c *permissionDialogCmp) GetOrSetDiff(key string, generator func() (string, error)) string
func (c *permissionDialogCmp) GetOrSetMarkdown(key string, generator func() (string, error)) string
func NewPermissionDialogCmp() PermissionDialogCmp
</file>

<file path="cmd/root.go">
package cmd
import (
	"context"
	"fmt"
	"os"
	"sync"
	"time"
	tea "github.com/charmbracelet/bubbletea"
	zone "github.com/lrstanley/bubblezone"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/db"
	"github.com/opencode-ai/opencode/internal/format"
	"github.com/opencode-ai/opencode/internal/llm/agent"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/tui"
	"github.com/opencode-ai/opencode/internal/version"
	"github.com/spf13/cobra"
)
⋮----
"context"
"fmt"
"os"
"sync"
"time"
tea "github.com/charmbracelet/bubbletea"
zone "github.com/lrstanley/bubblezone"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/db"
"github.com/opencode-ai/opencode/internal/format"
"github.com/opencode-ai/opencode/internal/llm/agent"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/tui"
"github.com/opencode-ai/opencode/internal/version"
"github.com/spf13/cobra"
⋮----
var rootCmd = &cobra.Command{
	Use:   "opencode",
	Short: "Terminal-based AI assistant for software development",
	Long: `OpenCode is a powerful terminal-based AI assistant that helps with software development tasks.
It provides an interactive chat interface with AI capabilities, code analysis, and LSP integration
to assist developers in writing, debugging, and understanding code directly from the terminal.`,
	Example: `
  # Run in interactive mode
  opencode
  # Run with debug logging
  opencode -d
  # Run with debug logging in a specific directory
  opencode -d -c /path/to/project
  # Print version
  opencode -v
  # Run a single non-interactive prompt
  opencode -p "Explain the use of context in Go"
  # Run a single non-interactive prompt with JSON output format
  opencode -p "Explain the use of context in Go" -f json
  `,
	RunE: func(cmd *cobra.Command, args []string) error {
		if cmd.Flag("help").Changed {
			cmd.Help()
			return nil
		}
		if cmd.Flag("version").Changed {
			fmt.Println(version.Version)
			return nil
		}
		debug, _ := cmd.Flags().GetBool("debug")
		cwd, _ := cmd.Flags().GetString("cwd")
		prompt, _ := cmd.Flags().GetString("prompt")
		outputFormat, _ := cmd.Flags().GetString("output-format")
		quiet, _ := cmd.Flags().GetBool("quiet")
		if !format.IsValid(outputFormat) {
			return fmt.Errorf("invalid format option: %s\n%s", outputFormat, format.GetHelpText())
		}
		if cwd != "" {
			err := os.Chdir(cwd)
			if err != nil {
				return fmt.Errorf("failed to change directory: %v", err)
			}
		}
		if cwd == "" {
			c, err := os.Getwd()
			if err != nil {
				return fmt.Errorf("failed to get current working directory: %v", err)
			}
			cwd = c
		}
		_, err := config.Load(cwd, debug)
		if err != nil {
			return err
		}
		conn, err := db.Connect()
		if err != nil {
			return err
		}
		ctx, cancel := context.WithCancel(context.Background())
		defer cancel()
		app, err := app.New(ctx, conn)
		if err != nil {
			logging.Error("Failed to create app: %v", err)
			return err
		}
		defer app.Shutdown()
		initMCPTools(ctx, app)
		if prompt != "" {
			// Run non-interactive flow using the App method
			return app.RunNonInteractive(ctx, prompt, outputFormat, quiet)
		}
		// Interactive mode
		// Set up the TUI
		zone.NewGlobal()
		program := tea.NewProgram(
			tui.New(app),
			tea.WithAltScreen(),
			// Mouse support disabled until Bubble Tea implements native selection
			// Use Ctrl+U/D and PageUp/Down for scrolling
		)
		// Setup the subscriptions, this will send services events to the TUI
		ch, cancelSubs := setupSubscriptions(app, ctx)
		// Create a context for the TUI message handler
		tuiCtx, tuiCancel := context.WithCancel(ctx)
		var tuiWg sync.WaitGroup
		tuiWg.Add(1)
		// Set up message handling for the TUI
		go func() {
			defer tuiWg.Done()
			defer logging.RecoverPanic("TUI-message-handler", func() {
				attemptTUIRecovery(program)
			})
			for {
				select {
				case <-tuiCtx.Done():
					logging.Info("TUI message handler shutting down")
					return
				case msg, ok := <-ch:
					if !ok {
						logging.Info("TUI message channel closed")
						return
					}
					program.Send(msg)
				}
			}
		}()
		cleanup := func() {
			app.Shutdown()
			cancelSubs()
			tuiCancel()
			tuiWg.Wait()
			logging.Info("All goroutines cleaned up")
		}
		result, err := program.Run()
		cleanup()
		if err != nil {
			logging.Error("TUI error: %v", err)
			return fmt.Errorf("TUI error: %v", err)
		}
		logging.Info("TUI exited with result: %v", result)
		return nil
	},
}
⋮----
// Run non-interactive flow using the App method
⋮----
// Interactive mode
// Set up the TUI
⋮----
// Mouse support disabled until Bubble Tea implements native selection
// Use Ctrl+U/D and PageUp/Down for scrolling
⋮----
// Setup the subscriptions, this will send services events to the TUI
⋮----
// Create a context for the TUI message handler
⋮----
var tuiWg sync.WaitGroup
⋮----
// Set up message handling for the TUI
⋮----
func attemptTUIRecovery(program *tea.Program)
func initMCPTools(ctx context.Context, app *app.App)
func setupSubscriber[T any](
	ctx context.Context,
	wg *sync.WaitGroup,
	name string,
	subscriber func(context.Context) <-chan pubsub.Event[T],
	outputCh chan<- tea.Msg,
)
⋮----
var msg tea.Msg = event
⋮----
func setupSubscriptions(app *app.App, parentCtx context.Context) (chan tea.Msg, func())
func Execute()
func init()
</file>

<file path="internal/llm/agent/agent.go">
package agent
import (
	"context"
	"errors"
	"fmt"
	"strings"
	"sync"
	"time"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/prompt"
	"github.com/opencode-ai/opencode/internal/llm/provider"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/session"
)
⋮----
"context"
"errors"
"fmt"
"strings"
"sync"
"time"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/prompt"
"github.com/opencode-ai/opencode/internal/llm/provider"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/session"
⋮----
var (
	ErrRequestCancelled = errors.New("request cancelled by user")
type AgentEventType string
const (
	AgentEventTypeError     AgentEventType = "error"
	AgentEventTypeResponse  AgentEventType = "response"
	AgentEventTypeSummarize AgentEventType = "summarize"
)
type AgentEvent struct {
	Type    AgentEventType
	Message message.Message
	Error   error
	SessionID string
	Progress  string
	Done      bool
}
type Service interface {
	pubsub.Suscriber[AgentEvent]
	Model() models.Model
	Run(ctx context.Context, sessionID string, content string, attachments ...message.Attachment) (<-chan AgentEvent, error)
	Cancel(sessionID string)
	IsSessionBusy(sessionID string) bool
	IsBusy() bool
	Update(agentName config.AgentName, modelID models.ModelID) (models.Model, error)
	Summarize(ctx context.Context, sessionID string) error
}
type agent struct {
	*pubsub.Broker[AgentEvent]
	sessions session.Service
	messages message.Service
	tools    []tools.BaseTool
	provider provider.Provider
	titleProvider     provider.Provider
	summarizeProvider provider.Provider
	activeRequests sync.Map
}
func NewAgent(
	agentName config.AgentName,
	sessions session.Service,
	messages message.Service,
	agentTools []tools.BaseTool,
) (Service, error)
⋮----
var titleProvider provider.Provider
⋮----
var summarizeProvider provider.Provider
⋮----
func (a *agent) Model() models.Model
func (a *agent) Cancel(sessionID string)
func (a *agent) IsBusy() bool
func (a *agent) IsSessionBusy(sessionID string) bool
func (a *agent) generateTitle(ctx context.Context, sessionID string, content string) error
func (a *agent) err(err error) AgentEvent
func (a *agent) Run(ctx context.Context, sessionID string, content string, attachments ...message.Attachment) (<-chan AgentEvent, error)
⋮----
var attachmentParts []message.ContentPart
⋮----
func (a *agent) processGeneration(ctx context.Context, sessionID, content string, attachmentParts []message.ContentPart) AgentEvent
func (a *agent) createUserMessage(ctx context.Context, sessionID, content string, attachmentParts []message.ContentPart) (message.Message, error)
func (a *agent) streamAndHandleEvents(ctx context.Context, sessionID string, msgHistory []message.Message) (message.Message, *message.Message, error)
⋮----
var tool tools.BaseTool
⋮----
func (a *agent) finishMessage(ctx context.Context, msg *message.Message, finishReson message.FinishReason)
func (a *agent) processEvent(ctx context.Context, sessionID string, assistantMsg *message.Message, event provider.ProviderEvent) error
func (a *agent) TrackUsage(ctx context.Context, sessionID string, model models.Model, usage provider.TokenUsage) error
func (a *agent) Update(agentName config.AgentName, modelID models.ModelID) (models.Model, error)
func (a *agent) Summarize(ctx context.Context, sessionID string) error
func createAgentProvider(agentName config.AgentName) (provider.Provider, error)
</file>

<file path="internal/llm/provider/anthropic.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"
	"github.com/anthropics/anthropic-sdk-go"
	"github.com/anthropics/anthropic-sdk-go/bedrock"
	"github.com/anthropics/anthropic-sdk-go/option"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	toolsPkg "github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"os"
"path/filepath"
"strings"
"time"
"github.com/anthropics/anthropic-sdk-go"
"github.com/anthropics/anthropic-sdk-go/bedrock"
"github.com/anthropics/anthropic-sdk-go/option"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
toolsPkg "github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
⋮----
type anthropicOptions struct {
	useBedrock   bool
	disableCache bool
	shouldThink  func(userMessage string) bool
}
type AnthropicOption func(*anthropicOptions)
type anthropicClient struct {
	providerOptions providerClientOptions
	options         anthropicOptions
	client          anthropic.Client
}
type AnthropicClient ProviderClient
func newAnthropicClient(opts providerClientOptions) AnthropicClient
func (a *anthropicClient) convertMessages(messages []message.Message) (anthropicMessages []anthropic.MessageParam)
⋮----
var contentBlocks []anthropic.ContentBlockParamUnion
⋮----
var inputMap map[string]any
⋮----
func (a *anthropicClient) convertTools(tools []toolsPkg.BaseTool) []anthropic.ToolUnionParam
func (a *anthropicClient) finishReason(reason string) message.FinishReason
func (a *anthropicClient) preparedMessages(messages []anthropic.MessageParam, tools []anthropic.ToolUnionParam) anthropic.MessageNewParams
⋮----
var thinkingParam anthropic.ThinkingConfigParamUnion
⋮----
func (a *anthropicClient) send(ctx context.Context, messages []message.Message, tools []toolsPkg.BaseTool) (resposne *ProviderResponse, err error)
⋮----
request.Clear() // Clear request info on successful completion
⋮----
func (a *anthropicClient) stream(ctx context.Context, messages []message.Message, tools []toolsPkg.BaseTool) <-chan ProviderEvent
⋮----
// Set current request info for display
⋮----
var sessionId string
⋮----
request.Clear() // Clear request info on successful completion
⋮----
// If there is an error we are going to see if we can retry the call
⋮----
request.Clear() // Clear request info on error
⋮----
func (a *anthropicClient) shouldRetry(attempts int, err error) (bool, int64, error)
⋮----
var apierr *anthropic.Error
⋮----
func (a *anthropicClient) toolCalls(msg anthropic.Message) []message.ToolCall
⋮----
var toolCalls []message.ToolCall
⋮----
func (a *anthropicClient) usage(msg anthropic.Message) TokenUsage
func WithAnthropicBedrock(useBedrock bool) AnthropicOption
func WithAnthropicDisableCache() AnthropicOption
func DefaultShouldThinkFn(s string) bool
func WithAnthropicShouldThinkFn(fn func(string) bool) AnthropicOption
func (a *anthropicClient) logRequest()
</file>

<file path="internal/llm/provider/provider.go">
package provider
import (
	"context"
	"fmt"
	"os"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/message"
)
⋮----
"context"
"fmt"
"os"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/message"
⋮----
type EventType string
const maxRetries = 8
const (
	EventContentStart  EventType = "content_start"
	EventToolUseStart  EventType = "tool_use_start"
	EventToolUseDelta  EventType = "tool_use_delta"
	EventToolUseStop   EventType = "tool_use_stop"
	EventContentDelta  EventType = "content_delta"
	EventThinkingDelta EventType = "thinking_delta"
	EventContentStop   EventType = "content_stop"
	EventComplete      EventType = "complete"
	EventError         EventType = "error"
	EventWarning       EventType = "warning"
)
type TokenUsage struct {
	InputTokens         int64
	OutputTokens        int64
	CacheCreationTokens int64
	CacheReadTokens     int64
}
type ProviderResponse struct {
	Content      string
	ToolCalls    []message.ToolCall
	Usage        TokenUsage
	FinishReason message.FinishReason
}
type ProviderEvent struct {
	Type EventType
	Content  string
	Thinking string
	Response *ProviderResponse
	ToolCall *message.ToolCall
	Error    error
}
type Provider interface {
	SendMessages(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
	StreamResponse(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
	Model() models.Model
}
type providerClientOptions struct {
	apiKey        string
	model         models.Model
	maxTokens     int64
	systemMessage string
	anthropicOptions []AnthropicOption
	openaiOptions    []OpenAIOption
	geminiOptions    []GeminiOption
	bedrockOptions   []BedrockOption
	copilotOptions   []CopilotOption
}
type ProviderClientOption func(*providerClientOptions)
type ProviderClient interface {
	send(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
	stream(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
}
type baseProvider[C ProviderClient] struct {
	options providerClientOptions
	client  C
}
func NewProvider(providerName models.ModelProvider, opts ...ProviderClientOption) (Provider, error)
func (p *baseProvider[C]) cleanMessages(messages []message.Message) (cleaned []message.Message)
func (p *baseProvider[C]) SendMessages(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
func (p *baseProvider[C]) Model() models.Model
func (p *baseProvider[C]) StreamResponse(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
func WithAPIKey(apiKey string) ProviderClientOption
func WithModel(model models.Model) ProviderClientOption
func WithMaxTokens(maxTokens int64) ProviderClientOption
func WithSystemMessage(systemMessage string) ProviderClientOption
func WithAnthropicOptions(anthropicOptions ...AnthropicOption) ProviderClientOption
func WithOpenAIOptions(openaiOptions ...OpenAIOption) ProviderClientOption
func WithGeminiOptions(geminiOptions ...GeminiOption) ProviderClientOption
func WithBedrockOptions(bedrockOptions ...BedrockOption) ProviderClientOption
func WithCopilotOptions(copilotOptions ...CopilotOption) ProviderClientOption
</file>

<file path="internal/tui/components/chat/editor.go">
package chat
import (
	"fmt"
	"os"
	"os/exec"
	"slices"
	"strings"
	"unicode"
	"github.com/charmbracelet/bubbles/key"
	"github.com/charmbracelet/bubbles/textarea"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/components/dialog"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/styles"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"fmt"
"os"
"os/exec"
"slices"
"strings"
"unicode"
"github.com/charmbracelet/bubbles/key"
"github.com/charmbracelet/bubbles/textarea"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/components/dialog"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/styles"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type editorCmp struct {
	width       int
	height      int
	app         *app.App
	session     session.Session
	textarea    textarea.Model
	attachments []message.Attachment
	deleteMode  bool
}
type EditorKeyMaps struct {
	Send       key.Binding
	OpenEditor key.Binding
}
type bluredEditorKeyMaps struct {
	Send       key.Binding
	Focus      key.Binding
	OpenEditor key.Binding
}
type DeleteAttachmentKeyMaps struct {
	AttachmentDeleteMode key.Binding
	Escape               key.Binding
	DeleteAllAttachments key.Binding
}
var editorMaps = EditorKeyMaps{
	Send: key.NewBinding(
		key.WithKeys("enter", "ctrl+s"),
		key.WithHelp("enter", "send message"),
	),
	OpenEditor: key.NewBinding(
		key.WithKeys("ctrl+e"),
		key.WithHelp("ctrl+e", "open editor"),
	),
}
var DeleteKeyMaps = DeleteAttachmentKeyMaps{
	AttachmentDeleteMode: key.NewBinding(
		key.WithKeys("ctrl+r"),
		key.WithHelp("ctrl+r+{i}", "delete attachment at index i"),
	),
	Escape: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "cancel delete mode"),
	),
	DeleteAllAttachments: key.NewBinding(
		key.WithKeys("r"),
		key.WithHelp("ctrl+r+r", "delete all attchments"),
	),
}
const (
	maxAttachments = 5
)
func (m *editorCmp) openEditor() tea.Cmd
func (m *editorCmp) Init() tea.Cmd
func (m *editorCmp) send() tea.Cmd
func (m *editorCmp) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmd tea.Cmd
⋮----
func (m *editorCmp) View() string
func (m *editorCmp) SetSize(width, height int) tea.Cmd
func (m *editorCmp) GetSize() (int, int)
func (m *editorCmp) attachmentsContent() string
⋮----
var styledAttachments []string
⋮----
var filename string
⋮----
func (m *editorCmp) BindingKeys() []key.Binding
func CreateTextArea(existing *textarea.Model) textarea.Model
func NewEditorCmp(app *app.App) tea.Model
</file>

<file path="internal/tui/page/chat.go">
package page
import (
	"context"
	"strings"
	"time"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/completions"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/components/chat"
	"github.com/opencode-ai/opencode/internal/tui/components/dialog"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"context"
"strings"
"time"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/completions"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/components/chat"
"github.com/opencode-ai/opencode/internal/tui/components/dialog"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
var ChatPage PageID = "chat"
type chatPage struct {
	app                  *app.App
	editor               layout.Container
	messages             layout.Container
	layout               layout.SplitPaneLayout
	session              session.Session
	completionDialog     dialog.CompletionDialog
	showCompletionDialog bool
}
type ChatKeyMap struct {
	ShowCompletionDialog key.Binding
	NewSession           key.Binding
	Cancel               key.Binding
}
var keyMap = ChatKeyMap{
	ShowCompletionDialog: key.NewBinding(
		key.WithKeys("@"),
		key.WithHelp("@", "Complete"),
	),
	NewSession: key.NewBinding(
		key.WithKeys("ctrl+n"),
		key.WithHelp("ctrl+n", "new session"),
	),
	Cancel: key.NewBinding(
		key.WithKeys("esc"),
		key.WithHelp("esc", "cancel"),
	),
}
func (p *chatPage) Init() tea.Cmd
func (p *chatPage) tickCmd() tea.Cmd
type tickMsg time.Time
func (p *chatPage) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmds []tea.Cmd
⋮----
// Continue sending keys to layout->chat
⋮----
// Cancel the current session's generation process
// This allows users to interrupt long-running operations
⋮----
// Doesn't forward event if enter key is pressed
⋮----
func (p *chatPage) setSidebar() tea.Cmd
func (p *chatPage) clearSidebar() tea.Cmd
func (p *chatPage) sendMessage(text string, attachments []message.Attachment) tea.Cmd
func (p *chatPage) SetSize(width, height int) tea.Cmd
func (p *chatPage) GetSize() (int, int)
func (p *chatPage) View() string
func (p *chatPage) BindingKeys() []key.Binding
func NewChatPage(app *app.App) tea.Model
</file>

<file path="internal/llm/models/models.go">
package models
import "maps"
⋮----
ModelID       string
ModelProvider string
⋮----
type Model struct {
	ID                  ModelID       `json:"id"`
	Name                string        `json:"name"`
	Provider            ModelProvider `json:"provider"`
	APIModel            string        `json:"api_model"`
	CostPer1MIn         float64       `json:"cost_per_1m_in"`
	CostPer1MOut        float64       `json:"cost_per_1m_out"`
	CostPer1MInCached   float64       `json:"cost_per_1m_in_cached"`
	CostPer1MOutCached  float64       `json:"cost_per_1m_out_cached"`
	ContextWindow       int64         `json:"context_window"`
	DefaultMaxTokens    int64         `json:"default_max_tokens"`
	CanReason           bool          `json:"can_reason"`
	SupportsAttachments bool          `json:"supports_attachments"`
}
const (
	BedrockClaude37Sonnet ModelID = "bedrock.claude-3.7-sonnet"
)
const (
	ProviderBedrock ModelProvider = "bedrock"
	ProviderMock ModelProvider = "__mock"
)
var ProviderPopularity = map[ModelProvider]int{
	ProviderCopilot:    1,
	ProviderAnthropic:  2,
	ProviderOpenAI:     3,
	ProviderGemini:     4,
	ProviderGROQ:       5,
	ProviderOpenRouter: 6,
	ProviderBedrock:    7,
	ProviderAzure:      8,
	ProviderVertexAI:   9,
}
var SupportedModels = map[ModelID]Model{
	BedrockClaude37Sonnet: {
		ID:                 BedrockClaude37Sonnet,
		Name:               "Bedrock: Claude 3.7 Sonnet",
		Provider:           ProviderBedrock,
		APIModel:           "anthropic.claude-3-7-sonnet-20250219-v1:0",
		CostPer1MIn:        3.0,
		CostPer1MInCached:  3.75,
		CostPer1MOutCached: 0.30,
		CostPer1MOut:       15.0,
	},
}
func init()
</file>

<file path="internal/llm/prompt/prompt.go">
package prompt
import (
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/logging"
)
⋮----
"fmt"
"os"
"path/filepath"
"strings"
"sync"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/logging"
⋮----
func GetAgentPrompt(agentName config.AgentName, provider models.ModelProvider) string
var (
	onceContext    sync.Once
	contextContent string
)
func getContextFromPaths() string
⋮----
var (
			cfg          = config.Get()
⋮----
func processContextPaths(workDir string, paths []string) string
⋮----
var (
		wg       sync.WaitGroup
		resultCh = make(chan string)
⋮----
var processedMutex sync.Mutex
⋮----
// Check if we've already processed this file (case-insensitive)
⋮----
func processFile(filePath string) string
</file>

<file path="internal/llm/provider/gemini.go">
package provider
import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"strings"
	"time"
	"github.com/google/uuid"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/tools"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/message"
	"github.com/opencode-ai/opencode/internal/request"
	"google.golang.org/genai"
)
⋮----
"context"
"encoding/json"
"errors"
"fmt"
"io"
"strings"
"time"
"github.com/google/uuid"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/tools"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/message"
"github.com/opencode-ai/opencode/internal/request"
"google.golang.org/genai"
⋮----
type geminiOptions struct {
	disableCache bool
}
type GeminiOption func(*geminiOptions)
type geminiClient struct {
	providerOptions providerClientOptions
	options         geminiOptions
	client          *genai.Client
}
type GeminiClient ProviderClient
func newGeminiClient(opts providerClientOptions) GeminiClient
func (g *geminiClient) convertMessages(messages []message.Message) []*genai.Content
⋮----
var history []*genai.Content
⋮----
var parts []*genai.Part
⋮----
var assistantParts []*genai.Part
⋮----
var toolCall message.ToolCall
⋮----
func (g *geminiClient) convertTools(tools []tools.BaseTool) []*genai.Tool
func (g *geminiClient) finishReason(reason genai.FinishReason) message.FinishReason
func (g *geminiClient) send(ctx context.Context, messages []message.Message, tools []tools.BaseTool) (*ProviderResponse, error)
⋮----
var toolCalls []message.ToolCall
var lastMsgParts []genai.Part
⋮----
func (g *geminiClient) stream(ctx context.Context, messages []message.Message, tools []tools.BaseTool) <-chan ProviderEvent
⋮----
var finalResp *genai.GenerateContentResponse
⋮----
var lastMsgParts []genai.Part
⋮----
request.Clear() // Clear request info on error
⋮----
func (g *geminiClient) shouldRetry(attempts int, err error) (bool, int64, error)
func (g *geminiClient) toolCalls(resp *genai.GenerateContentResponse) []message.ToolCall
⋮----
var toolCalls []message.ToolCall
⋮----
func (g *geminiClient) usage(resp *genai.GenerateContentResponse) TokenUsage
func WithGeminiDisableCache() GeminiOption
func parseJsonToMap(jsonStr string) (map[string]interface
⋮----
var result map[string]interface{}
⋮----
func convertSchemaProperties(parameters map[string]interface
func convertToSchema(param interface
func processArrayItems(paramMap map[string]interface
func mapJSONTypeToGenAI(jsonType string) genai.Type
func contains(s string, substrs ...string) bool
</file>

<file path="go.mod">
module github.com/opencode-ai/opencode

go 1.24.0

require (
	github.com/Azure/azure-sdk-for-go/sdk/azidentity v1.7.0
	github.com/JohannesKaufmann/html-to-markdown v1.6.0
	github.com/PuerkitoBio/goquery v1.9.2
	github.com/alecthomas/chroma/v2 v2.15.0
	github.com/anthropics/anthropic-sdk-go v1.4.0
	github.com/aymanbagabas/go-udiff v0.2.0
	github.com/bmatcuk/doublestar/v4 v4.8.1
	github.com/catppuccin/go v0.3.0
	github.com/charmbracelet/bubbles v0.21.0
	github.com/charmbracelet/bubbletea v1.3.5
	github.com/charmbracelet/glamour v0.9.1
	github.com/charmbracelet/lipgloss v1.1.0
	github.com/charmbracelet/x/ansi v0.8.0
	github.com/fsnotify/fsnotify v1.8.0
	github.com/go-logfmt/logfmt v0.6.0
	github.com/google/uuid v1.6.0
	github.com/lrstanley/bubblezone v0.0.0-20250315020633-c249a3fe1231
	github.com/mark3labs/mcp-go v0.17.0
	github.com/muesli/ansi v0.0.0-20230316100256-276c6243b2f6
	github.com/muesli/reflow v0.3.0
	github.com/muesli/termenv v0.16.0
	github.com/ncruces/go-sqlite3 v0.25.0
	github.com/openai/openai-go v0.1.0-beta.2
	github.com/pressly/goose/v3 v3.24.2
	github.com/sergi/go-diff v1.3.2-0.20230802210424-5b0b94c5c0d3
	github.com/spf13/cobra v1.9.1
	github.com/spf13/viper v1.20.0
	github.com/stretchr/testify v1.10.0
)

require (
	cloud.google.com/go v0.116.0 // indirect
	cloud.google.com/go/auth v0.13.0 // indirect
	cloud.google.com/go/compute/metadata v0.6.0 // indirect
	github.com/Azure/azure-sdk-for-go/sdk/azcore v1.17.0 // indirect
	github.com/Azure/azure-sdk-for-go/sdk/internal v1.10.0 // indirect
	github.com/AzureAD/microsoft-authentication-library-for-go v1.2.2 // indirect
	github.com/andybalholm/cascadia v1.3.2 // indirect
	github.com/atotto/clipboard v0.1.4 // indirect
	github.com/aws/aws-sdk-go-v2 v1.30.3 // indirect
	github.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.6.3 // indirect
	github.com/aws/aws-sdk-go-v2/config v1.27.27 // indirect
	github.com/aws/aws-sdk-go-v2/credentials v1.17.27 // indirect
	github.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.11 // indirect
	github.com/aws/aws-sdk-go-v2/internal/configsources v1.3.15 // indirect
	github.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.15 // indirect
	github.com/aws/aws-sdk-go-v2/internal/ini v1.8.0 // indirect
	github.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.3 // indirect
	github.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.17 // indirect
	github.com/aws/aws-sdk-go-v2/service/sso v1.22.4 // indirect
	github.com/aws/aws-sdk-go-v2/service/ssooidc v1.26.4 // indirect
	github.com/aws/aws-sdk-go-v2/service/sts v1.30.3 // indirect
	github.com/aws/smithy-go v1.20.3 // indirect
	github.com/aymanbagabas/go-osc52/v2 v2.0.1 // indirect
	github.com/aymerick/douceur v0.2.0 // indirect
	github.com/charmbracelet/colorprofile v0.2.3-0.20250311203215-f60798e515dc // indirect
	github.com/charmbracelet/x/cellbuf v0.0.13-0.20250311204145-2c3ea96c31dd // indirect
	github.com/charmbracelet/x/term v0.2.1 // indirect
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/disintegration/imaging v1.6.2
	github.com/dlclark/regexp2 v1.11.4 // indirect
	github.com/erikgeiser/coninput v0.0.0-20211004153227-1c3628e74d0f // indirect
	github.com/felixge/httpsnoop v1.0.4 // indirect
	github.com/go-logr/logr v1.4.2 // indirect
	github.com/go-logr/stdr v1.2.2 // indirect
	github.com/go-viper/mapstructure/v2 v2.2.1 // indirect
	github.com/golang-jwt/jwt/v5 v5.2.2 // indirect
	github.com/google/go-cmp v0.7.0 // indirect
	github.com/google/s2a-go v0.1.8 // indirect
	github.com/googleapis/enterprise-certificate-proxy v0.3.4 // indirect
	github.com/googleapis/gax-go/v2 v2.14.1 // indirect
	github.com/gorilla/css v1.0.1 // indirect
	github.com/gorilla/websocket v1.5.3 // indirect
	github.com/inconshreveable/mousetrap v1.1.0 // indirect
	github.com/kylelemons/godebug v1.1.0 // indirect
	github.com/lithammer/fuzzysearch v1.1.8
	github.com/lucasb-eyer/go-colorful v1.2.0
	github.com/mattn/go-isatty v0.0.20 // indirect
	github.com/mattn/go-localereader v0.0.1 // indirect
	github.com/mattn/go-runewidth v0.0.16 // indirect
	github.com/mfridman/interpolate v0.0.2 // indirect
	github.com/microcosm-cc/bluemonday v1.0.27 // indirect
	github.com/muesli/cancelreader v0.2.2 // indirect
	github.com/ncruces/julianday v1.0.0 // indirect
	github.com/pelletier/go-toml/v2 v2.2.3 // indirect
	github.com/pkg/browser v0.0.0-20240102092130-5ac0b6a4141c // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/rivo/uniseg v0.4.7 // indirect
	github.com/rogpeppe/go-internal v1.14.1 // indirect
	github.com/sagikazarmark/locafero v0.7.0 // indirect
	github.com/sethvargo/go-retry v0.3.0 // indirect
	github.com/sourcegraph/conc v0.3.0 // indirect
	github.com/spf13/afero v1.12.0 // indirect
	github.com/spf13/cast v1.7.1 // indirect
	github.com/spf13/pflag v1.0.6 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	github.com/tetratelabs/wazero v1.9.0 // indirect
	github.com/tidwall/gjson v1.18.0 // indirect
	github.com/tidwall/match v1.1.1 // indirect
	github.com/tidwall/pretty v1.2.1 // indirect
	github.com/tidwall/sjson v1.2.5 // indirect
	github.com/xo/terminfo v0.0.0-20220910002029-abceb7e1c41e // indirect
	github.com/yosida95/uritemplate/v3 v3.0.2 // indirect
	github.com/yuin/goldmark v1.7.8 // indirect
	github.com/yuin/goldmark-emoji v1.0.5 // indirect
	go.opentelemetry.io/auto/sdk v1.1.0 // indirect
	go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.54.0 // indirect
	go.opentelemetry.io/otel v1.35.0 // indirect
	go.opentelemetry.io/otel/metric v1.35.0 // indirect
	go.opentelemetry.io/otel/trace v1.35.0 // indirect
	go.uber.org/multierr v1.11.0 // indirect
	golang.org/x/crypto v0.37.0 // indirect
	golang.org/x/image v0.26.0 // indirect
	golang.org/x/net v0.39.0 // indirect
	golang.org/x/sync v0.13.0 // indirect
	golang.org/x/sys v0.32.0 // indirect
	golang.org/x/term v0.31.0 // indirect
	golang.org/x/text v0.24.0 // indirect
	google.golang.org/genai v1.3.0
	google.golang.org/genproto/googleapis/rpc v0.0.0-20250324211829-b45e905df463 // indirect
	google.golang.org/grpc v1.71.0 // indirect
	google.golang.org/protobuf v1.36.6 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
)
</file>

<file path="opencode-schema.json">
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "definitions": {
    "agent": {
      "description": "Agent configuration",
      "properties": {
        "maxTokens": {
          "description": "Maximum tokens for the agent",
          "minimum": 1,
          "type": "integer"
        },
        "model": {
          "description": "Model ID for the agent",
          "enum": [
            "gpt-4.1",
            "llama-3.3-70b-versatile",
            "azure.gpt-4.1",
            "openrouter.gpt-4o",
            "openrouter.o1-mini",
            "openrouter.claude-3-haiku",
            "claude-3-opus",
            "gpt-4o",
            "gpt-4o-mini",
            "o1",
            "meta-llama/llama-4-maverick-17b-128e-instruct",
            "azure.o3-mini",
            "openrouter.gpt-4o-mini",
            "openrouter.o1",
            "claude-3.5-haiku",
            "o4-mini",
            "azure.gpt-4.1-mini",
            "openrouter.o3",
            "grok-3-beta",
            "o3-mini",
            "qwen-qwq",
            "azure.o1",
            "openrouter.gemini-2.5-flash",
            "openrouter.gemini-2.5",
            "o1-mini",
            "azure.gpt-4o",
            "openrouter.gpt-4.1-mini",
            "openrouter.claude-3.5-sonnet",
            "openrouter.o3-mini",
            "gpt-4.1-mini",
            "gpt-4.5-preview",
            "gpt-4.1-nano",
            "deepseek-r1-distill-llama-70b",
            "azure.gpt-4o-mini",
            "openrouter.gpt-4.1",
            "bedrock.claude-3.7-sonnet",
            "claude-3-haiku",
            "o3",
            "gemini-2.0-flash-lite",
            "azure.o3",
            "azure.gpt-4.5-preview",
            "openrouter.claude-3-opus",
            "grok-3-mini-fast-beta",
            "claude-4-sonnet",
            "azure.o4-mini",
            "grok-3-fast-beta",
            "claude-3.5-sonnet",
            "azure.o1-mini",
            "openrouter.claude-3.7-sonnet",
            "openrouter.gpt-4.5-preview",
            "grok-3-mini-beta",
            "claude-3.7-sonnet",
            "gemini-2.0-flash",
            "openrouter.deepseek-r1-free",
            "vertexai.gemini-2.5-flash",
            "vertexai.gemini-2.5",
            "o1-pro",
            "gemini-2.5",
            "meta-llama/llama-4-scout-17b-16e-instruct",
            "azure.gpt-4.1-nano",
            "openrouter.gpt-4.1-nano",
            "gemini-2.5-flash",
            "openrouter.o4-mini",
            "openrouter.claude-3.5-haiku",
            "claude-4-opus",
            "openrouter.o1-pro",
            "copilot.gpt-4o",
            "copilot.gpt-4o-mini",
            "copilot.gpt-4.1",
            "copilot.claude-3.5-sonnet",
            "copilot.claude-3.7-sonnet",
            "copilot.claude-sonnet-4",
            "copilot.o1",
            "copilot.o3-mini",
            "copilot.o4-mini",
            "copilot.gemini-2.0-flash",
            "copilot.gemini-2.5-pro"
          ],
          "type": "string"
        },
        "reasoningEffort": {
          "description": "Reasoning effort for models that support it (OpenAI, Anthropic)",
          "enum": [
            "low",
            "medium",
            "high"
          ],
          "type": "string"
        }
      },
      "required": [
        "model"
      ],
      "type": "object"
    }
  },
  "description": "Configuration schema for the OpenCode application",
  "properties": {
    "agents": {
      "additionalProperties": {
        "description": "Agent configuration",
        "properties": {
          "maxTokens": {
            "description": "Maximum tokens for the agent",
            "minimum": 1,
            "type": "integer"
          },
          "model": {
            "description": "Model ID for the agent",
            "enum": [
              "gpt-4.1",
              "llama-3.3-70b-versatile",
              "azure.gpt-4.1",
              "openrouter.gpt-4o",
              "openrouter.o1-mini",
              "openrouter.claude-3-haiku",
              "claude-3-opus",
              "gpt-4o",
              "gpt-4o-mini",
              "o1",
              "meta-llama/llama-4-maverick-17b-128e-instruct",
              "azure.o3-mini",
              "openrouter.gpt-4o-mini",
              "openrouter.o1",
              "claude-3.5-haiku",
              "o4-mini",
              "azure.gpt-4.1-mini",
              "openrouter.o3",
              "grok-3-beta",
              "o3-mini",
              "qwen-qwq",
              "azure.o1",
              "openrouter.gemini-2.5-flash",
              "openrouter.gemini-2.5",
              "o1-mini",
              "azure.gpt-4o",
              "openrouter.gpt-4.1-mini",
              "openrouter.claude-3.5-sonnet",
              "openrouter.o3-mini",
              "gpt-4.1-mini",
              "gpt-4.5-preview",
              "gpt-4.1-nano",
              "deepseek-r1-distill-llama-70b",
              "azure.gpt-4o-mini",
              "openrouter.gpt-4.1",
              "bedrock.claude-3.7-sonnet",
              "claude-3-haiku",
              "o3",
              "gemini-2.0-flash-lite",
              "azure.o3",
              "azure.gpt-4.5-preview",
              "openrouter.claude-3-opus",
              "grok-3-mini-fast-beta",
              "claude-4-sonnet",
              "azure.o4-mini",
              "grok-3-fast-beta",
              "claude-3.5-sonnet",
              "azure.o1-mini",
              "openrouter.claude-3.7-sonnet",
              "openrouter.gpt-4.5-preview",
              "grok-3-mini-beta",
              "claude-3.7-sonnet",
              "gemini-2.0-flash",
              "openrouter.deepseek-r1-free",
              "vertexai.gemini-2.5-flash",
              "vertexai.gemini-2.5",
              "o1-pro",
              "gemini-2.5",
              "meta-llama/llama-4-scout-17b-16e-instruct",
              "azure.gpt-4.1-nano",
              "openrouter.gpt-4.1-nano",
              "gemini-2.5-flash",
              "openrouter.o4-mini",
              "openrouter.claude-3.5-haiku",
              "claude-4-opus",
              "openrouter.o1-pro",
              "copilot.gpt-4o",
              "copilot.gpt-4o-mini",
              "copilot.gpt-4.1",
              "copilot.claude-3.5-sonnet",
              "copilot.claude-3.7-sonnet",
              "copilot.claude-sonnet-4",
              "copilot.o1",
              "copilot.o3-mini",
              "copilot.o4-mini",
              "copilot.gemini-2.0-flash",
              "copilot.gemini-2.5-pro"
            ],
            "type": "string"
          },
          "reasoningEffort": {
            "description": "Reasoning effort for models that support it (OpenAI, Anthropic)",
            "enum": [
              "low",
              "medium",
              "high"
            ],
            "type": "string"
          }
        },
        "required": [
          "model"
        ],
        "type": "object"
      },
      "description": "Agent configurations",
      "properties": {
        "coder": {
          "$ref": "#/definitions/agent"
        },
        "task": {
          "$ref": "#/definitions/agent"
        },
        "title": {
          "$ref": "#/definitions/agent"
        }
      },
      "type": "object"
    },
    "contextPaths": {
      "default": [
        ".github/copilot-instructions.md",
        ".cursorrules",
        ".cursor/rules/",
        "CLAUDE.md",
        "CLAUDE.local.md",
        "opencode.md",
        "opencode.local.md",
        "OpenCode.md",
        "OpenCode.local.md",
        "OPENCODE.md",
        "OPENCODE.local.md"
      ],
      "description": "Context paths for the application",
      "items": {
        "type": "string"
      },
      "type": "array"
    },
    "data": {
      "description": "Storage configuration",
      "properties": {
        "directory": {
          "default": ".opencode",
          "description": "Directory where application data is stored",
          "type": "string"
        }
      },
      "required": [
        "directory"
      ],
      "type": "object"
    },
    "debug": {
      "default": false,
      "description": "Enable debug mode",
      "type": "boolean"
    },
    "debugLSP": {
      "default": false,
      "description": "Enable LSP debug mode",
      "type": "boolean"
    },
    "lsp": {
      "additionalProperties": {
        "description": "LSP configuration for a language",
        "properties": {
          "args": {
            "description": "Command arguments for the LSP server",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "command": {
            "description": "Command to execute for the LSP server",
            "type": "string"
          },
          "disabled": {
            "default": false,
            "description": "Whether the LSP is disabled",
            "type": "boolean"
          },
          "options": {
            "description": "Additional options for the LSP server",
            "type": "object"
          }
        },
        "required": [
          "command"
        ],
        "type": "object"
      },
      "description": "Language Server Protocol configurations",
      "type": "object"
    },
    "mcpServers": {
      "additionalProperties": {
        "description": "MCP server configuration",
        "properties": {
          "args": {
            "description": "Command arguments for the MCP server",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "command": {
            "description": "Command to execute for the MCP server",
            "type": "string"
          },
          "env": {
            "description": "Environment variables for the MCP server",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "headers": {
            "additionalProperties": {
              "type": "string"
            },
            "description": "HTTP headers for SSE type MCP servers",
            "type": "object"
          },
          "type": {
            "default": "stdio",
            "description": "Type of MCP server",
            "enum": [
              "stdio",
              "sse"
            ],
            "type": "string"
          },
          "url": {
            "description": "URL for SSE type MCP servers",
            "type": "string"
          }
        },
        "required": [
          "command"
        ],
        "type": "object"
      },
      "description": "Model Control Protocol server configurations",
      "type": "object"
    },
    "providers": {
      "additionalProperties": {
        "description": "Provider configuration",
        "properties": {
          "apiKey": {
            "description": "API key for the provider",
            "type": "string"
          },
          "disabled": {
            "default": false,
            "description": "Whether the provider is disabled",
            "type": "boolean"
          },
          "provider": {
            "description": "Provider type",
            "enum": [
              "anthropic",
              "openai",
              "gemini",
              "groq",
              "openrouter",
              "bedrock",
              "azure",
              "vertexai",
              "copilot"
            ],
            "type": "string"
          }
        },
        "type": "object"
      },
      "description": "LLM provider configurations",
      "type": "object"
    },
    "tui": {
      "description": "Terminal User Interface configuration",
      "properties": {
        "theme": {
          "default": "opencode",
          "description": "TUI theme name",
          "enum": [
            "opencode",
            "catppuccin",
            "dracula",
            "flexoki",
            "gruvbox",
            "monokai",
            "onedark",
            "tokyonight",
            "tron"
          ],
          "type": "string"
        }
      },
      "type": "object"
    },
    "wd": {
      "description": "Working directory for the application",
      "type": "string"
    }
  },
  "title": "OpenCode Configuration",
  "type": "object"
}
</file>

<file path=".goreleaser.yml">
version: 2
project_name: opencode
before:
  hooks:
builds:
  - env:
      - CGO_ENABLED=0
    goos:
      - linux
      - darwin
    goarch:
      - amd64
      - arm64
    ldflags:
      - -s -w -X github.com/opencode-ai/opencode/internal/version.Version={{.Version}}
    main: ./main.go
archives:
  - format: tar.gz
    name_template: >-
      opencode-
      {{- if eq .Os "darwin" }}mac-
      {{- else if eq .Os "windows" }}windows-
      {{- else if eq .Os "linux" }}linux-{{end}}
      {{- if eq .Arch "amd64" }}x86_64
      {{- else if eq .Arch "#86" }}i386
      {{- else }}{{ .Arch }}{{ end }}
      {{- if .Arm }}v{{ .Arm }}{{ end }}
    format_overrides:
      - goos: windows
        format: zip
checksum:
  name_template: "checksums.txt"
snapshot:
  name_template: "0.0.0-{{ .Timestamp }}"
aurs:
  - name: opencode-ai
    homepage: "https://github.com/opencode-ai/opencode"
    description: "terminal based agent that can build anything"
    maintainers:
      - "kujtimiihoxha <kujtimii.h@gmail.com>"
    license: "MIT"
    private_key: "{{ .Env.AUR_KEY }}"
    git_url: "ssh://aur@aur.archlinux.org/opencode-ai-bin.git"
    provides:
      - opencode
    conflicts:
      - opencode
    package: |-
      install -Dm755 ./opencode "${pkgdir}/usr/bin/opencode"
brews:
  - repository:
      owner: opencode-ai
      name: homebrew-tap
nfpms:
  - maintainer: kujtimiihoxha
    description: terminal based agent that can build anything
    formats:
      - deb
      - rpm
    file_name_template: >-
      {{ .ProjectName }}-
      {{- if eq .Os "darwin" }}mac
      {{- else }}{{ .Os }}{{ end }}-{{ .Arch }}
changelog:
  sort: asc
  filters:
    exclude:
      - "^docs:"
      - "^doc:"
      - "^test:"
      - "^ci:"
      - "^ignore:"
      - "^example:"
      - "^wip:"
</file>

<file path="internal/tui/tui.go">
package tui
import (
	"context"
	"fmt"
	"strings"
	"github.com/charmbracelet/bubbles/key"
	tea "github.com/charmbracelet/bubbletea"
	"github.com/charmbracelet/lipgloss"
	"github.com/opencode-ai/opencode/internal/app"
	"github.com/opencode-ai/opencode/internal/config"
	"github.com/opencode-ai/opencode/internal/llm/agent"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/opencode-ai/opencode/internal/permission"
	"github.com/opencode-ai/opencode/internal/pubsub"
	"github.com/opencode-ai/opencode/internal/session"
	"github.com/opencode-ai/opencode/internal/tui/components/chat"
	"github.com/opencode-ai/opencode/internal/tui/components/core"
	"github.com/opencode-ai/opencode/internal/tui/components/dialog"
	"github.com/opencode-ai/opencode/internal/tui/layout"
	"github.com/opencode-ai/opencode/internal/tui/page"
	"github.com/opencode-ai/opencode/internal/tui/theme"
	"github.com/opencode-ai/opencode/internal/tui/util"
)
⋮----
"context"
"fmt"
"strings"
"github.com/charmbracelet/bubbles/key"
tea "github.com/charmbracelet/bubbletea"
"github.com/charmbracelet/lipgloss"
"github.com/opencode-ai/opencode/internal/app"
"github.com/opencode-ai/opencode/internal/config"
"github.com/opencode-ai/opencode/internal/llm/agent"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/opencode-ai/opencode/internal/permission"
"github.com/opencode-ai/opencode/internal/pubsub"
"github.com/opencode-ai/opencode/internal/session"
"github.com/opencode-ai/opencode/internal/tui/components/chat"
"github.com/opencode-ai/opencode/internal/tui/components/core"
"github.com/opencode-ai/opencode/internal/tui/components/dialog"
"github.com/opencode-ai/opencode/internal/tui/layout"
"github.com/opencode-ai/opencode/internal/tui/page"
"github.com/opencode-ai/opencode/internal/tui/theme"
"github.com/opencode-ai/opencode/internal/tui/util"
⋮----
type keyMap struct {
	Logs          key.Binding
	Quit          key.Binding
	Help          key.Binding
	SwitchSession key.Binding
	Commands      key.Binding
	Filepicker    key.Binding
	Models        key.Binding
	SwitchTheme   key.Binding
}
type startCompactSessionMsg struct{}
const (
	quitKey = "q"
)
var keys = keyMap{
	Logs: key.NewBinding(
		key.WithKeys("ctrl+l"),
		key.WithHelp("ctrl+l", "logs"),
	),
	Quit: key.NewBinding(
		key.WithKeys("ctrl+c"),
		key.WithHelp("ctrl+c", "quit"),
	),
	Help: key.NewBinding(
		key.WithKeys("ctrl+_", "ctrl+h"),
		key.WithHelp("ctrl+?", "toggle help"),
	),
	SwitchSession: key.NewBinding(
		key.WithKeys("ctrl+s"),
		key.WithHelp("ctrl+s", "switch session"),
	),
	Commands: key.NewBinding(
		key.WithKeys("ctrl+k"),
		key.WithHelp("ctrl+k", "commands"),
	),
	Filepicker: key.NewBinding(
		key.WithKeys("ctrl+f"),
		key.WithHelp("ctrl+f", "select files to upload"),
	),
	Models: key.NewBinding(
		key.WithKeys("ctrl+o"),
		key.WithHelp("ctrl+o", "model selection"),
	),
	SwitchTheme: key.NewBinding(
		key.WithKeys("ctrl+t"),
		key.WithHelp("ctrl+t", "switch theme"),
	),
}
var helpEsc = key.NewBinding(
	key.WithKeys("?"),
var returnKey = key.NewBinding(
	key.WithKeys("esc"),
var logsKeyReturnKey = key.NewBinding(
	key.WithKeys("esc", "backspace", quitKey),
type appModel struct {
	width, height   int
	currentPage     page.PageID
	previousPage    page.PageID
	pages           map[page.PageID]tea.Model
	loadedPages     map[page.PageID]bool
	status          core.StatusCmp
	app             *app.App
	selectedSession session.Session
	showPermissions bool
	permissions     dialog.PermissionDialogCmp
	showHelp bool
	help     dialog.HelpCmp
	showQuit bool
	quit     dialog.QuitDialog
	showSessionDialog bool
	sessionDialog     dialog.SessionDialog
	showCommandDialog bool
	commandDialog     dialog.CommandDialog
	commands          []dialog.Command
	showModelDialog bool
	modelDialog     dialog.ModelDialog
	showInitDialog bool
	initDialog     dialog.InitDialogCmp
	showFilepicker bool
	filepicker     dialog.FilepickerCmp
	showThemeDialog bool
	themeDialog     dialog.ThemeDialog
	showMultiArgumentsDialog bool
	multiArgumentsDialog     dialog.MultiArgumentsDialogCmp
	isCompacting      bool
	compactingMessage string
}
func (a appModel) Init() tea.Cmd
⋮----
var cmds []tea.Cmd
⋮----
func (a appModel) Update(msg tea.Msg) (tea.Model, tea.Cmd)
⋮----
var cmd tea.Cmd
⋮----
var cmd tea.Cmd
⋮----
// Continue listening for events
⋮----
// Model selected: msg.Model.Name
⋮----
// Error updating model
⋮----
// Model successfully changed
⋮----
func (a *appModel) RegisterCommand(cmd dialog.Command)
func (a *appModel) findCommand(id string) (dialog.Command, bool)
func (a *appModel) moveToPage(pageID page.PageID) tea.Cmd
func (a appModel) View() string
func New(app *app.App) tea.Model
</file>

<file path="internal/config/config.go">
package config
import (
	"encoding/json"
	"fmt"
	"log/slog"
	"os"
	"path/filepath"
	"runtime"
	"strings"
	"github.com/opencode-ai/opencode/internal/llm/models"
	"github.com/opencode-ai/opencode/internal/logging"
	"github.com/spf13/viper"
)
⋮----
"encoding/json"
"fmt"
"log/slog"
"os"
"path/filepath"
"runtime"
"strings"
"github.com/opencode-ai/opencode/internal/llm/models"
"github.com/opencode-ai/opencode/internal/logging"
"github.com/spf13/viper"
⋮----
type MCPType string
const (
	MCPStdio MCPType = "stdio"
	MCPSse   MCPType = "sse"
)
type MCPServer struct {
	Command string            `json:"command"`
	Env     []string          `json:"env"`
	Args    []string          `json:"args"`
	Type    MCPType           `json:"type"`
	URL     string            `json:"url"`
	Headers map[string]string `json:"headers"`
}
type AgentName string
const (
	AgentCoder      AgentName = "coder"
	AgentSummarizer AgentName = "summarizer"
	AgentTask       AgentName = "task"
	AgentTitle      AgentName = "title"
)
type Agent struct {
	Model           models.ModelID `json:"model"`
	MaxTokens       int64          `json:"maxTokens"`
	ReasoningEffort string         `json:"reasoningEffort"`
}
type Provider struct {
	APIKey   string `json:"apiKey"`
	Disabled bool   `json:"disabled"`
}
type Data struct {
	Directory string `json:"directory,omitempty"`
}
type LSPConfig struct {
	Disabled bool     `json:"enabled"`
	Command  string   `json:"command"`
	Args     []string `json:"args"`
	Options  any      `json:"options"`
}
type TUIConfig struct {
	Theme string `json:"theme,omitempty"`
}
type ShellConfig struct {
	Path string   `json:"path,omitempty"`
	Args []string `json:"args,omitempty"`
}
type Config struct {
	Data         Data                              `json:"data"`
	WorkingDir   string                            `json:"wd,omitempty"`
	MCPServers   map[string]MCPServer              `json:"mcpServers,omitempty"`
	Providers    map[models.ModelProvider]Provider `json:"providers,omitempty"`
	LSP          map[string]LSPConfig              `json:"lsp,omitempty"`
	Agents       map[AgentName]Agent               `json:"agents,omitempty"`
	Debug        bool                              `json:"debug,omitempty"`
	DebugLSP     bool                              `json:"debugLSP,omitempty"`
	ContextPaths []string                          `json:"contextPaths,omitempty"`
	TUI          TUIConfig                         `json:"tui"`
	Shell        ShellConfig                       `json:"shell,omitempty"`
	AutoCompact  bool                              `json:"autoCompact,omitempty"`
}
const (
	defaultDataDirectory = ".opencode"
	defaultLogLevel      = "info"
	appName              = "opencode"
	MaxTokensFallbackDefault = 4096
)
var defaultContextPaths = []string{
	".github/copilot-instructions.md",
	".cursorrules",
	".cursor/rules/",
	"CLAUDE.md",
	"CLAUDE.local.md",
	"opencode.md",
	"opencode.local.md",
	"OpenCode.md",
	"OpenCode.local.md",
	"OPENCODE.md",
	"OPENCODE.local.md",
}
var cfg *Config
func Load(workingDir string, debug bool) (*Config, error)
func configureViper()
func setDefaults(debug bool)
func setProviderDefaults()
⋮----
// api-key may be empty when using Entra ID credentials – that's okay
⋮----
func hasAWSCredentials() bool
⋮----
// Check for AWS profile
⋮----
// Check for AWS region
⋮----
// Check if running on EC2 with instance profile
⋮----
// hasVertexAICredentials checks if VertexAI credentials are available in the environment.
func hasVertexAICredentials() bool
⋮----
// Check for explicit VertexAI parameters
⋮----
// Check for Google Cloud project and location
⋮----
func hasCopilotCredentials() bool
⋮----
// Check for explicit Copilot parameters
⋮----
// readConfig handles the result of reading a configuration file.
func readConfig(err error) error
⋮----
// It's okay if the config file doesn't exist
⋮----
func mergeLocalConfig(workingDir string)
func applyDefaultValues()
// It validates model IDs and providers, ensuring they are supported.
func validateAgent(cfg *Config, name AgentName, agent Agent) error
⋮----
// Check if model exists
// TODO:	If a copilot model is specified, but model is not found,
// 		 	it might be new model. The https://api.githubcopilot.com/models
// 		 	endpoint should be queried to validate if the model is supported.
⋮----
// Add provider with API key from environment
⋮----
// Provider is disabled or has no API key
⋮----
// Set default reasoning effort for models that support it
⋮----
// Model doesn't support reasoning but reasoning effort is set
⋮----
// Validate checks if the configuration is valid and applies defaults where needed.
func Validate() error
func getProviderAPIKey(provider models.ModelProvider) string
// setDefaultModelForAgent sets a default model for an agent based on available providers
func setDefaultModelForAgent(agent AgentName) bool
⋮----
// Check providers in order of preference
⋮----
var model models.ModelID
⋮----
// Check if model supports reasoning
⋮----
func updateCfgFile(updateCfg func(config *Config)) error
⋮----
var configData []byte
⋮----
var userCfg *Config
⋮----
func Get() *Config
func WorkingDirectory() string
func UpdateAgentModel(agentName AgentName, modelID models.ModelID) error
func UpdateTheme(themeName string) error
func LoadGitHubToken() (string, error)
⋮----
// Get config directory
var configDir string
⋮----
var config map[string]map[string]interface{}
</file>

<file path="README.md">
> [!NOTE]  
> This is the original OpenCode repository, now continuing at [Charm](https://github.com/charmbracelet) with its original creator, [Kujtim Hoxha](https://github.com/kujtimiihoxha).  
> Development is continuing under a new name as we prepare for a public relaunch.  
> Follow [@charmcli](https://x.com/charmcli) or join our [Discord](https://charm.sh/chat) for updates.

# ⌬ OpenCode

<p align="center"><img src="https://github.com/user-attachments/assets/9ae61ef6-70e5-4876-bc45-5bcb4e52c714" width="800"></p>

> **⚠️ Early Development Notice:** This project is in early development and is not yet ready for production use. Features may change, break, or be incomplete. Use at your own risk.

A powerful terminal-based AI assistant for developers, providing intelligent coding assistance directly in your terminal.

## Overview

OpenCode is a Go-based CLI application that brings AI assistance to your terminal. It provides a TUI (Terminal User Interface) for interacting with various AI models to help with coding tasks, debugging, and more.

<p>For a quick video overview, check out
<a href="https://www.youtube.com/watch?v=P8luPmEa1QI"><img width="25" src="https://upload.wikimedia.org/wikipedia/commons/0/09/YouTube_full-color_icon_%282017%29.svg"> OpenCode + Gemini 2.5 Pro: BYE Claude Code! I'm SWITCHING To the FASTEST AI Coder!</a></p>

<a href="https://www.youtube.com/watch?v=P8luPmEa1QI"><img width="550" src="https://i3.ytimg.com/vi/P8luPmEa1QI/maxresdefault.jpg"></a><p>

## Features

- **Interactive TUI**: Built with [Bubble Tea](https://github.com/charmbracelet/bubbletea) for a smooth terminal experience
- **Multiple AI Providers**: Support for OpenAI, Anthropic Claude, Google Gemini, AWS Bedrock, Groq, Azure OpenAI, and OpenRouter
- **Session Management**: Save and manage multiple conversation sessions
- **Tool Integration**: AI can execute commands, search files, and modify code
- **Vim-like Editor**: Integrated editor with text input capabilities
- **Persistent Storage**: SQLite database for storing conversations and sessions
- **LSP Integration**: Language Server Protocol support for code intelligence
- **File Change Tracking**: Track and visualize file changes during sessions
- **External Editor Support**: Open your preferred editor for composing messages
- **Named Arguments for Custom Commands**: Create powerful custom commands with multiple named placeholders

## Installation

### Using the Install Script

```bash
# Install the latest version
curl -fsSL https://raw.githubusercontent.com/opencode-ai/opencode/refs/heads/main/install | bash

# Install a specific version
curl -fsSL https://raw.githubusercontent.com/opencode-ai/opencode/refs/heads/main/install | VERSION=0.1.0 bash
```

### Using Homebrew (macOS and Linux)

```bash
brew install opencode-ai/tap/opencode
```

### Using AUR (Arch Linux)

```bash
# Using yay
yay -S opencode-ai-bin

# Using paru
paru -S opencode-ai-bin
```

### Using Go

```bash
go install github.com/opencode-ai/opencode@latest
```

## Configuration

OpenCode looks for configuration in the following locations:

- `$HOME/.opencode.json`
- `$XDG_CONFIG_HOME/opencode/.opencode.json`
- `./.opencode.json` (local directory)

### Auto Compact Feature

OpenCode includes an auto compact feature that automatically summarizes your conversation when it approaches the model's context window limit. When enabled (default setting), this feature:

- Monitors token usage during your conversation
- Automatically triggers summarization when usage reaches 95% of the model's context window
- Creates a new session with the summary, allowing you to continue your work without losing context
- Helps prevent "out of context" errors that can occur with long conversations

You can enable or disable this feature in your configuration file:

```json
{
  "autoCompact": true // default is true
}
```

### Environment Variables

You can configure OpenCode using environment variables:

| Environment Variable       | Purpose                                                                          |
| -------------------------- | -------------------------------------------------------------------------------- |
| `ANTHROPIC_API_KEY`        | For Claude models                                                                |
| `OPENAI_API_KEY`           | For OpenAI models                                                                |
| `GEMINI_API_KEY`           | For Google Gemini models                                                         |
| `GITHUB_TOKEN`             | For Github Copilot models (see [Using Github Copilot](#using-github-copilot))    |
| `VERTEXAI_PROJECT`         | For Google Cloud VertexAI (Gemini)                                               |
| `VERTEXAI_LOCATION`        | For Google Cloud VertexAI (Gemini)                                               |
| `GROQ_API_KEY`             | For Groq models                                                                  |
| `AWS_ACCESS_KEY_ID`        | For AWS Bedrock (Claude)                                                         |
| `AWS_SECRET_ACCESS_KEY`    | For AWS Bedrock (Claude)                                                         |
| `AWS_REGION`               | For AWS Bedrock (Claude)                                                         |
| `AZURE_OPENAI_ENDPOINT`    | For Azure OpenAI models                                                          |
| `AZURE_OPENAI_API_KEY`     | For Azure OpenAI models (optional when using Entra ID)                           |
| `AZURE_OPENAI_API_VERSION` | For Azure OpenAI models                                                          |
| `LOCAL_ENDPOINT`           | For self-hosted models                                                           |
| `SHELL`                    | Default shell to use (if not specified in config)                                |

### Shell Configuration

OpenCode allows you to configure the shell used by the bash tool. By default, it uses the shell specified in the `SHELL` environment variable, or falls back to `/bin/bash` if not set.

You can override this in your configuration file:

```json
{
  "shell": {
    "path": "/bin/zsh",
    "args": ["-l"]
  }
}
```

This is useful if you want to use a different shell than your default system shell, or if you need to pass specific arguments to the shell.

### Configuration File Structure

```json
{
  "data": {
    "directory": ".opencode"
  },
  "providers": {
    "openai": {
      "apiKey": "your-api-key",
      "disabled": false
    },
    "anthropic": {
      "apiKey": "your-api-key",
      "disabled": false
    },
    "copilot": {
      "disabled": false
    },
    "groq": {
      "apiKey": "your-api-key",
      "disabled": false
    },
    "openrouter": {
      "apiKey": "your-api-key",
      "disabled": false
    }
  },
  "agents": {
    "coder": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 5000
    },
    "task": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 5000
    },
    "title": {
      "model": "claude-3.7-sonnet",
      "maxTokens": 80
    }
  },
  "shell": {
    "path": "/bin/bash",
    "args": ["-l"]
  },
  "mcpServers": {
    "example": {
      "type": "stdio",
      "command": "path/to/mcp-server",
      "env": [],
      "args": []
    }
  },
  "lsp": {
    "go": {
      "disabled": false,
      "command": "gopls"
    }
  },
  "debug": false,
  "debugLSP": false,
  "autoCompact": true
}
```

## Supported AI Models

OpenCode supports a variety of AI models from different providers:

### OpenAI

- GPT-4.1 family (gpt-4.1, gpt-4.1-mini, gpt-4.1-nano)
- GPT-4.5 Preview
- GPT-4o family (gpt-4o, gpt-4o-mini)
- O1 family (o1, o1-pro, o1-mini)
- O3 family (o3, o3-mini)
- O4 Mini

### Anthropic

- Claude 4 Sonnet
- Claude 4 Opus
- Claude 3.5 Sonnet
- Claude 3.5 Haiku
- Claude 3.7 Sonnet
- Claude 3 Haiku
- Claude 3 Opus

### GitHub Copilot

- GPT-3.5 Turbo
- GPT-4
- GPT-4o
- GPT-4o Mini
- GPT-4.1
- Claude 3.5 Sonnet
- Claude 3.7 Sonnet
- Claude 3.7 Sonnet Thinking
- Claude Sonnet 4
- O1
- O3 Mini
- O4 Mini
- Gemini 2.0 Flash
- Gemini 2.5 Pro

### Google

- Gemini 2.5
- Gemini 2.5 Flash
- Gemini 2.0 Flash
- Gemini 2.0 Flash Lite

### AWS Bedrock

- Claude 3.7 Sonnet

### Groq

- Llama 4 Maverick (17b-128e-instruct)
- Llama 4 Scout (17b-16e-instruct)
- QWEN QWQ-32b
- Deepseek R1 distill Llama 70b
- Llama 3.3 70b Versatile

### Azure OpenAI

- GPT-4.1 family (gpt-4.1, gpt-4.1-mini, gpt-4.1-nano)
- GPT-4.5 Preview
- GPT-4o family (gpt-4o, gpt-4o-mini)
- O1 family (o1, o1-mini)
- O3 family (o3, o3-mini)
- O4 Mini

### Google Cloud VertexAI

- Gemini 2.5
- Gemini 2.5 Flash

## Usage

```bash
# Start OpenCode
opencode

# Start with debug logging
opencode -d

# Start with a specific working directory
opencode -c /path/to/project
```

## Non-interactive Prompt Mode

You can run OpenCode in non-interactive mode by passing a prompt directly as a command-line argument. This is useful for scripting, automation, or when you want a quick answer without launching the full TUI.

```bash
# Run a single prompt and print the AI's response to the terminal
opencode -p "Explain the use of context in Go"

# Get response in JSON format
opencode -p "Explain the use of context in Go" -f json

# Run without showing the spinner (useful for scripts)
opencode -p "Explain the use of context in Go" -q
```

In this mode, OpenCode will process your prompt, print the result to standard output, and then exit. All permissions are auto-approved for the session.

By default, a spinner animation is displayed while the model is processing your query. You can disable this spinner with the `-q` or `--quiet` flag, which is particularly useful when running OpenCode from scripts or automated workflows.

### Output Formats

OpenCode supports the following output formats in non-interactive mode:

| Format | Description                     |
| ------ | ------------------------------- |
| `text` | Plain text output (default)     |
| `json` | Output wrapped in a JSON object |

The output format is implemented as a strongly-typed `OutputFormat` in the codebase, ensuring type safety and validation when processing outputs.

## Command-line Flags

| Flag              | Short | Description                                         |
| ----------------- | ----- | --------------------------------------------------- |
| `--help`          | `-h`  | Display help information                            |
| `--debug`         | `-d`  | Enable debug mode                                   |
| `--cwd`           | `-c`  | Set current working directory                       |
| `--prompt`        | `-p`  | Run a single prompt in non-interactive mode         |
| `--output-format` | `-f`  | Output format for non-interactive mode (text, json) |
| `--quiet`         | `-q`  | Hide spinner in non-interactive mode                |

## Keyboard Shortcuts

### Global Shortcuts

| Shortcut | Action                                                  |
| -------- | ------------------------------------------------------- |
| `Ctrl+C` | Quit application                                        |
| `Ctrl+?` | Toggle help dialog                                      |
| `?`      | Toggle help dialog (when not in editing mode)           |
| `Ctrl+L` | View logs                                               |
| `Ctrl+A` | Switch session                                          |
| `Ctrl+K` | Command dialog                                          |
| `Ctrl+O` | Toggle model selection dialog                           |
| `Esc`    | Close current overlay/dialog or return to previous mode |

### Chat Page Shortcuts

| Shortcut | Action                                  |
| -------- | --------------------------------------- |
| `Ctrl+N` | Create new session                      |
| `Ctrl+X` | Cancel current operation/generation     |
| `i`      | Focus editor (when not in writing mode) |
| `Esc`    | Exit writing mode and focus messages    |

### Editor Shortcuts

| Shortcut            | Action                                    |
| ------------------- | ----------------------------------------- |
| `Ctrl+S`            | Send message (when editor is focused)     |
| `Enter` or `Ctrl+S` | Send message (when editor is not focused) |
| `Ctrl+E`            | Open external editor                      |
| `Esc`               | Blur editor and focus messages            |

### Session Dialog Shortcuts

| Shortcut   | Action           |
| ---------- | ---------------- |
| `↑` or `k` | Previous session |
| `↓` or `j` | Next session     |
| `Enter`    | Select session   |
| `Esc`      | Close dialog     |

### Model Dialog Shortcuts

| Shortcut   | Action            |
| ---------- | ----------------- |
| `↑` or `k` | Move up           |
| `↓` or `j` | Move down         |
| `←` or `h` | Previous provider |
| `→` or `l` | Next provider     |
| `Esc`      | Close dialog      |

### Permission Dialog Shortcuts

| Shortcut                | Action                       |
| ----------------------- | ---------------------------- |
| `←` or `left`           | Switch options left          |
| `→` or `right` or `tab` | Switch options right         |
| `Enter` or `space`      | Confirm selection            |
| `a`                     | Allow permission             |
| `A`                     | Allow permission for session |
| `d`                     | Deny permission              |

### Logs Page Shortcuts

| Shortcut           | Action              |
| ------------------ | ------------------- |
| `Backspace` or `q` | Return to chat page |

## AI Assistant Tools

OpenCode's AI assistant has access to various tools to help with coding tasks:

### File and Code Tools

| Tool          | Description                 | Parameters                                                                               |
| ------------- | --------------------------- | ---------------------------------------------------------------------------------------- |
| `glob`        | Find files by pattern       | `pattern` (required), `path` (optional)                                                  |
| `grep`        | Search file contents        | `pattern` (required), `path` (optional), `include` (optional), `literal_text` (optional) |
| `ls`          | List directory contents     | `path` (optional), `ignore` (optional array of patterns)                                 |
| `view`        | View file contents          | `file_path` (required), `offset` (optional), `limit` (optional)                          |
| `write`       | Write to files              | `file_path` (required), `content` (required)                                             |
| `edit`        | Edit files                  | Various parameters for file editing                                                      |
| `patch`       | Apply patches to files      | `file_path` (required), `diff` (required)                                                |
| `diagnostics` | Get diagnostics information | `file_path` (optional)                                                                   |

### Other Tools

| Tool          | Description                            | Parameters                                                                                |
| ------------- | -------------------------------------- | ----------------------------------------------------------------------------------------- |
| `bash`        | Execute shell commands                 | `command` (required), `timeout` (optional)                                                |
| `fetch`       | Fetch data from URLs                   | `url` (required), `format` (required), `timeout` (optional)                               |
| `sourcegraph` | Search code across public repositories | `query` (required), `count` (optional), `context_window` (optional), `timeout` (optional) |
| `agent`       | Run sub-tasks with the AI agent        | `prompt` (required)                                                                       |

## Architecture

OpenCode is built with a modular architecture:

- **cmd**: Command-line interface using Cobra
- **internal/app**: Core application services
- **internal/config**: Configuration management
- **internal/db**: Database operations and migrations
- **internal/llm**: LLM providers and tools integration
- **internal/tui**: Terminal UI components and layouts
- **internal/logging**: Logging infrastructure
- **internal/message**: Message handling
- **internal/session**: Session management
- **internal/lsp**: Language Server Protocol integration

## Custom Commands

OpenCode supports custom commands that can be created by users to quickly send predefined prompts to the AI assistant.

### Creating Custom Commands

Custom commands are predefined prompts stored as Markdown files in one of three locations:

1. **User Commands** (prefixed with `user:`):

   ```
   $XDG_CONFIG_HOME/opencode/commands/
   ```

   (typically `~/.config/opencode/commands/` on Linux/macOS)

   or

   ```
   $HOME/.opencode/commands/
   ```

2. **Project Commands** (prefixed with `project:`):

   ```
   <PROJECT DIR>/.opencode/commands/
   ```

Each `.md` file in these directories becomes a custom command. The file name (without extension) becomes the command ID.

For example, creating a file at `~/.config/opencode/commands/prime-context.md` with content:

```markdown
RUN git ls-files
READ README.md
```

This creates a command called `user:prime-context`.

### Command Arguments

OpenCode supports named arguments in custom commands using placeholders in the format `$NAME` (where NAME consists of uppercase letters, numbers, and underscores, and must start with a letter).

For example:

```markdown
# Fetch Context for Issue $ISSUE_NUMBER

RUN gh issue view $ISSUE_NUMBER --json title,body,comments
RUN git grep --author="$AUTHOR_NAME" -n .
RUN grep -R "$SEARCH_PATTERN" $DIRECTORY
```

When you run a command with arguments, OpenCode will prompt you to enter values for each unique placeholder. Named arguments provide several benefits:

- Clear identification of what each argument represents
- Ability to use the same argument multiple times
- Better organization for commands with multiple inputs

### Organizing Commands

You can organize commands in subdirectories:

```
~/.config/opencode/commands/git/commit.md
```

This creates a command with ID `user:git:commit`.

### Using Custom Commands

1. Press `Ctrl+K` to open the command dialog
2. Select your custom command (prefixed with either `user:` or `project:`)
3. Press Enter to execute the command

The content of the command file will be sent as a message to the AI assistant.

### Built-in Commands

OpenCode includes several built-in commands:

| Command            | Description                                                                                         |
| ------------------ | --------------------------------------------------------------------------------------------------- |
| Initialize Project | Creates or updates the OpenCode.md memory file with project-specific information                    |
| Compact Session    | Manually triggers the summarization of the current session, creating a new session with the summary |

## MCP (Model Context Protocol)

OpenCode implements the Model Context Protocol (MCP) to extend its capabilities through external tools. MCP provides a standardized way for the AI assistant to interact with external services and tools.

### MCP Features

- **External Tool Integration**: Connect to external tools and services via a standardized protocol
- **Tool Discovery**: Automatically discover available tools from MCP servers
- **Multiple Connection Types**:
  - **Stdio**: Communicate with tools via standard input/output
  - **SSE**: Communicate with tools via Server-Sent Events
- **Security**: Permission system for controlling access to MCP tools

### Configuring MCP Servers

MCP servers are defined in the configuration file under the `mcpServers` section:

```json
{
  "mcpServers": {
    "example": {
      "type": "stdio",
      "command": "path/to/mcp-server",
      "env": [],
      "args": []
    },
    "web-example": {
      "type": "sse",
      "url": "https://example.com/mcp",
      "headers": {
        "Authorization": "Bearer token"
      }
    }
  }
}
```

### MCP Tool Usage

Once configured, MCP tools are automatically available to the AI assistant alongside built-in tools. They follow the same permission model as other tools, requiring user approval before execution.

## LSP (Language Server Protocol)

OpenCode integrates with Language Server Protocol to provide code intelligence features across multiple programming languages.

### LSP Features

- **Multi-language Support**: Connect to language servers for different programming languages
- **Diagnostics**: Receive error checking and linting information
- **File Watching**: Automatically notify language servers of file changes

### Configuring LSP

Language servers are configured in the configuration file under the `lsp` section:

```json
{
  "lsp": {
    "go": {
      "disabled": false,
      "command": "gopls"
    },
    "typescript": {
      "disabled": false,
      "command": "typescript-language-server",
      "args": ["--stdio"]
    }
  }
}
```

### LSP Integration with AI

The AI assistant can access LSP features through the `diagnostics` tool, allowing it to:

- Check for errors in your code
- Suggest fixes based on diagnostics

While the LSP client implementation supports the full LSP protocol (including completions, hover, definition, etc.), currently only diagnostics are exposed to the AI assistant.

## Using Github Copilot

_Copilot support is currently experimental._

### Requirements
- [Copilot chat in the IDE](https://github.com/settings/copilot) enabled in GitHub settings
- One of:
  - VSCode Github Copilot chat extension
  - Github `gh` CLI
  - Neovim Github Copilot plugin (`copilot.vim` or `copilot.lua`)
  - Github token with copilot permissions

If using one of the above plugins or cli tools, make sure you use the authenticate
the tool with your github account. This should create a github token at one of the following locations:
- ~/.config/github-copilot/[hosts,apps].json
- $XDG_CONFIG_HOME/github-copilot/[hosts,apps].json

If using an explicit github token, you may either set the $GITHUB_TOKEN environment variable or add it to the opencode.json config file at `providers.copilot.apiKey`.

## Using a self-hosted model provider

OpenCode can also load and use models from a self-hosted (OpenAI-like) provider.
This is useful for developers who want to experiment with custom models.

### Configuring a self-hosted provider

You can use a self-hosted model by setting the `LOCAL_ENDPOINT` environment variable.
This will cause OpenCode to load and use the models from the specified endpoint.

```bash
LOCAL_ENDPOINT=http://localhost:1235/v1
```

### Configuring a self-hosted model

You can also configure a self-hosted model in the configuration file under the `agents` section:

```json
{
  "agents": {
    "coder": {
      "model": "local.granite-3.3-2b-instruct@q8_0",
      "reasoningEffort": "high"
    }
  }
}
```

## Development

### Prerequisites

- Go 1.24.0 or higher

### Building from Source

```bash
# Clone the repository
git clone https://github.com/opencode-ai/opencode.git
cd opencode

# Build
go build -o opencode

# Run
./opencode
```

## Acknowledgments

OpenCode gratefully acknowledges the contributions and support from these key individuals:

- [@isaacphi](https://github.com/isaacphi) - For the [mcp-language-server](https://github.com/isaacphi/mcp-language-server) project which provided the foundation for our LSP client implementation
- [@adamdottv](https://github.com/adamdottv) - For the design direction and UI/UX architecture

Special thanks to the broader open source community whose tools and libraries have made this project possible.

## License

OpenCode is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contributing

Contributions are welcome! Here's how you can contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please make sure to update tests as appropriate and follow the existing code style.
</file>

</files>
